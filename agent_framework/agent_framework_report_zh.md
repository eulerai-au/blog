 # **å¦‚ä½•é€‰å‹ï¼Ÿçƒ­é—¨ AI Agent æ¡†æ¶æ·±åº¦æ¨ªè¯„**
ç”Ÿæˆå¼ AI çš„çˆ†å‘å¼å‘å±•è®©æŠ€æœ¯é€‰å‹æˆä¸ºå¼€å‘è€…é¢ä¸´çš„é¦–è¦æŒ‘æˆ˜ã€‚å‡ ä¹æ¯å¤©éƒ½æœ‰æ–°çš„æ¡†æ¶ã€å·¥å…·æˆ–æŠ€æœ¯æ¶Œç°ï¼Œæ— è®ºæ˜¯ä¸ªäººå¼€å‘è€…è¿˜æ˜¯ä¼ä¸šå›¢é˜Ÿï¼Œåœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„å»ºåˆ›æ–°åº”ç”¨æ—¶ï¼Œéƒ½ä¼šç›´é¢ä¸€ä¸ªé—®é¢˜ï¼šâ€œå“ªæ¬¾æ¡†æ¶æœ€é€‚åˆæˆ‘çš„åœºæ™¯ï¼Ÿâ€æœ¬æ–‡å°†ä»å¼€å‘äººå‘˜çš„è§†è§’ï¼Œä»å¤šä¸ªç»´åº¦æ·±åº¦æ¨ªè¯„äº”ä¸ªä¸»æµçš„ AI Agent æ¡†æ¶â€”â€”LangGraphã€LlamaIndexã€PydanticAIã€AutoGen å’Œ CrewAIï¼Œä¸ºå¼€å‘è€…æä¾›å®æ“å¯¼å‘çš„å‚è€ƒã€‚**éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦ä¾§é‡äºè¯„æµ‹è¿™äº›æ¡†æ¶åœ¨æ­å»ºéä»£ç†å‹ï¼ˆNon-Agenticï¼‰AI Workflow æ—¶çš„è¡¨ç°ã€‚**

## ä¸ºä»€ä¹ˆéœ€è¦LLMæ¡†æ¶ï¼Ÿ
LLM å¼€å‘æ¡†æ¶æ˜¯ä¸ºç®€åŒ– AI åº”ç”¨ï¼ˆå¦‚ Agentã€Workflowã€RAG ç­‰ï¼‰çš„åˆ›å»ºã€éƒ¨ç½²ä¸ç®¡ç†è€Œè®¾è®¡çš„è½¯ä»¶å¹³å°ã€‚è¿™äº›æ¡†æ¶æä¾›é¢„æ„å»ºç»„ä»¶ã€æŠ½è±¡æ¥å£ä¸å¼€å‘å·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…é«˜æ•ˆæ„å»ºå¤æ‚ AI ç³»ç»Ÿã€‚é€šè¿‡æ ‡å‡†åŒ–çš„å¼€å‘èŒƒå¼ä¸æ¨¡å—åŒ–æ¶æ„ï¼ŒLLM æ¡†æ¶è®©å¼€å‘è€…èƒ½å¤Ÿèšç„¦äºåº”ç”¨çš„ç‹¬ç‰¹é€»è¾‘ä¸åˆ›æ–°ï¼Œè€Œæ— éœ€é‡å¤é€ è½®å­ã€‚æ— è®ºæ˜¯å¿«é€ŸåŸå‹éªŒè¯è¿˜æ˜¯ç”Ÿäº§çº§éƒ¨ç½²ï¼Œæ ¹æ®è‡ªå·±çš„éœ€æ±‚åœºæ™¯åˆç†çš„é€‰æ‹©LLM æ¡†æ¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å¼€å‘é—¨æ§›ä¸æ—¶é—´æˆæœ¬ã€‚

## å·¥ä½œæµçš„æ ¸å¿ƒä»·å€¼
<font style="color:rgba(0, 0, 0, 0.87);">å·¥ä½œæµæ˜¯ä¸€ç§äº‹ä»¶é©±åŠ¨ã€åŸºäºæ­¥éª¤çš„æ–¹æ³•ï¼Œç”¨äºæ§åˆ¶åº”ç”¨ç¨‹åºçš„æ‰§è¡Œæµã€‚éšç€ç”Ÿæˆå¼ AI åº”ç”¨ç¨‹åºå˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œç®¡ç†æ•°æ®æµå’Œæ§åˆ¶åº”ç”¨ç¨‹åºçš„æ‰§è¡Œå˜å¾—è¶Šæ¥è¶Šå›°éš¾ã€‚ å·¥ä½œæµå°†ä»»åŠ¡æ‹†è§£ä¸ºæ¨¡å—åŒ–çš„å­æ­¥éª¤ï¼Œæä¾›æ›´é«˜çš„çµæ´»æ€§å’Œå¯ç»´æŠ¤æ€§ï¼Œç‰¹åˆ«åœ¨å¤šä»£ç†åä½œæˆ–è·¨ç³»ç»Ÿäº¤äº’åœºæ™¯ä¸­ï¼Œèƒ½æ˜¾è‘—æå‡å¼€å‘æ•ˆç‡å’Œç³»ç»Ÿé²æ£’æ€§ã€‚  </font>

## <font style="color:rgba(0, 0, 0, 0.87);">ä»£ç†å‹ä¸éä»£ç†å‹å·¥ä½œæµçš„åŒºåˆ«</font>
![agentic_workflow.png](pictures/agentic_workflow.png)

<font style="color:rgba(0, 0, 0, 0.87);">AI å·¥ä½œæµæ ¹æ®è‡ªä¸»æ€§å¯åˆ†ä¸ºéä»£ç†å‹ï¼ˆNon-Agenticï¼‰å’Œä»£ç†å‹ï¼ˆAgenticï¼‰ï¼š</font>

+ **éä»£ç†å‹å·¥ä½œæµ**<font style="color:rgba(0, 0, 0, 0.87);">ï¼šä¾èµ– LLM çš„è¾“å…¥-è¾“å‡ºèƒ½åŠ›ï¼Œæ‰§è¡Œé¢„å®šä¹‰çš„ç¡®å®šæ€§æ­¥éª¤ã€‚ä¾‹å¦‚ï¼Œæ–‡æœ¬æ‘˜è¦ä»»åŠ¡å¯èƒ½æ˜¯ï¼šè¾“å…¥é•¿æ–‡æœ¬ â†’ LLM ç”Ÿæˆæ‘˜è¦ â†’ è¾“å‡ºç»“æœã€‚æ­¤ç±»å·¥ä½œæµé€‚åˆå†…å®¹ç”Ÿæˆã€æ•°æ®å¤„ç†ç­‰è§„åˆ™æ˜ç¡®çš„åœºæ™¯ï¼Œä½†ç¼ºä¹åŠ¨æ€å†³ç­–å’Œç¯å¢ƒé€‚åº”èƒ½åŠ›ã€‚</font>
+ **ä»£ç†å‹å·¥ä½œæµ**<font style="color:rgba(0, 0, 0, 0.87);">ï¼šç”± AI ä»£ç†åŠ¨æ€æ‰§è¡Œä»»åŠ¡ï¼Œå…·å¤‡æ¨ç†ã€å·¥å…·è°ƒç”¨å’Œä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›ã€‚ä»£ç†èƒ½åœ¨æˆæƒèŒƒå›´å†…è‡ªä¸»æ”¶é›†ä¿¡æ¯ã€è°ƒç”¨å¤–éƒ¨ API æˆ–åšå‡ºå†³ç­–ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªæ™ºèƒ½å®¢æœä»£ç†å¯é€šè¿‡åˆ†æç”¨æˆ·æ„å›¾ã€æŸ¥è¯¢ CRM ç³»ç»Ÿå¹¶ç”Ÿæˆä¸ªæ€§åŒ–å›å¤ï¼ŒåŠ¨æ€å¤„ç†å¤æ‚äº¤äº’ã€‚ä»£ç†å‹å·¥ä½œæµå› å…¶å“åº”æ€§å’Œè‡ªé€‚åº”æ€§ï¼Œç‰¹åˆ«é€‚åˆå¤šæ­¥éª¤ã€äº¤äº’å¼æˆ–è·¨ç³»ç»Ÿçš„åœºæ™¯ã€‚</font>

## <font style="color:rgba(0, 0, 0, 0.87);">å¦‚ä½•é€‰æ‹©ï¼Ÿ</font>
è¿™é‡Œæ¨èå¼€å‘è€…å¯ä»¥ä»ä¸‹é¢ä¸‰ä¸ªæ–¹å‘å»æ€è€ƒå’Œè¯„ä¼°ä½ çš„å®é™…å¼€å‘éœ€æ±‚ï¼š

### ä»»åŠ¡èƒ½ä¸èƒ½æ‹†æˆæ¸…æ™°æ­¥éª¤ï¼Ÿ
+ **èƒ½æ‹†**ï¼šè€ƒè™‘é€‰ **éä»£ç†å‹å·¥ä½œæµ**ï¼Œæ‹†æˆ Workflowã€‚  
å¦‚æœä»»åŠ¡å¯ä»¥åˆ†è§£ä¸ºæ˜ç¡®çš„æ­¥éª¤ï¼ˆå¦‚æ•°æ®æå– â†’ åˆ†æ â†’ ç”ŸæˆæŠ¥å‘Šï¼‰ï¼Œç”¨éä»£ç†å‹å·¥ä½œæµæœ€çœåŠ›ã€‚æ¯ä¸ªæ­¥éª¤åƒæµæ°´çº¿ï¼Œç¨³å®šã€å¯æ§ï¼Œé€‚åˆå†…å®¹ç”Ÿæˆã€æ•°æ®å¤„ç†ç­‰è§„åˆ™æ˜ç¡®çš„åœºæ™¯ã€‚  
**ä½•æ—¶æ‹†åˆ†ï¼Ÿ** å½“ä»»åŠ¡æœ‰å¯é çš„ä¸­é—´æ£€æŸ¥ç‚¹ï¼ˆç±»ä¼¼â€œè¿‡ç¨‹å¥–åŠ±æ¨¡å‹â€ PRMï¼‰ï¼Œæ¯”å¦‚æ¯æ­¥è¾“å‡ºå¯ä»¥éªŒè¯æ­£ç¡®æ€§ï¼Œå°±è¯¥æ‹†åˆ† Workflowã€‚æ‹†åˆ†åèƒ½æ’å…¥éªŒè¯å·¥å…·ï¼Œå‘ç°é—®é¢˜å°±æ‰“å›é‡åšï¼Œé™ä½å‡ºé”™é£é™©ã€‚  
**ä¾‹å­**ï¼šç”Ÿæˆè´¢åŠ¡æŠ¥è¡¨ï¼Œæ‹†æˆâ€œæ‹‰æ•°æ® â†’ è®¡ç®— â†’ æ ¼å¼åŒ–â€ï¼Œæ¯æ­¥éƒ½èƒ½æ£€æŸ¥ï¼Œç¡®ä¿ä¸å‡ºé”™ã€‚
+ **ä¸å¥½æ‹†**ï¼šè€ƒè™‘é€‰ **ä»£ç†å‹å·¥ä½œæµ**ï¼Œé æ¨¡å‹æ™ºèƒ½ã€‚  
å¦‚æœä»»åŠ¡åŠ¨æ€å¤šå˜ï¼ˆå¦‚æ™ºèƒ½å®¢æœéœ€å®æ—¶ç†è§£ç”¨æˆ·ã€è°ƒç”¨å·¥å…·ï¼‰ï¼Œä»£ç†å‹å·¥ä½œæµçš„è‡ªä¸»æ¨ç†å’Œå·¥å…·è°ƒç”¨æ›´é€‚åˆã€‚Agent åƒæ™ºèƒ½åŠ©æ‰‹ï¼Œèƒ½åŠ¨æ€è§„åˆ’è·¯å¾„ã€‚  
**ä½•æ—¶é æ¨¡å‹ï¼Ÿ** å¦‚æœä¸­é—´è¿‡ç¨‹éš¾ä»¥éªŒè¯ï¼Œæˆ–æ‹†åˆ†å Workflow è¿‡äºå¤æ‚ã€ç ”å‘æˆæœ¬è¿‡é«˜ï¼Œå°±è¯¥é æ¨¡å‹ã€‚å¯ä»¥ç”¨ç°æˆæ¨¡å‹åš Agentï¼Œæˆ–é’ˆå¯¹åœºæ™¯åš SFT/RFT å¾®è°ƒï¼Œç”šè‡³åˆæˆæ•°æ®è¿›è¡Œæ·±åº¦è®­ç»ƒã€‚  
**ä¾‹å­**ï¼šå®æ—¶æ•…éšœè¯Šæ–­ï¼Œéœ€åŠ¨æ€æŸ¥æ—¥å¿—ã€è°ƒ APIï¼ŒAgent èƒ½çµæ´»åº”å¯¹ã€‚

### ç¨³å®šæ€§å’Œå¯è§£é‡Šæ€§è¦æ±‚é«˜å—ï¼Ÿ
+ **é«˜**ï¼šè€ƒè™‘é€‰ **éä»£ç†å‹å·¥ä½œæµ**ï¼Œæ‹†åˆ†ä¼˜å…ˆã€‚  
é‡‘èã€åŒ»ç–—ç­‰åœºæ™¯éœ€è¦é«˜ç¨³å®šæ€§å’Œå¯æ§æ€§ï¼ŒWorkflow çš„å›ºå®šæ­¥éª¤èƒ½å‡å°‘æ¨¡å‹éšæœºæ€§å¸¦æ¥çš„é£é™©ã€‚  
**å¯è§£é‡Šæ€§éœ€æ±‚**ï¼šå¦‚æœä¸šåŠ¡è¦æ±‚ä¸­é—´ç»“æœé€æ˜ï¼ˆå¦‚å±•ç¤ºç»™ç”¨æˆ·æˆ–æ”¯æŒäººå·¥å¹²é¢„ï¼‰ï¼Œæ‹†åˆ† Workflow èƒ½æå–æ¯æ­¥è¾“å‡ºï¼Œæ–¹ä¾¿æ£€æŸ¥å’Œæ§åˆ¶ï¼Œå“ªæ€•è¿™å¯èƒ½ç‰ºç‰²ç‚¹æ•ˆæœã€‚  
**ä¾‹å­**ï¼šåŒ»ç–—æ•°æ®å¤„ç†ï¼Œæ‹†åˆ†æ­¥éª¤å¹¶å±•ç¤ºä¸­é—´ç»“æœï¼Œæ»¡è¶³ç›‘ç®¡å’Œç”¨æˆ·ä¿¡ä»»éœ€æ±‚ã€‚
+ **ä½**ï¼šè€ƒè™‘é€‰ **ä»£ç†å‹å·¥ä½œæµ**ï¼Œé æ¨¡å‹ã€‚  
åŸå‹éªŒè¯æˆ–äº¤äº’å¼åœºæ™¯ï¼ˆå¦‚æ™ºèƒ½åŠ©æ‰‹ï¼‰å¯ä»¥æ¥å—ä¸€å®šä¸ç¡®å®šæ€§ï¼ŒAgent çš„çµæ´»æ€§æ›´é€‚åˆå¿«é€Ÿè¯•é”™ã€‚é•¿æœŸçœ‹ï¼Œæ— å¯é æ£€æŸ¥ç‚¹çš„ç¯èŠ‚ä¼šé€æ¸èåˆï¼Œé æ¨¡å‹æ™ºèƒ½è§£å†³é—®é¢˜ã€‚  
**èåˆè¿˜æ˜¯è®­ç»ƒï¼Ÿ** èåˆæ–¹å‘ä¸Šï¼Œç”¨ç°æˆæ¨¡å‹åš Agent æˆæœ¬ä½ï¼›è‹¥åœºæ™¯ç‰¹æ®Šï¼ˆå¦‚å¼€æ”¾æ€§å¼ºã€ç°æœ‰æ¨¡å‹æ•ˆæœå·®ï¼‰ï¼Œå¯è€ƒè™‘å¾®è°ƒæˆ–è‡ªè®­æ¨¡å‹ã€‚  
**ä¾‹å­**ï¼šå®éªŒæ€§å¯¹è¯ç³»ç»Ÿï¼ŒAgent ç›´æ¥è·‘ï¼Œæ•ˆæœä¸å¥½å†å¾®è°ƒã€‚

### ç°åœ¨åšéä»£ç†å‹ Workflow è¿˜æ˜¯ç­‰æ¨¡å‹è¿›æ­¥ï¼Ÿ
+ **ç°åœ¨åšéä»£ç†å‹ Workflow**ï¼š  
å¦‚æœä»»åŠ¡èƒ½æ‹†åˆ†ä¸”æœ‰å¯é æ£€æŸ¥ç‚¹ï¼Œå°½å¿«å»º Workflowï¼ŒéªŒè¯æ•ˆæœã€‚Workflow é€‚åˆå¿«é€Ÿä¸Šçº¿ï¼Œå°¤å…¶åœ¨æ–°åœºæ™¯éªŒè¯é˜¶æ®µï¼Œç ”å‘æˆæœ¬å¯æ§ã€‚  
**ç›´è§‰æ³µ**ï¼šé—®è‡ªå·±ï¼Œâ€œè¿™ä¸ª Workflow åŠå¹´åä¼šè¢«æ–°æ¨¡å‹é¢ è¦†å—ï¼Ÿâ€ å¦‚æœ 80% çš„å·¥ä½œé‡ä¼šç™½è´¹ï¼Œè€ƒè™‘æš‚åœï¼Œè¯„ä¼°æ¨¡å‹å‘å±•é€Ÿåº¦ã€‚
+ **ç­‰æ¨¡å‹æˆ–é  Agent**ï¼š  
å¦‚æœ Workflow æ‹†åˆ†åå¤ªå¤æ‚ï¼Œæˆ–ç°æœ‰æ¨¡å‹æ•ˆæœå¾ˆå·®ï¼ˆå¦‚å¼€æ”¾åœºæ™¯ï¼‰ï¼Œå¯ä»¥å…ˆç”¨ Agent è·‘ baselineï¼Œè§‚å¯Ÿæ¨¡å‹è¿›æ­¥ã€‚é•¿æœŸçœ‹ï¼Œæ— æ£€æŸ¥ç‚¹çš„ç¯èŠ‚ä¼šé æ¨¡å‹èåˆè§£å†³ã€‚  
**ä¾‹å­**ï¼šè¶…å¤æ‚ä»»åŠ¡ï¼ˆå¦‚å…¨è‡ªåŠ¨ä»£ç ç”Ÿæˆï¼‰ï¼Œç°æœ‰æ¨¡å‹ä¸è¡Œï¼Œå…ˆç”¨ Agent è¯•ï¼Œç­‰å¾…æ›´å¼ºæ¨¡å‹ã€‚

> ğŸ’¡Tipsï¼š
> + **æ··åˆç­–ç•¥**ï¼šå¤æ‚ä»»åŠ¡å¸¸ç»“åˆä¸¤è€…â€”â€” Workflow åº”å¯¹ç¡®å®šæ€§å­ä»»åŠ¡ï¼ŒAgent ç®¡åŠ¨æ€å†³ç­–ã€‚
> + **åˆ«è½»æ˜“æ”¹ PMF æ–¹æ¡ˆ**ï¼šå·²éªŒè¯æœ‰æ•ˆçš„æ–¹æ¡ˆï¼ˆProduct-Market Fitï¼‰æ— éœ€é¢‘ç¹è°ƒæ•´ï¼Œé™¤éæœ‰å¼ºéœ€æ±‚ã€‚æŠ€æœ¯è¿­ä»£å¿«ï¼Œæ¯éš”ä¸€å®šå‘¨æœŸï¼ˆå¦‚åŠå¹´ï¼‰è¯„ä¼°ä¸€æ¬¡å³å¯ã€‚
> + **éä»£ç†å‹Workflow ä¸ä¼šè¢«æ·˜æ±°**ï¼šå®ƒåœ¨å¯æ‹†åˆ†ã€é«˜ç¨³å®šåœºæ™¯ä¸­å§‹ç»ˆé«˜æ•ˆï¼Œå°¤å…¶å½“å¯è§£é‡Šæ€§å’Œä¸­é—´éªŒè¯è‡³å…³é‡è¦æ—¶ã€‚
>

# äº”ä¸ªä¸»æµAgentå¼€å‘æ¡†æ¶
## å¼€æºæƒ…å†µä¸ç¤¾åŒºçƒ­åº¦
è¡¨1ï¼šä¸»æµ AI Agent æ¡†æ¶ç¤¾åŒºæ´»è·ƒåº¦å¯¹æ¯”æ€»è§ˆ

| æ¡†æ¶åç§° | Stars | Commits | Issues | Forks | PR åˆ›å»ºè€…æ•° | ä¸»è¯­è¨€ |
| --- | --- | --- | --- | --- | --- | --- |
| **LangGraph** | 11,353 | 9,624 | 646 | 2,022 | 259 | Python |
| **LlamaIndex** | 39,568 | 14,044 | 8,826 | 5,881 | 1,603 | Python |
| **PydanticAI** | 8,218 | 2,303 | 724 | 798 | 159 | Python |
| **AutoGen** | 41,610 | 14,143 | 2,667 | 6,624 | 571 | Python |
| **CrewAI** | 29,091 | 5,245 | 1,290 | 4,129 | 364 | Python |


_è¡¨2ï¼š è¿‘ 28 å¤©ä¸»æµ AI Agent æ¡†æ¶ç¤¾åŒºæ´»è·ƒåº¦å¯¹æ¯”è¡¨  _

| æ¡†æ¶åç§° | Stars å¢é•¿ | PRï¼ˆOpenï¼‰ | PRï¼ˆmergeï¼‰ | Issuesï¼ˆOpenï¼‰ | Issuesï¼ˆClosedï¼‰ |  Commits |
| --- | --- | --- | --- | --- | --- | --- |
| **LangGraph** | 1,018 | 157 | 141 | 49 | 45 | 630 |
| **LlamaIndex** | 657 | 100 | 85 | 85 | 382 | 202 |
| **PydanticAI** | 969 | 99 | 67 | 119 | 102 | 313 |
| **AutoGen** | 1,233 | 103 | 88 | 54 | 65 | 167 |
| **CrewAI** | 1,265 | 113 | 48 | 70 | 69 | 393 |


## æµ‹è¯„æ€»è§ˆ
**å…ˆç»™ç»“è®ºï¼š**

+ **LangGraphï¼š**å¦‚æœä½ è¦æ„å»º**å¯æ§æ€§å¼ºã€çŠ¶æ€æ¸…æ™°çš„å¤æ‚ä»£ç†ç³»ç»Ÿ**ï¼Œå¦‚å¯¹è¯æœºå™¨äººã€ä»£ç åˆ†æå™¨ï¼Œæ¨èä½¿ç”¨ LangGraphã€‚å®ƒåŸºäºå›¾æ¨¡å‹çš„å·¥ä½œæµæ¶æ„ï¼Œéå¸¸é€‚åˆéœ€è¦æ¸…æ™°çŠ¶æ€æµè½¬ã€å¼‚å¸¸æ¢å¤ã€ä»»åŠ¡å›æº¯çš„ä¼ä¸šçº§åœºæ™¯ã€‚
+ **LlamaIndexï¼š**  
å¦‚æœä½ åå‘**æ•°æ®é©±åŠ¨çš„é—®ç­”ç³»ç»Ÿæˆ–å¤šè½®æ–‡æ¡£å¤„ç†ä»»åŠ¡**ï¼Œå¦‚å†…éƒ¨çŸ¥è¯†åº“é—®ç­”ã€ä¼ä¸šæœç´¢ï¼ŒLlamaIndex æ˜¯ä¼˜é€‰ã€‚  
å®ƒçš„æ•°æ®æ„ŸçŸ¥èƒ½åŠ›å¼ºï¼Œæ“…é•¿å¤„ç†å¤šæ¨¡æ€æ•°æ®ä¸æ–‡æ¡£ç»“æ„ï¼Œæ˜¯æ„å»º RAG åº”ç”¨çš„æˆç†Ÿæ–¹æ¡ˆã€‚
+ **PydanticAIï¼š**  
å¯¹äºå¸Œæœ›**è¾“å‡ºç»“æ„ä¸¥è°¨ã€å®‰å…¨ç¨³å®šçš„ AI æœåŠ¡**ï¼Œç‰¹åˆ«æ˜¯åœ¨åç«¯ç³»ç»Ÿä¸­å¯¹æ¥ LLMï¼ŒPydanticAI æä¾›ç±»å‹ä¿éšœï¼Œæå…¶é€‚åˆã€‚å®ƒåœ¨è¾“å…¥/è¾“å‡ºæ ¼å¼æ§åˆ¶ä¸Šéå¸¸ç²¾ç»†ï¼Œé€‚ç”¨äºéœ€è¦é«˜å¯é æ€§ã€ç±»å‹æ ¡éªŒçš„åœºæ™¯ï¼Œå°¤å…¶ä¾¿äºé›†æˆåˆ° API æˆ–å¾®æœåŠ¡ä¸­ã€‚
+ **AutoGenï¼š**  
AutoGen éå¸¸é€‚åˆéœ€è¦**å¿«é€ŸåŸå‹ã€åŠ¨æ€åä½œã€å¤šæ™ºèƒ½ä½“æ¶ˆæ¯äº¤äº’**çš„åœºæ™¯ï¼Œæ¯”å¦‚ç ”ç©¶å‹å¯¹è¯å·¥å…·ã€ä»£ç å»ºè®®å™¨ç­‰ã€‚å®ƒçµæ´»ä¸”å¼€ç®±å³ç”¨ï¼Œå°¤å…¶é€‚åˆç”¨äºæ¢ç´¢æ€§é¡¹ç›®ã€åˆ›æ–°å®éªŒæˆ–æ„å»ºå…·æœ‰å¯¹è¯è®°å¿†ä¸æ¨ç†é“¾çš„å¤šä»£ç†ç³»ç»Ÿã€‚
+ **CrewAIï¼š**  
æƒ³è¦æ„å»º**å¤šè§’è‰²åä½œã€ä¸šåŠ¡æµè‡ªåŠ¨åŒ–**çš„ç³»ç»Ÿï¼Œå¦‚å†…å®¹å›¢é˜Ÿç¼–æ’æˆ–è·¨éƒ¨é—¨æµç¨‹ç®¡ç†ï¼ŒCrewAI æ˜¯å®æˆ˜å¯¼å‘æœ€å¼ºçš„é€‰æ‹©ä¹‹ä¸€ã€‚å®ƒé€šè¿‡è§’è‰²åˆ†å·¥ä¸æµç¨‹é©±åŠ¨ç›¸ç»“åˆï¼Œèƒ½å¤Ÿéå¸¸è‡ªç„¶åœ°æ˜ å°„ç°å®ä¸­å›¢é˜Ÿåˆä½œçš„ä»»åŠ¡åˆ†è§£ä¸æ‰§è¡Œé€»è¾‘ã€‚

ä»¥ä¸‹æ˜¯ä»æŠ€æœ¯ç‰¹æ€§ã€æ§åˆ¶èƒ½åŠ›ã€çŠ¶æ€æŒä¹…ã€å¯è§‚æµ‹æ€§ã€éƒ¨ç½²ä¾¿åˆ©æ€§ç­‰å¤šä¸ªç»´åº¦ï¼Œå¯¹äº”å¤§æ¡†æ¶çš„å…¨é¢è¯„æµ‹å¯¹æ¯”ï¼š

| ç‰¹æ€§ / æ¡†æ¶ | **LangGraph** | **LlamaIndex** | **PydanticAI** | **AutoGen** | **CrewAI** |
| --- | --- | --- | --- | --- | --- |
| **æŠ€æœ¯ç‰¹ç‚¹** | æœ‰çŠ¶æ€å›¾ç¼–æ’æ¡†æ¶ï¼Œæ”¯æŒå¤æ‚æ§åˆ¶æµå’Œå¤šæ™ºèƒ½ä½“ã€‚é‡‡ç”¨ DAG æ¶æ„ï¼ŒèŠ‚ç‚¹ä¸è¾¹ç²¾ç»†å®šä¹‰ã€‚æ”¯æŒçŠ¶æ€æŒä¹…åŒ–ã€å¼‚å¸¸æ¢å¤å’Œæµå¼è¾“å‡ºã€‚ | äº‹ä»¶é©±åŠ¨çš„å·¥ä½œæµæ¨¡å‹ï¼Œç®€åŒ–æ•°æ®æµä¼ é€’ã€‚æ”¯æŒæ–‡æ¡£æ£€ç´¢ä¸å¤„ç†ï¼Œé›†æˆä¸°å¯Œå·¥å…·é“¾ã€‚ | åŸºäº Pydanticï¼Œå¼ºè°ƒç±»å‹å®‰å…¨ä¸ç»“æ„åŒ–è¾“å‡ºã€‚è®¾è®¡è½»é‡ï¼Œé€‚åˆåç«¯é›†æˆã€‚ | å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ï¼ŒåŸºäºå¯¹è¯ä¸æ¶ˆæ¯ä¼ é€’ã€‚æ”¯æŒå¼‚æ­¥æ‰§è¡Œä¸ä»£ç è‡ªåŠ¨ç”Ÿæˆã€‚ | ä¸“æ³¨å¤šè§’è‰²åä½œï¼Œé‡‡ç”¨ Crew + Flow æ¨¡å¼ï¼Œæ”¯æŒå¹¶å‘ã€ç¼“å­˜å’Œä»»åŠ¡å§”æ´¾ã€‚ |
| **é€‚ç”¨åœºæ™¯** | é¢å‘é«˜å¯æ§æ€§ã€é«˜å¯è§‚æµ‹æ€§çš„å¤æ‚åº”ç”¨ï¼Œå¦‚æ™ºèƒ½åŠ©æ‰‹ã€ä»£ç ç”Ÿæˆã€ä¸šåŠ¡æµç¨‹ã€‚ | æ•°æ®é©±åŠ¨çš„é—®ç­”ä¸ç ”ç©¶ç±»ä»»åŠ¡ï¼Œå¦‚çŸ¥è¯†åº“æ£€ç´¢ã€é—®ç­”ç”Ÿæˆç­‰ã€‚ | å¼ºè°ƒå®‰å…¨ä¸ç»“æ„æ€§ï¼Œé€‚åˆæ•°æ®å¤„ç†ã€ç»“æ„ç”Ÿæˆä¸åç«¯æ¥å£é›†æˆã€‚ | å¯¹è¯ã€ä»£ç ç¼–å†™ã€ç ”ç©¶è®¨è®ºç±»ä»»åŠ¡ï¼›é€‚åˆåŠ¨æ€å¤šä»£ç†ç¼–æ’åœºæ™¯ã€‚ | å·¥ä½œæµè‡ªåŠ¨åŒ–ã€å¤šæ™ºèƒ½ä½“ä»»åŠ¡ååŒï¼Œå¦‚å†…å®¹ç”Ÿäº§ã€å®¡æ‰¹æµç­‰ã€‚ |
| **çŠ¶æ€ç®¡ç†** | å†…å»ºçŠ¶æ€æœºåˆ¶ï¼ŒèŠ‚ç‚¹é—´é€šè¿‡ TypedDict å…±äº«çŠ¶æ€ï¼›æ”¯æŒçŠ¶æ€ reducer å’Œæ£€æŸ¥ç‚¹ã€‚ | é€šè¿‡ Context ä¼ é€’å…¨å±€ä¸Šä¸‹æ–‡ï¼Œç®€åŒ–çŠ¶æ€å…±äº«ä¸æ›´æ–°ã€‚ | åˆ©ç”¨ä¾èµ–æ³¨å…¥ä¼ é€’çŠ¶æ€ï¼ŒAgent è¾“å…¥è¾“å‡ºé€šè¿‡ Pydantic æ¨¡å‹å®šä¹‰ã€‚ | çŠ¶æ€é€šè¿‡æ¶ˆæ¯å…±äº«ï¼›ç”±ç”¨æˆ·ç®¡ç†çŠ¶æ€å­˜å‚¨æˆ–ä¸Šä¸‹æ–‡è®°å¿†ã€‚ | Flow æä¾›å†…ç½®çŠ¶æ€æ”¯æŒï¼›Crews å¯ä¿ç•™ä¸Šä¸‹æ–‡ï¼Œé€‚é…å¤šè½®ä»»åŠ¡ã€‚ |
| **ç»†ç²’åº¦æ§åˆ¶** | æ”¯æŒåˆ†æ”¯ã€å¾ªç¯ã€å¹¶è¡Œã€æ¡ä»¶è·³è½¬ç­‰é«˜çº§æµç¨‹æ§åˆ¶ã€‚Send API å®ç°åŠ¨æ€ä»»åŠ¡è°ƒåº¦ã€‚ | æ”¯æŒåˆ†æ”¯ä¸å¾ªç¯äº‹ä»¶ï¼›å­æµç¨‹ã€åµŒå¥—æµç¨‹å¯ç»„åˆæ„å»ºå¤æ‚æ‰§è¡Œå›¾ã€‚ | æ”¯æŒé€šè¿‡ Python æ§åˆ¶æµç»„ç»‡ä»»åŠ¡ï¼›å¹¶å‘éœ€æ‰‹åŠ¨å®ç°ã€‚ | å¤š Agent å¹¶è¡Œã€ä¸»é¢˜è®¢é˜…ã€æ¶ˆæ¯æ¨¡å¼ï¼Œé€‚åˆéç»“æ„åŒ–äº¤äº’ã€‚ | å¯ä½¿ç”¨é€»è¾‘æ¡ä»¶æ§åˆ¶åˆ†æ”¯ä¸åŒæ­¥ï¼›æ”¯æŒä»»åŠ¡å§”æ´¾å’Œå¤šè·¯å¾„åä½œã€‚ |
| **å¼‚æ­¥ä¸å¹¶å‘** | æ”¯æŒå¼‚æ­¥æ‰§è¡ŒèŠ‚ç‚¹ï¼Œå…¼å®¹ asyncioï¼›é…åˆ Ray å¯æ‰©å±•ä¸ºåˆ†å¸ƒå¼ã€‚ | å®Œå…¨å¼‚æ­¥æ¨¡å‹ï¼Œæ”¯æŒ `await`<br/>ã€äº‹ä»¶å¼‚æ­¥è§¦å‘å’Œå¹¶è¡Œ Stepã€‚ | åŸç”Ÿæ”¯æŒå¼‚æ­¥å‡½æ•°ä¸å¹¶å‘æ‰§è¡Œï¼›å¼‚æ­¥æ ¡éªŒå’Œè°ƒç”¨å…¼å®¹æ€§å¥½ã€‚ | æ¶æ„åŸç”Ÿæ”¯æŒ asyncioï¼›Agent ä»»åŠ¡å¯å¹¶å‘æˆ–å¼‚æ­¥è¿è¡Œã€‚ | æ”¯æŒå¼‚æ­¥æ‰§è¡Œã€å¹¶å‘ Flow æ­¥éª¤ï¼Œæœ€å¤§é™åº¦åˆ©ç”¨å¤šæ ¸èµ„æºã€‚ |
| **åˆ†å¸ƒå¼æ”¯æŒ** | å¯ä¸ Ray ç»“åˆå®ç°åˆ†å¸ƒå¼éƒ¨ç½²ï¼›ä¼ä¸šç‰ˆå†…å»ºè°ƒåº¦ä¸é›†ç¾¤èƒ½åŠ›ã€‚ | æ”¯æŒä¸ Ray é…åˆåˆ†å¸ƒå¼æ‰§è¡Œï¼›å¤šèŠ‚ç‚¹ä»»åŠ¡å¹¶å‘éœ€ç”¨æˆ·ç®¡ç†ã€‚ | æ— å†…å»ºåˆ†å¸ƒå¼ï¼›å¯ç»“åˆ Celeryã€FastAPI ç­‰å®ç°æ¨ªå‘æ‰©å±•ã€‚ | æ”¯æŒæœ¬åœ°å’Œè¿œç¨‹éƒ¨ç½²ï¼Œå…·å¤‡å¤šè¿›ç¨‹ã€åˆ†å¸ƒå¼è¿è¡Œæœºåˆ¶ã€‚ | ä¼ä¸šç‰ˆæ”¯æŒé›†ç¾¤éƒ¨ç½²ä¸è´Ÿè½½å‡è¡¡ï¼›å¼€æºç‰ˆéœ€æ‰‹åŠ¨æ‰©å±•ã€‚ |
| **æµå¼è¾“å‡º** | å¤šç§æ¨¡å¼ï¼šæŒ‰èŠ‚ç‚¹æ›´æ–°ã€é€ tokenã€ç»“æ„åŒ–ç»“æœæµï¼›é€‚åˆå‰ç«¯å®æ—¶äº¤äº’ã€‚ | æ­¥éª¤çº§å’Œ token çº§äº‹ä»¶æµæ”¯æŒï¼Œé€‚åˆ UI åŠ¨æ€åé¦ˆã€‚ | æ”¯æŒè¾¹ç”Ÿæˆè¾¹éªŒè¯ï¼Œé€‚é… LLM è¾“å‡ºé€æ­¥æ£€æŸ¥çš„åœºæ™¯ã€‚ | æ”¯æŒé€å¥/é€ token è¾“å‡ºï¼Œæ–¹ä¾¿ç”¨æˆ·å®æ—¶æŸ¥çœ‹ç”Ÿæˆè¿‡ç¨‹ã€‚ | æ”¯æŒä»»åŠ¡å›è°ƒç›‘å¬ï¼Œé—´æ¥å®ç°æµå¼äº¤äº’ã€‚ |
| **æŒä¹…åŒ–æœºåˆ¶** | æ”¯æŒæœ¬åœ°å’Œè¿œç¨‹æ•°æ®åº“æŒä¹…åŒ–ï¼ˆå¦‚ Postgresï¼‰ï¼›çº¿ç¨‹çº§/è·¨çº¿ç¨‹çŠ¶æ€ä¿å­˜ã€‚ | éœ€è‡ªè¡Œé›†æˆå‘é‡æ•°æ®åº“æˆ–ç¼“å­˜ç³»ç»Ÿè¿›è¡ŒçŠ¶æ€ä¿å­˜ã€‚ | æ— æŒä¹…å±‚ï¼Œéœ€å¼€å‘è€…ç®¡ç†æ•°æ®å­˜å‚¨ã€‚ | åº”ç”¨å±‚ç®¡ç†æŒä¹…åŒ–ï¼Œç»“åˆå¤–éƒ¨æ•°æ®åº“è®°å½•ä¼šè¯ç­‰ä¿¡æ¯ã€‚ | å†…ç½® Memory æ¨¡å—ï¼Œè‡ªåŠ¨ç¼“å­˜ä»»åŠ¡çŠ¶æ€ï¼›æ”¯æŒè·¨ä»»åŠ¡ä¸Šä¸‹æ–‡ã€‚ |
| **å¯è§‚æµ‹æ€§** | å¯é›†æˆ LangSmithï¼Œè¿½è¸ªè°ƒç”¨é“¾å’Œ token æ¶ˆè€—ï¼›éœ€è‡ªè¡Œæ·»åŠ ç›‘æ§ã€‚ | æ”¯æŒæ—¥å¿—è®°å½•å’Œ Verbose è°ƒè¯•ï¼Œéœ€ç”¨æˆ·è‡ªå»ºç›‘æ§é€»è¾‘ã€‚ | åŸç”Ÿé›†æˆ Logfireï¼Œæ”¯æŒå¯è§†åŒ–è°ƒè¯•ä¸æ—¥å¿—è¿½è¸ªã€‚ | å¯ç»“åˆæ—¥å¿—ç³»ç»Ÿåˆ†æè¡Œä¸ºï¼Œæ— ä¸“ç”¨å¯è§†åŒ–é¢æ¿ã€‚ | æä¾›æ§åˆ¶å¹³é¢è§†å›¾ï¼Œå±•ç¤ºæ¯ä¸ª Crew çš„è°ƒç”¨å’Œæ¶ˆè€—ç»Ÿè®¡ã€‚ |
| **å­¦ä¹ æ›²çº¿** | å›¾æ¨¡å‹ä¸ reducer æœºåˆ¶å¯¹åˆå­¦è€…ç•¥æœ‰æŒ‘æˆ˜ï¼›æ–‡æ¡£è¯¦å®ã€‚ | ä¸­ç­‰éš¾åº¦ï¼Œéœ€ç†è§£äº‹ä»¶æµä¸æµç¨‹ç¼–æ’ï¼›æ”¯æŒå¯è§†åŒ–åˆ†æã€‚ | æ˜“äºå…¥é—¨ï¼Œé¢å‘ Python å¼€å‘è€…ï¼›å¼ºè°ƒå·¥ç¨‹å®è·µã€‚ | å¤šæ¨¡å—åä½œè¾ƒå¤æ‚ï¼Œéœ€ç†è§£ Agent æ¨¡å¼ä¸æ‰©å±•æ–¹å¼ã€‚ | æ¨¡å‹æ¸…æ™°ä½†è¾ƒæ–°ï¼›éœ€ç†Ÿæ‚‰ Crew/Flow æœºåˆ¶ä¸ç”Ÿå‘½å‘¨æœŸã€‚ |
| **ç¤¾åŒºæ´»è·ƒåº¦** | æ´»è·ƒç¤¾åŒºï¼ŒåŸºäº LangChain ç”Ÿæ€ï¼›å¤šå…¬å¸å·²åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨ã€‚ | ç”¨æˆ·åŸºæ•°å¤§ï¼Œç¤¾åŒºæ–‡æ¡£ä¸°å¯Œï¼›æ´»è·ƒç»´æŠ¤ä¸ç‰ˆæœ¬æ›´æ–°ã€‚ | æ–°å…´æ¡†æ¶ï¼Œä¾æ‰˜ Pydantic ç¤¾åŒºï¼›å¢é•¿å¿«é€Ÿã€‚ | å¤§å‹ç¤¾åŒºæ”¯æŒï¼Œæ–‡æ¡£å®Œå–„ï¼ŒGitHub æ´»è·ƒåº¦é«˜ã€‚ | Star æ•°å¤šï¼Œæ–‡æ¡£å’Œè¯¾ç¨‹ä¸°å¯Œï¼Œä¼ä¸šæ”¯æŒç¨‹åº¦é«˜ã€‚ |
| **LLM æ”¯æŒèŒƒå›´** | OpenAIã€Anthropicã€Mistralã€Llama ç­‰ä¸»æµæ¨¡å‹ï¼›ä¹Ÿæ”¯æŒè‡ªå®šä¹‰ã€‚ | æ”¯æŒæ‰€æœ‰å…¼å®¹ LangChain çš„ LLMï¼Œæ”¯æŒè‡ªå®šä¹‰å·¥å…·è°ƒç”¨ã€‚ | æ”¯æŒ OpenAIã€Claudeã€Geminiã€DeepSeekã€Cohere ç­‰ã€‚ | æ”¯æŒä¸»æµ API æä¾›å•†ï¼ˆOpenAIã€Azure OpenAIã€HF ç­‰ï¼‰ã€‚ | å¯è¿æ¥ä»»æ„ API æ¥å£å‹ LLMï¼Œçµæ´»é›†æˆã€‚ |
| **æ¡†æ¶å…¼å®¹æ€§** | é«˜åº¦å…¼å®¹ LangChain/LangSmith/MemoryStore ç­‰ç”Ÿæ€ç»„ä»¶ã€‚ | å¯ä¸å‘é‡æ•°æ®åº“ã€å·¥å…·é“¾ï¼ˆllama_hubï¼‰é…åˆä½¿ç”¨ã€‚ | ä¸ FastAPIã€æ•°æ®åº“ã€æ¶ˆæ¯é˜Ÿåˆ—ç­‰åç«¯æœåŠ¡é›†æˆç´§å¯†ã€‚ | Python/.NET é€šç”¨ï¼ŒStudio å¯è§†åŒ–æ¥å…¥å¤šå¹³å°ã€‚ | ä¸ Python åŸç”Ÿç”Ÿæ€å…¼å®¹ï¼Œæ˜“æ¥å…¥æ—¥å¿—ã€ç¼“å­˜ä¸æ•°æ®å¹³å°ã€‚ |
| **DevOps éƒ¨ç½²èƒ½åŠ›** | å¯æœ¬åœ°éƒ¨ç½²æˆ–ä½¿ç”¨å¹³å°ç‰ˆï¼›æ”¯æŒ Docker/K8sï¼Œä¾¿äºé›†æˆ CI/CDã€‚ | æ”¯æŒå®¹å™¨åŒ–éƒ¨ç½²ï¼Œæ—  SaaS æ”¯æŒï¼›éœ€æ‰‹åŠ¨é…ç½®ç”Ÿäº§ç¯å¢ƒã€‚ | å¯å¿«é€ŸåµŒå…¥æœåŠ¡ç«¯ï¼›æ”¯æŒ REST æ¥å£æš´éœ²ä¸å®¹å™¨åŒ–éƒ¨ç½²ã€‚ | Python åŒ…å½¢å¼éƒ¨ç½²ï¼›Studio UI æ”¯æŒæœåŠ¡å™¨æ‰˜ç®¡ã€‚ | ä¼ä¸šç‰ˆæ”¯æŒé›†ä¸­ç®¡æ§å’Œäº‘éƒ¨ç½²ï¼›å¼€æºç‰ˆæ”¯æŒè„šæœ¬è‡ªåŠ¨éƒ¨ç½²ã€‚ |


---

# LangGraph
## ğŸ”— åŸºæœ¬ä»‹ç»
![langgraph_workflow.png](pictures/langgraph_workflow.png)
LangGraph æ˜¯æ„å»ºåœ¨ LangChain ä¹‹ä¸Šçš„æ‰©å±•åº“ï¼Œæ—¨åœ¨å¢å¼º LangChain Expression Languageï¼ˆLCELï¼‰çš„èƒ½åŠ›ï¼Œå®ƒå¼•å…¥äº†å›¾ç»“æ„ï¼ˆå¦‚æœ‰å‘æ— ç¯å›¾ DAGï¼‰ï¼Œä½¿å¾—å¼€å‘è€…èƒ½å¤Ÿæ›´æ¸…æ™°åœ°å®šä¹‰å’Œç®¡ç†å¤æ‚çš„å·¥ä½œæµï¼ŒåŒ…æ‹¬å¾ªç¯ã€æ¡ä»¶åˆ†æ”¯å’Œå¤šæ™ºèƒ½ä½“åä½œç­‰ã€‚è™½ç„¶ LangGraph çš„ä½¿ç”¨ç›¸è¾ƒäº LCEL æ›´ä¸ºå¤æ‚ï¼Œä½†å®ƒæä¾›äº†æ›´å¼ºçš„æµç¨‹æ§åˆ¶å’ŒçŠ¶æ€ç®¡ç†èƒ½åŠ›ï¼Œé€‚ç”¨äºæ„å»ºéœ€è¦é«˜åº¦å¯æ§æ€§å’Œå¯æ‰©å±•æ€§çš„ AI åº”ç”¨ã€‚

+ **çŠ¶æ€å›¾å»ºæ¨¡**ï¼šé€šè¿‡èŠ‚ç‚¹å’Œè¾¹çš„æ–¹å¼å®šä¹‰åº”ç”¨æµç¨‹ï¼Œå®ç°ç²¾ç»†çš„æµç¨‹æ§åˆ¶ã€‚
+ **æ”¯æŒå¾ªç¯å’Œæ¡ä»¶æµç¨‹**ï¼šå¯æ ¹æ®çŠ¶æ€åŠ¨æ€å†³å®šæ‰§è¡Œè·¯å¾„ï¼Œé€‚åº”å¤æ‚çš„å¯¹è¯å’Œä»»åŠ¡æµç¨‹ã€‚
+ **å¤šä»£ç†åä½œ**ï¼šåè°ƒå¤šä¸ª Chainã€Agentã€Tool ç­‰å…±åŒåä½œå®Œæˆä»»åŠ¡ã€‚
+ **çŠ¶æ€æŒä¹…åŒ–**ï¼šè‡ªåŠ¨ä¿å­˜å’Œç®¡ç†çŠ¶æ€ï¼Œæ”¯æŒæš‚åœå’Œæ¢å¤æ‰§è¡Œï¼Œä¾¿äºå¤„ç†é•¿æ—¶é—´è¿è¡Œçš„å¯¹è¯ã€‚

ä¸åŒäºLangChain çš„çº¿æ€§æµç¨‹ï¼Œ**LangGraph æ˜¯ä¸“ä¸ºæ„å»ºå¤æ‚ã€æœ‰çŠ¶æ€ï¼ˆstatefulï¼‰å·¥ä½œæµè€Œè®¾è®¡çš„å›¾ç»“æ„æ¡†æ¶**ã€‚

LangGraph ä»¥ **å›¾ï¼ˆGraphï¼‰** çš„å½¢å¼ç»„ç»‡å·¥ä½œæµï¼Œå…·å¤‡å¦‚ä¸‹å…³é”®ç‰¹æ€§ï¼š

+ **Nodeï¼ˆèŠ‚ç‚¹ï¼‰**ï¼šä»£è¡¨å·¥ä½œæµä¸­çš„æ“ä½œæ­¥éª¤ï¼Œå¦‚ LLM è°ƒç”¨ã€API è¯·æ±‚ã€å·¥å…·æ‰§è¡Œç­‰ã€‚
+ **Edgeï¼ˆè¾¹ï¼‰** ä¸ **Conditional Edgeï¼ˆæ¡ä»¶è¾¹ï¼‰**ï¼šå®šä¹‰èŠ‚ç‚¹é—´çš„ä¿¡æ¯æµå‘ã€‚æ¡ä»¶è¾¹å…è®¸å¼€å‘è€…åŸºäºçŠ¶æ€é€»è¾‘å®ç°åŠ¨æ€åˆ†æ”¯æ§åˆ¶ã€‚
+ **Stateï¼ˆçŠ¶æ€ï¼‰**ï¼šç”±å¼€å‘è€…å®šä¹‰çš„ TypedDict å¯¹è±¡ï¼Œè®°å½•å½“å‰æ‰§è¡Œå›¾çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚LangGraph åœ¨æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåè‡ªåŠ¨æ›´æ–°çŠ¶æ€ï¼Œç¡®ä¿ç³»ç»Ÿå…·å¤‡è¿ç»­æ€§å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ã€‚
+ **å¾ªç¯ä¸åé¦ˆæœºåˆ¶ï¼ˆCyclical Graphsï¼‰**ï¼šå›¾ç»“æ„æ”¯æŒå›ç¯è·¯å¾„ï¼Œå¯å®ç°ä»»åŠ¡é‡è¯•ã€ç»“æœåé¦ˆã€çŠ¶æ€å›æº¯ç­‰é«˜çº§æ§åˆ¶æµã€‚

> _å®˜æ–¹å‚è€ƒ_ï¼š[Langraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/) æ–‡æ¡£ï¼Œ[Langgraph GitHub](about:blank)ã€‚
>

## ğŸ”— æ¡†æ¶è¯„æµ‹
### ä½¿ç”¨è¯´æ˜
#### ğŸ“Œ ç®€å•é“¾å¼æ–¹å¼ï¼š
å¯¹äºå¯ä»¥è½»æ¾ã€å¹²å‡€åœ°å°†ä»»åŠ¡åˆ†è§£ä¸ºå›ºå®šå­ä»»åŠ¡çš„æƒ…å†µï¼ŒLangGraphå¯ä»¥é€šè¿‡é“¾å¼æ–¹å¼ç®€å•å®ç°ï¼š

```python
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END

# Define the pipeline state
class PipelineState(TypedDict):
    pdf_path: str
    raw_content: str
    parsed_content: dict
    summarized_content: str
    persist_status: str

# Node: Load PDF
def load_pdf(state: PipelineState):
    """Simulate loading a PDF file."""
    pdf_path = state["pdf_path"]
    return {"raw_content": f"Simulated raw content from {pdf_path}"}

# Node: Parse document
def parse_document(state: PipelineState):
    """Simulate parsing the loaded document."""
    raw_content = state["raw_content"]
    parsed_content = {...}
    return {"parsed_content": parsed_content}

# Node: Summarize text using LLM
def summarize_text(state: PipelineState):
    """Simulate summarizing the parsed content via LLM."""
    parsed_content = state["parsed_content"]
    summarized_text = "Summary: AI applications in various industries."
    return {"summarized_content": summarized_text}

# Node: Persist results into a database
def persist_to_db(state: PipelineState):
    """Simulate writing summarized content to the database."""
    summarized_content = state["summarized_content"]
    return {"persist_status": "success"}

# Build the workflow graph
workflow = StateGraph(PipelineState)

# Add nodes
workflow.add_node("load_pdf", load_pdf)
workflow.add_node("parse_document", parse_document)
workflow.add_node("summarize_text", summarize_text)
workflow.add_node("persist_to_db", persist_to_db)

# Add edges between nodes
workflow.add_edge(START, "load_pdf")
workflow.add_edge("load_pdf", "parse_document")
workflow.add_edge("parse_document", "summarize_text")
workflow.add_edge("summarize_text", "persist_to_db")
workflow.add_edge("persist_to_db", END)

# Compile the graph into a runnable chain
chain = workflow.compile()

# Execute the workflow
if __name__ == "__main__":
    init_state = {"pdf_path": "upload/pdf/ai_for_everyone.pdf"}
    final_state = chain.invoke(init_state)

    print("--- Pipeline Execution Result ---")
    for key, value in final_state.items():
        print(f"{key}: {value}")

# --- Pipeline Execution Result ---
# pdf_path: upload/pdf/ai_for_everyone.pdf
# raw_content: Simulated raw content from upload/pdf/ai_for_everyone.pdf
# parsed_content: {'metadata': {'title': 'AI for Everyone'}, 'text_chunks':{}...}
# summarized_content: Summary: AI applications in various industries.
# persist_status: success

```

### çŠ¶æ€ç®¡ç†ï¼ˆState Managementï¼‰
#### ğŸ“Œ LangGraphçš„ä¸€å¤§ç‰¹ç‚¹æ˜¯StateGraphï¼Œå…·å¤‡å¦‚ä¸‹å…³é”®ç»“æ„ï¼š
+ **Nodeï¼ˆèŠ‚ç‚¹ï¼‰**ï¼šä»£è¡¨å·¥ä½œæµä¸­çš„æ“ä½œæ­¥éª¤ï¼Œå¦‚ LLM è°ƒç”¨ã€API è¯·æ±‚ã€å·¥å…·æ‰§è¡Œç­‰ã€‚
+ **Edgeï¼ˆè¾¹ï¼‰** ä¸ **Conditional Edgeï¼ˆæ¡ä»¶è¾¹ï¼‰**ï¼šå®šä¹‰èŠ‚ç‚¹é—´çš„ä¿¡æ¯æµå‘ã€‚æ¡ä»¶è¾¹å…è®¸å¼€å‘è€…åŸºäºçŠ¶æ€é€»è¾‘å®ç°åŠ¨æ€åˆ†æ”¯æ§åˆ¶ã€‚
+ **Stateï¼ˆçŠ¶æ€ï¼‰**æ˜¯ç”±å¼€å‘è€…å®šä¹‰çš„ TypedDict å¯¹è±¡ï¼Œè®°å½•å½“å‰æ‰§è¡Œå›¾çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œstate<font style="color:rgb(25, 27, 31);">ä¼šåœ¨æ¯ä¸€ä¸ªNodeä¹‹é—´ä¼ é€’ä¸åŒçš„çŠ¶æ€ä¿¡æ¯ã€‚ç„¶åæ¯ä¸€ä¸ªèŠ‚ç‚¹ä¼šæ ¹æ®è‡ªå·±å®šä¹‰çš„é€»è¾‘å»æ›´æ–°è¿™ä¸ªçŠ¶æ€ä¿¡æ¯</font>ã€‚å¯ä»¥ä½¿ç”¨ `TypedDict`ã€`Pydantic` æ¨¡å‹æˆ– `dataclass` æ¥å®šä¹‰çŠ¶æ€ç»“æ„ã€‚

> ğŸ’¡ <font style="color:rgba(0, 0, 0, 0.87);">é»˜è®¤æƒ…å†µä¸‹ï¼Œ`StateGraph`<font style="color:rgba(0, 0, 0, 0.87);"> ä½¿ç”¨å•ä¸ª`state schema` è¿è¡Œï¼Œå¹¶ä¸”æ‰€æœ‰èŠ‚ç‚¹éƒ½åº”ä½¿ç”¨è¯¥ schema è¿›è¡Œé€šä¿¡ã€‚ä½†æ˜¯ï¼Œä¹Ÿå¯ä»¥ä¸º </font><font style="color:rgb(54, 70, 78);background-color:rgb(245, 245, 245);">StateGraph </font><font style="color:rgba(0, 0, 0, 0.87);">å®šä¹‰ä¸åŒçš„</font>`InputState`å’Œ`OutputState`<font style="color:rgb(168, 70, 185);background-color:rgb(245, 245, 245);"> </font><font style="color:rgba(0, 0, 0, 0.87);">schemaã€‚</font>
>

#### ğŸ“Œ State ä¸­çš„æ¯ä¸ª key éƒ½å¯ä»¥æœ‰è‡ªå·±ç‹¬ç«‹çš„ reducer å‡½æ•°ï¼Œè¯¥å‡½æ•°æ§åˆ¶å¦‚ä½•åº”ç”¨æ¥è‡ªèŠ‚ç‚¹çš„æ›´æ–°ã€‚
+ å¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®š reducer å‡½æ•°ï¼Œåˆ™é»˜è®¤å¯¹ key çš„æ‰€æœ‰æ›´æ–°éƒ½åº”è¯¥è¦†ç›–å®ƒã€‚æ¯”å¦‚ä»¥ä¸‹ç¤ºä¾‹é€šè¿‡ç»™ `parsed_chunks` å­—æ®µåŠ ä¸Š `append_chunks` reducerï¼Œæ¯æ¬¡èŠ‚ç‚¹è¿”å›æ–°çš„æ–‡æœ¬ç‰‡æ®µæ—¶ï¼Œç³»ç»Ÿä¼š**è‡ªåŠ¨ç´¯ç§¯**åˆ°å½“å‰ State ä¸­ï¼Œæ— éœ€æ¯ä¸ªèŠ‚ç‚¹æ‰‹åŠ¨ç®¡ç† merge é€»è¾‘ï¼Œ ä¿è¯äº†**æ•°æ®å¤„ç†çš„ä¸€è‡´æ€§**ã€‚

```python
class State(TypedDict):
    parsed_chunks: Annotated[list[str], append_chunks]
    metadata: dict

def append_chunks(left, right):
    """Append two lists of parsed text chunks."""
    return left + right

def parse_document(state:State):
    """Mock parsing a document and returning new chunks."""
    new_chunks = ["This is a new paragraph extracted."]
    return {"parsed_chunks": new_chunks, "metadata": {"source": "upload/pdf/ai_for_everyone.pdf"}}

# Build the graph
graph = StateGraph(ExtractState)
graph.add_node("parse_document", parse_document)
graph.add_edge(START, "parse_document")

# Compile the graph
chain = graph.compile()

# Invoke the chain with an initial parsed chunk
initial_state = {"parsed_chunks": ["Introduction to AI..."], "metadata": {}}
result = chain.invoke(initial_state)

# Output
print("Accumulated parsed chunks:")
for idx, chunk in enumerate(result["parsed_chunks"], start=1):
    print(f"{idx}. {chunk}")

# =================================
# Accumulated parsed chunks:
# 1. Introduction to AI...
# 2. This is a new paragraph extracted.
# =================================
```

### ç»†ç²’åº¦æ§åˆ¶ï¼ˆControl Granularityï¼‰
#### ğŸ“Œ åŸºæœ¬ä½¿ç”¨æ–¹å¼
åœ¨åŸºäº **LangGraph** çš„æµç¨‹ç®¡ç†ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥éå¸¸çµæ´»åœ°æ§åˆ¶èŠ‚ç‚¹æ‰§è¡Œçš„ç²’åº¦ï¼ŒLangGraphåŸç”Ÿæ”¯æŒå¹¶è¡Œæ‰§è¡Œå¤šä¸ªèŠ‚ç‚¹ï¼Œ è¿˜å¯ä»¥å®ç°**ç»“æœèšåˆ**ï¼ˆfan-inï¼‰ä¸**æ¡ä»¶åˆ†æ”¯**ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›åŸºæœ¬ä½¿ç”¨æ–¹å¼ï¼š 

+ **fan-out**ï¼šä¸€ä¸ªèŠ‚ç‚¹æ‰§è¡Œåï¼Œå¯ä»¥å¹¶å‘åœ°å¯åŠ¨å¤šä¸ªå­èŠ‚ç‚¹ã€‚
+ **fan-in**ï¼šå­èŠ‚ç‚¹å…¨éƒ¨å®Œæˆåï¼Œç»Ÿä¸€è¿›å…¥ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚
+ **Reducer**ï¼šç”¨äºåˆå¹¶å¤šä¸ªå¹¶å‘èŠ‚ç‚¹å¯¹åŒä¸€ State å­—æ®µçš„æ›´æ–°ï¼ˆå¦‚ç´¯ç§¯åˆ—è¡¨ï¼‰ã€‚
+ **Conditional Branch**ï¼šåŸºäº State ä¸­çš„æ¡ä»¶å­—æ®µåŠ¨æ€å†³å®šåˆ†æ”¯è·¯å¾„ã€‚åˆ›å»ºå¾ªç¯æ—¶ï¼Œå¯ä»¥åŒ…å«æŒ‡å®šç»ˆæ­¢æ¡ä»¶çš„æ¡ä»¶è¾¹ã€‚ï¼ˆä¹Ÿå¯ä»¥ä½¿ç”¨<font style="color:rgb(54, 70, 78);background-color:rgb(245, 245, 245);">Command</font>å¯¹è±¡æ¥æ§åˆ¶èŠ‚ç‚¹è·¯ç”±ï¼Œæ­¤æ—¶æ— éœ€æ˜¾å¼å¢åŠ è¾¹ï¼‰
+ **Loop & Termination**ï¼šæ”¯æŒåœ¨å›¾ä¸­åˆ›å»ºå¾ªç¯ï¼Œé€šè¿‡æ¡ä»¶è¾¹æ§åˆ¶ç»ˆæ­¢ï¼ŒåŒæ—¶å¯è®¾ç½® recursion_limit æ¬¡æ•°é˜²æ­¢æ— é™å¾ªç¯å¹¶æŠ›å‡º<font style="color:rgb(54, 70, 78);background-color:rgb(245, 245, 245);">GraphRecursionError</font>ã€‚

```python
from langgraph.graph import StateGraph, START, END
from langgraph.errors import GraphRecursionError
from typing import Annotated, Sequence
import operator
from typing_extensions import TypedDict

# Define the State
class State(TypedDict):
    body_chunks: Annotated[list[str], operator.add]
    table_chunks: Annotated[list[str], operator.add]
    language: str
    retry_count: int 

# Define Nodes
def load_pdf(state: State):
    print("Loading PDF...")

def extract_body_chinese(state: State):
    print("Extracting Chinese body text...")
    return {"body_chunks": ["ä¸­æ–‡æ®µè½"]}

def extract_body_english(state: State):
    print("Extracting English body text...")
    return {"body_chunks": ["English paragraph"]}

def extract_table(state: State):
    print("Extracting table of contents...")
    return {"table_chunks": ["ç›®å½•å†…å®¹"]}

def merge_results(state: State):
    print(f"Merged Body Chunks: {state['body_chunks']}")
    print(f"Merged Table Chunks: {state['table_chunks']}")

# Branching
def route_body_extraction(state: State) -> Sequence[str]:
    if state["language"] == "zh":
        return ["extract_body_chinese", "extract_table"]
    else:
        return ["extract_body_english", "extract_table"]

# Loop Control
def check_retry(state: State):
    if state["retry_count"] <= 0:
        return END
    else:
        return {"retry_count": state["retry_count"] - 1}

# Build the Graph
builder = StateGraph(State)

# Add nodes
builder.add_node(load_pdf)
builder.add_node(extract_body_chinese)
builder.add_node(extract_body_english)
builder.add_node(extract_table)
builder.add_node(merge_results)

# Add edges
builder.add_edge(START, "load_pdf")
builder.add_conditional_edges("load_pdf", route_body_extraction, ["extract_body_chinese", "extract_body_english", "extract_table"])
builder.add_edge(["extract_body_chinese", "extract_body_english", "extract_table"], "merge_results")
builder.add_conditional_edges("merge_results", lambda state: END if state["retry_count"] <= 0 else "load_pdf", [END, "load_pdf"])

# Compile
graph = builder.compile()

# Run with recursion_limit to avoid infinite loop
try:
    result = graph.invoke(
        {"body_chunks": [], "table_chunks": [], "language": "zh", "retry_count": 2},
        config={"recursion_limit": 5}  
    )
    print(result)
except GraphRecursionError:
    print("Exceeded maximum recursion limit. Returning last known state.")
```

> ğŸ’¡ æ³¨æ„ç‚¹ï¼š 
>
> 1. éœ€è¦è€ƒè™‘**Error Handling**ï¼Œ èŠ‚ç‚¹ä¹‹é—´ fan-out åï¼Œå¦‚æœæŸä¸ªèŠ‚ç‚¹å¼‚å¸¸å´©äº†ï¼Œ å½“å‰æ¡†æ¶æ²¡æœ‰æœºåˆ¶å¤„ç†å¼‚å¸¸ï¼Œä¼šå¯¼è‡´æ•´ä¸ª pipeline ä¸­æ–­ã€‚  
> 2. å®é™…åº”ç”¨å¯èƒ½éœ€è¦è€ƒè™‘ä¼˜å…ˆçº§è°ƒåº¦ã€‚
>

#### ğŸ“Œ å¹¶è¡Œæ‰§è¡Œ
**Super-Stepæ¦‚å¿µ**

LangGraph çš„æ‰§è¡Œæ¨¡å‹åŸºäº **super-step**ã€‚ä¸€ä¸ª super-step å¯ä»¥è¢«è®¤ä¸ºæ˜¯å›¾ä¸­çš„ä¸€æ¬¡è¿­ä»£ï¼Œæ‰€æœ‰å¹¶è¡Œæ‰§è¡Œçš„èŠ‚ç‚¹éƒ½å±äºåŒä¸€ä¸ª super-stepï¼Œè€Œé¡ºåºæ‰§è¡Œçš„èŠ‚ç‚¹åˆ™ä¼šè¢«åˆ†é…åˆ°ä¸åŒçš„ super-stepã€‚<font style="color:rgb(51, 65, 85);">è¿™æ¯å½“å›¾è¿è¡Œæ—¶ï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½å¤„äºä¸€ä¸ª</font>`inactive`<font style="color:rgb(51, 65, 85);">çŠ¶æ€ã€‚æ¯å½“ä¼ å…¥è¾¹æ”¶åˆ°æ–°æ¶ˆæ¯ï¼ˆçŠ¶æ€ï¼‰æ—¶ï¼Œè¯¥èŠ‚ç‚¹å˜ä¸º`active`<font style="color:rgb(51, 65, 85);">ï¼Œè¿è¡Œå‡½æ•°å¹¶è¿›è¡Œæ›´æ–°å“åº”ã€‚åœ¨æ¯ä¸ª super-stepç»“æŸæ—¶ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½ä¼š</font>`halt`<font style="color:rgb(51, 65, 85);">é€šè¿‡å°†è‡ªå·±æ ‡è®°ä¸º</font>`inactive`<font style="color:rgb(51, 65, 85);">ä¸å†æœ‰ä¼ å…¥æ¶ˆæ¯æ¥æŠ•ç¥¨ã€‚å½“æ‰€æœ‰èŠ‚ç‚¹éƒ½`inactive`<font style="color:rgb(51, 65, 85);">ä¸”æ²¡æœ‰æ¶ˆæ¯åœ¨ä¼ è¾“æ—¶ï¼Œå›¾ç»ˆæ­¢ã€‚</font>

+ **å¹¶è¡Œæ‰§è¡Œ**<font style="color:rgb(25, 27, 31);">ï¼š</font>**<font style="color:rgb(25, 27, 31);">å½“å¤šä¸ªèŠ‚ç‚¹åœ¨åŒä¸€ä¸ª super-step ä¸­æ‰§è¡Œæ—¶ï¼Œå®ƒä»¬ä¼šå¹¶è¡Œè¿è¡Œ</font>**<font style="color:rgb(25, 27, 31);">ã€‚æ¯”å¦‚ï¼Œå½“èŠ‚ç‚¹ </font>`a`<font style="color:rgb(25, 27, 31);"> ä¹‹åæœ‰ä¸¤ä¸ªèŠ‚ç‚¹ </font>`b`<font style="color:rgb(25, 27, 31);"> å’Œ </font>`c`<font style="color:rgb(25, 27, 31);">ï¼Œå®ƒä»¬å¯ä»¥å¹¶è¡Œæ‰§è¡Œã€‚</font>
+ **é¡ºåºæ‰§è¡Œ**<font style="color:rgb(25, 27, 31);">ï¼š</font>**<font style="color:rgb(25, 27, 31);">å½“ä¸€ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œä¾èµ–äºå¤šä¸ªå…¶ä»–èŠ‚ç‚¹çš„å®Œæˆæ—¶ï¼Œå¿…é¡»ç­‰å¾…è¿™äº›èŠ‚ç‚¹çš„æ‰§è¡Œç»“æœ</font>**<font style="color:rgb(25, 27, 31);">ã€‚æ¯”å¦‚ï¼Œå¦‚æœèŠ‚ç‚¹ </font>`d`<font style="color:rgb(25, 27, 31);"> ä¾èµ–äºèŠ‚ç‚¹ `b2`<font style="color:rgb(25, 27, 31);"> å’Œ </font>`c`<font style="color:rgb(25, 27, 31);">ï¼Œåˆ™ </font>`d`<font style="color:rgb(25, 27, 31);"> ä¼šåœ¨ </font>`b2`<font style="color:rgb(25, 27, 31);"> å’Œ </font>`c`<font style="color:rgb(25, 27, 31);"> éƒ½å®Œæˆä¹‹åæ‰§è¡Œã€‚</font>

<div style="text-align: center;">
  <img src="pictures/workflow_sample.png" alt="Workflow Sample">
</div>

> ğŸ’¡å¯¹äºä¸Šè¿°æƒ…å†µï¼Œ`b`ã€`c`åŒå±ä¸€ä¸ª`super step`ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨<font style="color:rgba(0, 0, 0, 0.87);"> </font>`add_edge([â€œb_2â€, â€œcâ€], â€œdâ€)`<font style="color:rgba(0, 0, 0, 0.87);"> æ¥å¼ºåˆ¶èŠ‚ç‚¹ </font>`â€œdâ€`<font style="color:rgba(0, 0, 0, 0.87);"> ä»…åœ¨èŠ‚ç‚¹ </font>`â€œb_2â€`<font style="color:rgba(0, 0, 0, 0.87);"> å’Œ </font>`â€œcâ€`<font style="color:rgba(0, 0, 0, 0.87);"> éƒ½å®Œæˆæ‰§è¡Œæ—¶è¿è¡Œã€‚å¦åˆ™å¦‚æœåˆ†åˆ«åŠ ä¸¤æ¡è¾¹ï¼Œä¼šå¯¼è‡´`d`æ‰§è¡Œä¸¤æ¬¡</font>
>

**Map-Reduceå¹¶è¡Œ**

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦ï¼šé’ˆå¯¹ä¸€æ‰¹å­ä»»åŠ¡ï¼ˆå¦‚ï¼šæ–‡æœ¬å—ã€æ–‡æ¡£æ®µè½ã€å›¾ç‰‡ï¼‰ï¼Œå¹¶è¡Œå¤„ç†ï¼Œå¹¶æœ€ç»ˆåˆå¹¶ç»“æœï¼Œæ¯”å¦‚ å¯¹ä¸€ä»½å¤§æ–‡æ¡£çš„å¤šä¸ªéƒ¨åˆ†åˆ†åˆ«æ€»ç»“ï¼ˆæ¯ä¸€å—æ–‡æœ¬ -> summaryï¼‰ï¼Œ è¿™ç§éœ€æ±‚å¤©ç„¶ç¬¦åˆ **Map-Reduce** æ¨¡å¼ã€‚ç„¶è€Œé¢ä¸´çš„ä¸¤ä¸ªé—®é¢˜æ˜¯ ï¼š

+ æµç¨‹è®¾è®¡æ—¶æ— æ³•æå‰çŸ¥é“ä¸€å…±å¤šå°‘å—æ–‡æœ¬è¦å¤„ç†ï¼ˆæ•°é‡æ˜¯åŠ¨æ€çš„ï¼‰ 
+ æ¯ä¸ªå­èŠ‚ç‚¹åº”è¯¥åªå¤„ç†å±äºè‡ªå·±çš„ chunkï¼Œä¸èƒ½å…±äº«æ•´ä½“ State  

å¯¹æ­¤ï¼ŒLangGraph æä¾›äº† `Send` APIï¼Œå®ƒå…è®¸ï¼š

+ åœ¨è¿è¡Œæ—¶ **åŠ¨æ€åˆ›å»ºå­èŠ‚ç‚¹ä»»åŠ¡**
+ **ç»™æ¯ä¸ªå­ä»»åŠ¡åˆ†å‘ä¸åŒçš„ State**

```python
Send("target_node_name", {"key": value})   
```

å…¶ä¸­ï¼š

+ `"target_node_name"` æ˜¯è¦å‘å¾€çš„èŠ‚ç‚¹
+ `{"key": value}` æ˜¯æ–°çš„ã€å­ä»»åŠ¡ç‰¹æœ‰çš„è¾“å…¥ State

è¿™æ ·å°±å¯ä»¥éå¸¸çµæ´»åœ°å¤„ç† **åŠ¨æ€æ•°é‡ + ç‹¬ç«‹ State** çš„å­ä»»åŠ¡ï¼Œå¦‚ä¸‹ç¤ºä¾‹æ‰€ç¤ºï¼š

```python
from langgraph.types import Send

# Define the overall state
class OverallState(TypedDict):
    chunks: list[str]
    summaries: Annotated[list[str], operator.add]

# Define the dispatch logic using Send API
def dispatch_chunks(state: OverallState):
    return [Send("summarize_chunk", {"chunk": chunk}) for chunk in state["chunks"]]

# Define the node to summarize a single chunk
def summarize_chunk(state: OverallState):
    return {"summaries": [f"Summary of: {state['chunk'][:10]}..."]}

# Build the graph
builder = StateGraph(OverallState)
builder.add_node("summarize_chunk", summarize_chunk)
builder.add_conditional_edges(START, dispatch_chunks)
builder.add_edge("summarize_chunk", END)
graph = builder.compile()

# Run the graph
output = graph.invoke({"chunks": ["This is the first part.", "This is the second part."]})
print(output)

```

#### ğŸ“Œ èŠ‚ç‚¹é‡è¯•ç­–ç•¥
 LangGraph å¼•å…¥äº†èŠ‚ç‚¹çº§çš„** RetryPolicy **ã€‚  <font style="color:rgba(0, 0, 0, 0.87);">å¯ä»¥åœ¨è°ƒç”¨</font>`add_node`<font style="color:rgba(0, 0, 0, 0.87);">å‡½æ•°æ—¶ä¼ é€’ </font>`RetryPolicy`<font style="color:rgba(0, 0, 0, 0.87);"> å¯¹è±¡</font>

```python
from langgraph.pregel import RetryPolicy

RetryPolicy()
RetryPolicy(initial_interval=0.5, backoff_factor=2.0, max_interval=128.0, max_attempts=3, jitter=True, retry_on=<function default_retry_on at 0x78b964b89940>)

# Define a new graph
builder = StateGraph(AgentState)
builder.add_node("model", call_model, retry=RetryPolicy(max_attempts=5))
```

#### ğŸ“Œ å¦‚ä½•åœ¨è¾¾åˆ°é€’å½’é™åˆ¶å‰è¿”å›State
åœ¨å¤æ‚æµç¨‹ä¸­ï¼Œå›¾ï¼ˆGraphï¼‰å¯èƒ½å› ä¸ºå¾ªç¯è°ƒç”¨æˆ–æ·±åº¦åµŒå¥—ï¼Œæ„å¤–è¾¾åˆ°é€’å½’é™åˆ¶ (`GraphRecursionError`)ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¶…é™ç›´æ¥æŠ¥é”™ï¼Œå¯¼è‡´åº”ç”¨ä½“éªŒä¸ä½³ã€‚ä¸ºæ­¤ï¼ŒLangGraph å¼•å…¥äº† `RemainingSteps` æœºåˆ¶ã€‚  

**é€šè¿‡åœ¨ **`**State**`** ç±»å‹ä¸­åŠ ä¸Š **`**RemainingSteps**`** æ³¨è§£ï¼Œæ¡†æ¶ä¼šè‡ªåŠ¨ä¸ºä½ ç®¡ç†é€’å½’æ·±åº¦ã€‚LangGraph ä¼šä¸ºæ¯æ¬¡å›¾çš„æ‰§è¡Œåˆ›å»ºå¹¶é€’å‡ **`**remaining_steps**`**ï¼Œå®ƒè·Ÿè¸ªå½“å‰æ‰§è¡Œåˆ°å“ªä¸€æ­¥ï¼Œä»¥åŠè¿˜éœ€è¦æ‰§è¡Œå¤šå°‘æ¬¡ã€‚  **

```python
class State(TypedDict):
    value: str
    action_result: str
    remaining_steps: RemainingSteps
```

### å¼‚æ­¥æ‰§è¡Œï¼ˆAsynchronouslyï¼‰
<font style="color:rgba(0, 0, 0, 0.87);">åœ¨å¹¶å‘è¿è¡Œioç»‘å®šä»£ç æ—¶ï¼ˆä¾‹å¦‚ï¼Œå‘èŠå¤©æ¨¡å‹æä¾›å•†å‘å‡ºå¹¶å‘ API è¯·æ±‚ï¼‰ï¼Œä½¿ç”¨å¼‚æ­¥æ–¹å¼å¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½ã€‚</font>

è¦å°†åŒæ­¥æ”¹ä¸ºå¼‚æ­¥ï¼Œåªéœ€è¦ï¼š

+ <font style="color:rgba(0, 0, 0, 0.87);">å°†èŠ‚ç‚¹å‡½æ•°ä» </font>`def`<font style="color:rgba(0, 0, 0, 0.87);"> ä¿®æ”¹ä¸º </font>`async def`<font style="color:rgba(0, 0, 0, 0.87);">ï¼›</font>
+ <font style="color:rgba(0, 0, 0, 0.87);">åœ¨èŠ‚ç‚¹å†…éƒ¨æ­£ç¡®ä½¿ç”¨ </font>`await`<font style="color:rgba(0, 0, 0, 0.87);">ï¼›</font>

<font style="color:rgba(0, 0, 0, 0.87);">ç”±äºè®¸å¤š LangChain å¯¹è±¡éµå¾ª Runnable åè®®ï¼Œä¸”åŒæ­¥æ–¹æ³•é€šå¸¸éƒ½æœ‰å¯¹åº”çš„å¼‚æ­¥ç‰ˆæœ¬ï¼Œå› æ­¤æ•´ä½“è¿ç§»è¿‡ç¨‹é€šå¸¸è¾ƒä¸ºç®€å•ã€‚</font>

```python
async def call_model(state: State):
    messages = state["messages"]
    response = await model.ainvoke(messages)
    return {"messages": [response]}
    
from langchain_core.messages import HumanMessage
async def main():
    inputs = {"messages": [HumanMessage(content="what is the keywords in this text")]}
    # Streaming Node Output
    async for output in graph.astream(inputs, stream_mode="updates"):
        # stream_mode="updates" yields dictionaries with output keyed by node name
        for key, value in output.items():
            print(f"Output from node '{key}':")
            print(value["messages"][-1].pretty_print())
```

### åˆ†å¸ƒå¼æ”¯æŒ
<font style="color:rgb(25, 27, 31);">Langgraphæ”¯æŒå°†æ™ºèƒ½ä½“çš„ä»»åŠ¡åˆ†é…åˆ°å¤šä¸ªè®¡ç®—èŠ‚ç‚¹æˆ–çº¿ç¨‹ä¸ŠåŒæ—¶æ‰§è¡Œã€‚</font>

<font style="color:rgb(25, 27, 31);">ä»¥rayä¸ºä¾‹ï¼Œå’Œrayé›†æˆç®€å•çš„æ–¹å¼ï¼š</font>

+ <font style="color:rgb(25, 27, 31);"></font>**å°è£…StateGraphçš„Actorç±»**<font style="color:rgb(25, 27, 31);">ã€‚</font>
+ <font style="color:rgb(25, 27, 31);"></font>**ç”¨ **`**@ray.remote**`** æ³¨å†ŒæˆActor**<font style="color:rgb(25, 27, 31);">ã€‚</font>
+ <font style="color:rgb(25, 27, 31);"></font>**åœ¨ä¸»ç¨‹åºï¼ˆDriverï¼‰é‡Œï¼Œè°ƒç”¨ **`**GraphActor.remote()**`** å®ä¾‹åŒ–**<font style="color:rgb(25, 27, 31);">ã€‚</font>
+ **Rayåœ¨é›†ç¾¤é‡Œè°ƒåº¦workerè¿›ç¨‹ï¼Œä¸“é—¨è·‘è¿™ä¸ªActorå®ä¾‹**<font style="color:rgb(25, 27, 31);">ã€‚</font>
+ **å¼‚æ­¥è¿œç¨‹è°ƒç”¨Actoræ–¹æ³•**<font style="color:rgb(25, 27, 31);">ï¼Œå„ä¸ªActor</font>**ç‹¬ç«‹ã€å¹¶å‘ã€åˆ†å¸ƒå¼æ‰§è¡Œ**<font style="color:rgb(25, 27, 31);">ã€‚</font>

ä»£ç ç¤ºä¾‹ï¼š

```python
import ray
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, List
import asyncio

# Initialize Ray
ray.init(ignore_reinit_error=True)

# Define the state type for langgraph
class SimpleState(TypedDict):
    message_list: List[str]

# Node function
def add_message(state: SimpleState):
    state["message_list"].append("New message")
    print(f"Node executed, current message list: {state['message_list']}")
    return state

# Ray Actor class to encapsulate StateGraph
@ray.remote(num_cpus=1)  # Each Actor uses 1 CPU
class GraphActor:
    def __init__(self):
        # Initialize StateGraph and add node
        self.graph = StateGraph(SimpleState)
        self.graph.add_node("add_node", add_message)
        self.graph.set_entry_point("add_node")
        self.compiled_graph = self.graph.compile()

    async def execute(self, initial_state):
        # Execute the compiled graph
        return await self.compiled_graph.ainvoke(initial_state)

# Create and run multiple GraphActor
async def create_and_run_graphs(num_workers=4):
    # Create multiple GraphActors
    graph_actors = [GraphActor.remote() for _ in range(num_workers)]

    # Prepare initial state for each worker
    initial_states = [{"message_list": []} for _ in range(num_workers)]

    # Submit all execution tasks
    exec_tasks = [actor.execute.remote(state) for actor, state in zip(graph_actors, initial_states)]

    # Wait for all tasks to complete
    results = await asyncio.gather(*[asyncio.to_thread(ray.get, task) for task in exec_tasks])

    # Print results for each worker
    for idx, result in enumerate(results):
        print(f"Worker {idx} result: {result['message_list']}")

# Start the test
if __name__ == "__main__":
    asyncio.run(create_and_run_graphs(num_workers=4))  # Change num_workers as needed
    ray.shutdown()


```

### **æµå¼è¾“å‡ºï¼ˆStreaming Outputï¼‰**
#### ğŸ“Œä¸åŒæµå¼è¾“å‡ºæ¨¡å¼
æµå¼å¤„ç†å¯¹äºæå‡åŸºäº LLM æ„å»ºçš„åº”ç”¨å“åº”èƒ½åŠ›è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨å‡å°‘å»¶è¿Ÿæ–¹é¢ã€‚LangGraph æä¾›å¤šç§æµå¼è¾“å‡ºmodeï¼ŒåŒ…æ‹¬ï¼š

1. **values**ï¼šæ¯æ­¥åå‘å‡ºæ‰€æœ‰çŠ¶æ€å€¼ã€‚
2. **updates**ï¼šä»…å‘å‡ºèŠ‚ç‚¹åå’Œæ¯æ­¥æ›´æ–°å†…å®¹ã€‚
3. **custom**ï¼šé€šè¿‡ StreamWriter è‡ªå®šä¹‰æ•°æ®è¾“å‡ºã€‚
4. **messages**ï¼šé€ä¸ªä»¤ç‰Œå‘å‡º LLM æ¶ˆæ¯åŠå…¶å…ƒæ•°æ®ã€‚
5. **debug**ï¼šå‘å‡ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ã€‚

é€šè¿‡ä½¿ç”¨ `graph.stream(..., stream_mode=<stream_mode>)` æ–¹æ³•ï¼Œå¯ä»¥graphæ‰§è¡Œä¸­æµå¼è¿”å›è¾“å‡ºã€‚

```python
# sync
for chunk in graph.stream(inputs, stream_mode=["updates", "custom"]):
    print(chunk)
    
# async
async for chunk in graph.astream(inputs, stream_mode=["updates", "custom"]):
    print(chunk)
```

#### ğŸ“Œ å¼‚æ­¥æµå¼è¾“å‡ºå®ç°åŸç†
`astream` æ–¹æ³•æœ¬èº«è¿”å›ä¸€ä¸ªå¼‚æ­¥è¿­ä»£å™¨ (`AsyncIterator`)  ï¼Œå®ƒåœ¨graphæ‰§è¡Œè¿‡ç¨‹ä¸­é€æ­¥è¾“å‡ºæ•°æ®ã€‚`astream` æ–¹æ³•ä¸­çš„å…³é”®ç»„ä»¶æ˜¯ `AsyncQueue` å’Œ `StreamProtocol`ï¼Œå¹¶ä¸”ä¼šä½¿ç”¨ `async for` å’Œ `asyncio` åº“æ¥æ”¯æŒå¼‚æ­¥æµå¼å¤„ç†ã€‚   

```python
async def astream(
        self,
        input: dict[str, Any] | Any,
        config: RunnableConfig | None = None,
        *,
        stream_mode: StreamMode | list[StreamMode] | None = None,
        output_keys: str | Sequence[str] | None = None,
        interrupt_before: All | Sequence[str] | None = None,
        interrupt_after: All | Sequence[str] | None = None,
        checkpoint_during: bool | None = None,
        debug: bool | None = None,
        subgraphs: bool = False,
    ) -> AsyncIterator[dict[str, Any] | Any]:
```

å…¶ä¸­`AsyncQueue` æ˜¯ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„å¼‚æ­¥é˜Ÿåˆ—ï¼Œå®ƒç”¨äºå­˜å‚¨æµæ•°æ®ã€‚`stream_put` æ˜¯ä¸€ä¸ªå°†æ•°æ®æ”¾å…¥é˜Ÿåˆ—çš„å¼‚æ­¥æ–¹æ³•ï¼Œå®ƒé€šè¿‡ `aioloop.call_soon_threadsafe` æ¥ä¿è¯æ•°æ®è¢«å¼‚æ­¥æ¨é€åˆ°é˜Ÿåˆ—ä¸­

```python
stream = AsyncQueue()
aioloop = asyncio.get_running_loop()
stream_put = cast(
    Callable[[StreamChunk], None],
    partial(aioloop.call_soon_threadsafe, stream.put_nowait),
)
```

#### ğŸ“Œ å¼‚æ­¥æµçš„æ ¸å¿ƒæ­¥éª¤ï¼š
+ æ•°æ®ä¼šé€æ­¥æ”¾å…¥ `stream` é˜Ÿåˆ—ä¸­ã€‚
+ `output()` å‡½æ•°ç”¨äºä» `stream` å¼‚æ­¥é˜Ÿåˆ—é€æ­¥è·å–æ•°æ®ï¼Œå¹¶é€šè¿‡ `yield` è¾“å‡ºè¿™äº›æ•°æ®ã€‚
+ `async for` ä¼šå¼‚æ­¥è·å–è¿™äº›ç»“æœï¼Œç›´åˆ° `stream` é˜Ÿåˆ—ä¸ºç©ºã€‚

```python
def output() -> Iterator:
    while True:
        try:
            ns, mode, payload = stream.get_nowait()
        except asyncio.QueueEmpty:
            break
        if subgraphs and isinstance(stream_mode, list):
            yield (ns, mode, payload)
        elif isinstance(stream_mode, list):
            yield (mode, payload)
        elif subgraphs:
            yield (ns, payload)
        else:
            yield payload

```

#### ğŸ“Œ LLMæµå¼è¾“å‡ºï¼š
ä¸‹é¢æ˜¯ä¸€ä¸ªåœ¨å•ä¸ªèŠ‚ç‚¹ä¸­å…·æœ‰ä¸¤ä¸ªLLMè°ƒç”¨çš„ç¤ºä¾‹ï¼š

```python
from typing import TypedDict
from langgraph.graph import START, StateGraph
from langchain_openai import ChatOpenAI
import asyncio
import os

# Define two model instances with tags for filtering
summary_model = ChatOpenAI(model="gpt-4o-mini", tags=["summary"])
keyword_model = ChatOpenAI(model="gpt-4o-mini", tags=["keyword"])

# Define the state structure
class State(TypedDict):
    text: str
    summary: str
    keywords: str

async def call_model(state, config):
    text = state["text"]
    print("Generating summary...")
    summary_response = await summary_model.ainvoke(
        [{"role": "user", "content": f"Please summarize the following text:\n\n{text}"}],
        config,
    )
    print("\n\nExtracting keywords...")
    keyword_response = await keyword_model.ainvoke(
        [{"role": "user", "content": f"Please extract important keywords from the following text:\n\n{text}"}],
        config,
    )
    return {"summary": summary_response.content, "keywords": keyword_response.content}

graph = StateGraph(State).add_node(call_model).add_edge(START, "call_model").compile()

async def main():
    input_text = (
        "Artificial intelligence (AI) is the simulation of human intelligence processes "
        "by machines, especially computer systems. Specific applications of AI include "
        "expert systems, natural language processing, speech recognition, and machine vision."
    )
    async for msg, metadata in graph.astream(
        {"text": input_text},
        stream_mode="messages",
    ):
        if msg.content:
            print(msg.content, end="|", flush=True)
        #  We can use the streamed metadata and filter events using the tags we've added to the LLMs previously
        # if msg.content and "summary" in metadata.get("tags", []):
        #     print(msg.content, end="|", flush=True)

if __name__ == "__main__":
    asyncio.run(main())

############ Result #############
# Generating summary...
# Art|ificial| intelligence| (AI) involves| machines simulating human| intelligence processes. Key| applications of AI include| expert systems, natural| language processing, speech| recognition, and machine| vision.|

# Extracting keywords...
# Here| are| the| important keywords extracted from| the text:

# -| Artificial intelligence (AI|)  
# - Simulation|  
# - Human intelligence|
# ...

```

### æŒä¹…åŒ–ï¼ˆPersistenceï¼‰
#### ğŸ“Œ çº¿ç¨‹çº§æŒä¹…åŒ–
<font style="color:rgba(0, 0, 0, 0.87);">è®¸</font><font style="color:rgba(0, 0, 0, 0.87);">å¤š AI åº”ç”¨ç¨‹åºéœ€è¦å†…å­˜æ‰èƒ½åœ¨å¤šä¸ªäº¤äº’ä¹‹é—´å…±äº«ä¸Šä¸‹æ–‡ã€‚åœ¨ LangGraph ä¸­ï¼Œå¯ä»¥ä½¿ç”¨çº¿ç¨‹çº§æŒä¹…åŒ–å°†è¿™ç§å†…å­˜æ·»åŠ åˆ°ä»»ä½•StateGraph ä¸­ï¼Œå¯ä»¥é€šè¿‡åœ¨ç¼–è¯‘ Graph æ—¶æ·»åŠ </font>`checkpointer`<font style="color:rgba(0, 0, 0, 0.87);">æ¥è®¾ç½®å®ƒä»¥ä¿æŒå…¶çŠ¶æ€ã€‚</font>

```python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()

def call_model(state: MessagesState):
    response = model.invoke(state["messages"])
    return {"messages": response}

builder = StateGraph(MessagesState)
builder.add_node("call_model", call_model)
builder.add_edge(START, "call_model")
# Enable memory saving during execution
graph = builder.compile(checkpointer=memory)  

input_message = {"role": "user", "content": "hi! I'm Alen"}

# Stream the response with memory saving
for chunk in graph.stream({"messages": [input_message]}, {"configurable": {"thread_id": "1"}}, stream_mode="values"):
    chunk["messages"][-1].pretty_print()

# Send another message in the same thread, using memory to preserve the conversation context
input_message = {"role": "user", "content": "what's my name?"}
for chunk in graph.stream({"messages": [input_message]}, {"configurable": {"thread_id": "1"}}, stream_mode="values"):
    chunk["messages"][-1].pretty_print()

# Send a message in a new thread, demonstrating memory usage across threads
input_message = {"role": "user", "content": "what's my name?"}
for chunk in graph.stream(
    {"messages": [input_message]},
    {"configurable": {"thread_id": "2"}},  # New thread
    stream_mode="values",
):
    chunk["messages"][-1].pretty_print()
    
# ================================ Human Message =================================
# hi! I'm Alen
# ================================== Ai Message ==================================
# Hi Alen! Nice to meet you. How can I assist you today? ğŸ˜Š
# ================================ Human Message =================================
# what's my name?
# ================================== Ai Message ==================================
# Your name is **Alen**! ğŸ˜Š Did I get it right?
# ================================ Human Message =================================
# what's my name?
# ================================== Ai Message ==================================
# I don't have access to specific personal information about you, so I don't know your name. ğŸ˜Š


```

#### ğŸ“Œ è·¨çº¿ç¨‹æŒä¹…åŒ–
<font style="color:rgba(0, 0, 0, 0.87);">å½“ç„¶LangGraph è¿˜æ”¯æŒè·¨</font>**<font style="color:rgba(0, 0, 0, 0.87);">å¤šä¸ªçº¿ç¨‹</font>**<font style="color:rgba(0, 0, 0, 0.87);">æŒä¹…ä¿å­˜æ•°æ®ã€‚æ ¸å¿ƒæ˜¯ä½¿ç”¨</font>`Store`<font style="color:rgba(0, 0, 0, 0.87);"> æ¥å£å­˜å‚¨è·¨çº¿ç¨‹å…±äº«æ•°æ®ï¼ˆå¦‚ç”¨æˆ·åå¥½ï¼‰ã€‚</font>`namespace`ï¼ˆå¦‚ </font>`("memories", user_id)`<font style="color:rgba(0, 0, 0, 0.87);">ï¼‰éš”ç¦»ä¸åŒç”¨æˆ·çš„è®°å¿†ã€‚</font>

#### ğŸ“Œ ä½¿ç”¨Postgres checkpointeræŒä¹…åŒ–
```python
from langgraph.graph import StateGraph

builder = StateGraph(....)
# ... define the graph
checkpointer = # postgres checkpointer 
graph = builder.compile(checkpointer=checkpointer)
```

> ğŸ’¡<font style="color:rgba(0, 0, 0, 0.87);"> éœ€è¦åœ¨ checkpointer ä¸Šè¿è¡Œä¸€æ¬¡ </font>`.setup()`<font style="color:rgba(0, 0, 0, 0.87);"> æ¥åˆå§‹åŒ–æ•°æ®åº“ï¼Œç„¶åæ‰èƒ½ä½¿ç”¨ã€‚</font>
>

**åŒæ­¥è¿æ¥ï¼ˆ****<font style="color:rgba(0, 0, 0, 0.87);">sync connection</font>****ï¼‰**

<font style="color:rgba(0, 0, 0, 0.87);">åŒæ­¥è¿æ¥ä»¥é˜»å¡æ–¹å¼æ‰§è¡Œä½œï¼Œè¿™æ„å‘³ç€æ¯ä¸ªoperationéƒ½ä¼šç­‰å¾…å®Œæˆï¼Œç„¶åå†ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªoperationï¼Œä»¥ä¸‹å±•ç¤ºäº†ä¸‰ç§å¸¸è§çš„æ–¹å¼ï¼š</font>

+ <font style="color:rgba(0, 0, 0, 0.87);">With a connection</font>
+ <font style="color:rgba(0, 0, 0, 0.87);">With a connection pool</font>
+ <font style="color:rgba(0, 0, 0, 0.87);">With a connection string</font>

```python
from langgraph.prebuilt import create_react_agent
from psycopg_pool import ConnectionPool
from langgraph.checkpoint.postgres import PostgresSaver

DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable"
connection_kwargs = {
    "autocommit": True,
    "prepare_threshold": 0,
}

# =============With a connection ==============
with Connection.connect(DB_URI, **connection_kwargs) as conn:
    checkpointer = PostgresSaver(conn)
    checkpointer.setup()
    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
    config = {"configurable": {"thread_id": "2"}}
    res = graph.invoke({"messages": [("human", "what's the language of this paper")]}, config)

    checkpoint_tuple = checkpointer.get_tuple(config)

# ===========With a connection pool============
with ConnectionPool(
    # Example configuration
    conninfo=DB_URI,
    max_size=20,
    kwargs=connection_kwargs,
) as pool:
    checkpointer = PostgresSaver(pool)
    checkpointer.setup()
    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
    config = {"configurable": {"thread_id": "1"}}
    res = graph.invoke({"messages": [("human", "what's the language of this paper")]}, config)
    checkpoint = checkpointer.get(config)

# ===========With a connection string============
with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
    config = {"configurable": {"thread_id": "3"}}
    res = graph.invoke({"messages": [("human", "what's the language of this paper")]}, config)

    checkpoint_tuples = list(checkpointer.list(config))
```

**å¼‚æ­¥è¿æ¥ï¼ˆa****<font style="color:rgba(0, 0, 0, 0.87);">sync connection</font>****ï¼‰**

<font style="color:rgba(0, 0, 0, 0.87);">å¼‚æ­¥è¿æ¥å…è®¸éé˜»å¡æ•°æ®åº“ä½œã€‚ä¹Ÿå°±æ˜¯è¯´åº”ç”¨ç¨‹åºçš„å…¶ä»–éƒ¨åˆ†å¯ä»¥åœ¨ç­‰å¾…æ•°æ®åº“æ“ä½œå®Œæˆæ—¶ç»§ç»­è¿è¡Œã€‚é€‚åˆé«˜å¹¶å‘åœºæ™¯æˆ–å¤„ç† I/O ç»‘å®šæ“ä½œæ—¶ç‰¹åˆ«æœ‰ç”¨ã€‚</font>

```python
from psycopg import AsyncConnection

async with await AsyncConnection.connect(DB_URI, **connection_kwargs) as conn:
    checkpointer = AsyncPostgresSaver(conn)
    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
    config = {"configurable": {"thread_id": "5"}}
    res = await graph.ainvoke(
        {"messages": [("human", "what's the weather in nyc")]}, config
    )
    checkpoint_tuple = await checkpointer.aget_tuple(config)
```

### æ—¥å¿—ä¸å¯è§‚æµ‹æ€§ï¼ˆLogging & Monitoringï¼‰
<font style="color:rgb(50, 56, 62);"> LangSmith ä¸“é—¨ç”¨æ¥</font>**ç›‘æ§å’Œè°ƒè¯• LLM åº”ç”¨**<font style="color:rgb(50, 56, 62);">ï¼Œèƒ½å®æ—¶è·Ÿè¸ªå·¥ä½œæµã€æ¨¡å‹è¡¨ç°ï¼Œå¹¶ä¸” LangSmith æä¾›äº†</font>**é’ˆå¯¹å¤§æ¨¡å‹åŸç”Ÿä¼˜åŒ–çš„å¯è§‚æµ‹æ€§åŠŸèƒ½**<font style="color:rgb(50, 56, 62);">ï¼Œä»å¼€å‘ã€æµ‹è¯•åˆ°ä¸Šçº¿ ï¼Œéå¸¸é€‚åˆç”Ÿäº§ç¯å¢ƒã€‚ LangSmithæœ¬èº«</font>ä¸æ¡†æ¶æ— å…³ â€” å®ƒå¯ä»¥ä¸ langchain å’Œ langgraph ä¸€èµ·ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥å•ç‹¬ä½¿ç”¨ã€‚å¯¹äºLangGraphï¼Œæˆ‘ä»¬å¯ä»¥é›†æˆLangSmithå®ç°<font style="color:rgb(50, 56, 62);">ç”Ÿæˆå¯¹æ•´ä¸ªpiplineçš„è·Ÿè¸ªï¼Œæ–¹ä¾¿è°ƒè¯•ä¸ç›‘çœ‹ã€‚</font>

---

# LlamaIndex
## åŸºæœ¬ä»‹ç»
LlamaIndex æ˜¯ä¸€ä¸ªç”¨äºLLM åº”ç”¨ç¨‹åºçš„æ•°æ®æ¡†æ¶ï¼Œç”¨äºæ³¨å…¥ï¼Œç»“æ„åŒ–ï¼Œå¹¶è®¿é—®ç§æœ‰æˆ–ç‰¹å®šé¢†åŸŸæ•°æ®ï¼Œä¸“é—¨ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æä¾›å¤–éƒ¨æ•°æ®æ¥å…¥çš„èƒ½åŠ›ã€‚

ç›¸æ¯”ä¼ ç»Ÿä½¿ç”¨**æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰æ–¹å¼ç»„ç»‡æµç¨‹çš„æ¡†æ¶ï¼ŒLlamaIndexæå‡ºäº†æ›´è‡ªç„¶ã€æ›´å…·è¡¨è¾¾åŠ›çš„Workflowæœºåˆ¶**ï¼Œè§£å†³äº†å¤æ‚AIæµç¨‹ä¸­å¾ªç¯ï¼ˆloopsï¼‰ã€åˆ†æ”¯ï¼ˆbranchesï¼‰å’ŒåŠ¨æ€æ•°æ®ä¼ é€’çš„é—®é¢˜ã€‚å…¶ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬ï¼š

+ **æ›´ç›´è§‚çš„æ§åˆ¶æµ**ï¼šå¾ªç¯ä¸åˆ†æ”¯ä½œä¸ºä¸€ç­‰å…¬æ°‘å­˜åœ¨äºWorkflowä¸­ï¼Œä¸å†éœ€è¦éšæ™¦åœ°é€šè¿‡è¾¹ï¼ˆedgesï¼‰æ¥æ¨¡æ‹Ÿï¼Œå¤§å¹…æå‡å¯è¯»æ€§ä¸ç»´æŠ¤æ€§ã€‚
+ **ç®€åŒ–æ•°æ®æµç®¡ç†**ï¼šèŠ‚ç‚¹ä¹‹é—´çš„æ•°æ®ä¼ é€’æœºåˆ¶æ›´åŠ æ¸…æ™°ï¼Œå‡å°‘äº†åœ¨DAGä¸­å¸¸è§çš„é»˜è®¤å€¼ã€å¯é€‰å‚æ•°ã€æ•°æ®å¯¹é½ç­‰ç¹æ‚å¤„ç†ã€‚
+ **å¼€å‘ä½“éªŒè‡ªç„¶**ï¼šç¬¦åˆå¼€å‘è€…åœ¨æ„å»ºå¤æ‚ã€åŠ¨æ€AIåº”ç”¨ï¼ˆå¦‚Agentç³»ç»Ÿã€äº¤äº’å¼æ¨ç†é“¾ï¼‰æ—¶çš„æ€è€ƒæ–¹å¼ï¼Œæ— éœ€å¯¹é½åº•å±‚å›¾ç»“æ„ã€‚

> _å®˜æ–¹å‚è€ƒ_ï¼š[LlamaIndexæ–‡æ¡£](about:blank)ï¼Œ[LlamaIndex GitHub](https://github.com/run-llama/llama_index)ã€‚
>

## æ¡†æ¶è¯„æµ‹
### ä½¿ç”¨è¯´æ˜
åœ¨ **LlamaIndex** æ¡†æ¶ä¸­ï¼Œå·¥ä½œæµï¼ˆ`Workflow`ï¼‰ç”±å¤šä¸ªæ­¥éª¤ï¼ˆ`step`ï¼‰ç»„æˆã€‚æ¯ä¸ªæ­¥éª¤æ¥å—ä¸€ä¸ªæˆ–å¤šä¸ª **äº‹ä»¶ï¼ˆEventï¼‰**ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„äº‹ä»¶ã€‚å·¥ä½œæµé€šå¸¸ä¼šç”±ä¸€ä¸ªç‰¹æ®Šçš„ **StartEvent** è§¦å‘ï¼Œå¹¶ç”± **StopEvent** ç»“æŸã€‚

#### ğŸ“Œ æ ¸å¿ƒæ¦‚å¿µï¼š
1. `**StartEvent**`: å¯åŠ¨å·¥ä½œæµçš„äº‹ä»¶ï¼Œé€šå¸¸ä½œä¸ºç¬¬ä¸€ä¸ªæ­¥éª¤çš„è¾“å…¥ã€‚
2. `**StopEvent**`: ç»“æŸå·¥ä½œæµçš„äº‹ä»¶ï¼Œå®ƒä¼šç»“æŸå·¥ä½œæµå¹¶è¿”å›æœ€ç»ˆç»“æœã€‚
3. `**Event**`: æ‰€æœ‰äº‹ä»¶ï¼ˆåŒ…æ‹¬ StartEvent å’Œ StopEventï¼‰éƒ½éœ€è¦ç»§æ‰¿è‡ª `Event` ç±»ã€‚ç”¨æˆ·å¯ä»¥å®šä¹‰è‡ªå®šä¹‰çš„äº‹ä»¶æ¥åœ¨æ­¥éª¤ä¹‹é—´ä¼ é€’æ•°æ®ã€‚

#### ğŸ“Œ æ­¥éª¤ï¼ˆStepï¼‰å®šä¹‰ï¼š
+ `**@step**` è£…é¥°å™¨ï¼šç”¨äºæ ‡è®°ä¸€ä¸ªæ–¹æ³•ä¸ºå·¥ä½œæµä¸­çš„æ­¥éª¤ï¼ˆstepï¼‰ã€‚
+ æ¯ä¸ªæ­¥éª¤æ¥å—ä¸€ä¸ªäº‹ä»¶ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªäº‹ä»¶ä½œä¸ºè¾“å‡ºã€‚

#### ğŸ“Œ å·¥ä½œæµæ‰§è¡Œï¼š
1. åˆ›å»ºå·¥ä½œæµå®ä¾‹ã€‚
2. è°ƒç”¨ `run()` æ–¹æ³•ï¼Œå¯åŠ¨å·¥ä½œæµå¹¶ä¼ å…¥åˆå§‹äº‹ä»¶ã€‚
3. æ­¥éª¤ä¾æ¬¡æ‰§è¡Œï¼Œæ¯ä¸ªæ­¥éª¤åŸºäºå‰ä¸€ä¸ªæ­¥éª¤çš„è¾“å‡ºç”Ÿæˆæ–°çš„äº‹ä»¶ã€‚
4. <font style="color:rgba(0, 0, 0, 0.87);">é»˜è®¤æƒ…å†µä¸‹ï¼Œå·¥ä½œæµç¨‹æ˜¯å¼‚æ­¥çš„ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨ </font>`await`<font style="color:rgba(0, 0, 0, 0.87);"> æ¥è·å– </font>`run`<font style="color:rgba(0, 0, 0, 0.87);"> å‘½ä»¤çš„ç»“æœ</font>

```python
from llama_index.core.workflow import (
    StartEvent,
    StopEvent,
    Workflow,
    step,
    Event,
)
import asyncio

# å®šä¹‰äº‹ä»¶ç±»
class PDFLoadedEvent(Event):
    pdf_content: str

class ParsedTextEvent(Event):
    parsed_text: str

class SummarizedTextEvent(Event):
    summary: str

class DatabaseStoredEvent(Event):
    result: str

# åˆ›å»ºå·¥ä½œæµ
class MyWorkflow(Workflow):
    @step
    async def start_step(self, ev: StartEvent) -> PDFLoadedEvent:
        print("Starting the workflow...")
        return PDFLoadedEvent(pdf_content="Loaded PDF content here.")

    @step
    async def pdf_parser_step(self, ev: PDFLoadedEvent) -> ParsedTextEvent:
        print(f"Parsing PDF content: {ev.pdf_content}")
        return ParsedTextEvent(parsed_text="Parsed text from the PDF.")

    @step
    async def text_summary_step(self, ev: ParsedTextEvent) -> SummarizedTextEvent:
        print(f"Summarizing parsed text: {ev.parsed_text}")
        return SummarizedTextEvent(summary="Summary of the parsed text.")

    @step
    async def database_persistence_step(self, ev: SummarizedTextEvent) -> DatabaseStoredEvent:
        print(f"Storing summarized text in database: {ev.summary}")
        return DatabaseStoredEvent(result="Text stored in PostgreSQL database.")

    @step
    async def end_step(self, ev: DatabaseStoredEvent) -> StopEvent:
        print(f"Final result: {ev.result}")
        return StopEvent(result="Workflow complete.")

async def main():
    w = MyWorkflow(timeout=10, verbose=False)
    result = await w.run(first_input="Start the workflow.")
    print(result)

if __name__ == "__main__":
    asyncio.run(main())

```

#### ğŸ“Œ<font style="color:rgba(0, 0, 0, 0.87);"> å†…ç½®çš„å¯è§†åŒ–å·¥å…·</font>
LlamaIndexçš„ä¸€å¤§ç‰¹è‰²æ˜¯å†…ç½®äº†å¯è§†åŒ–å·¥å…·ï¼Œå¯ä»¥ç”¨ä¸‹é¢è¿™ç§æ–¹å¼ç”ŸæˆhtmlæŸ¥çœ‹

```python
from llama_index.utils.workflow import draw_all_possible_flows
    draw_all_possible_flows(MyWorkflow, filename="multi_step_workflow.html")
```

![](pictures/llamaindex_wf.png)

### çŠ¶æ€ç®¡ç†ï¼ˆState Managementï¼‰
Demoç¤ºä¾‹ä¸­ä½¿ç”¨çš„éƒ½æ˜¯è‡ªå®šä¹‰äº‹ä»¶çš„å±æ€§é€æ­¥ä¼ é€’æ•°æ®ï¼Œè¿™ç§é“¾å¼ä¼ è¾“æ–¹å¼å­˜åœ¨é—®é¢˜å°±æ˜¯ä¸å¤Ÿçµæ´»ï¼Œä¾‹å¦‚æˆ‘ä»¬éš¾ä»¥**è·¨èŠ‚ç‚¹ä¼ é€’æ•°æ®**ï¼Œç¼ºå°‘ä¸€ä¸ªå…¨å±€çš„ä¸Šä¸‹æ–‡çŠ¶æ€ç®¡ç†æ–¹å¼ã€‚å› æ­¤ï¼ŒLlamaIndexå¼•å…¥äº†`Context`<font style="color:rgba(0, 0, 0, 0.87);"> </font><font style="color:rgba(0, 0, 0, 0.87);">ç±»å‹çš„å‚æ•°æ¥è¡¥å……è¿™ä¸€ç‚¹ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š</font>

```python
from llama_index.core.workflow import (
    StartEvent,
    StopEvent,
    Workflow,
    step,
    Event,
    Context,
)
```

<font style="color:rgba(0, 0, 0, 0.87);">ç°åœ¨ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ª </font>`start`<font style="color:rgba(0, 0, 0, 0.87);"> äº‹ä»¶ï¼Œç”¨äºæ£€æŸ¥æ•°æ®æ˜¯å¦å·²åŠ è½½åˆ°ä¸Šä¸‹æ–‡ä¸­ã€‚å¦åˆ™ï¼Œå®ƒå°†è¿”å›ä¸€ä¸ª </font>`SetupEvent`<font style="color:rgba(0, 0, 0, 0.87);">ï¼Œè¯¥äº‹ä»¶è§¦å‘åŠ è½½æ•°æ®å¹¶å¾ªç¯å›åˆ° </font>`start`<font style="color:rgba(0, 0, 0, 0.87);"> çš„ </font>`setup`<font style="color:rgba(0, 0, 0, 0.87);">ã€‚</font>

```python
class SetupEvent(Event):
    query: str


class StepTwoEvent(Event):
    query: str


class StatefulFlow(Workflow):
    @step
    async def start(
        self, ctx: Context, ev: StartEvent
    ) -> SetupEvent | StepTwoEvent:
        db = await ctx.get("some_database", default=None)
        if db is None:
            print("Need to load data")
            return SetupEvent(query=ev.query)

        # do something with the query
        return StepTwoEvent(query=ev.query)

    @step
    async def setup(self, ctx: Context, ev: SetupEvent) -> StartEvent:
        # load data
        await ctx.set("some_database", [1, 2, 3])
        return StartEvent(query=ev.query)
```

<font style="color:rgba(0, 0, 0, 0.87);">ç„¶ååœ¨ </font>`step_two`<font style="color:rgba(0, 0, 0, 0.87);"> ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä»ä¸Šä¸‹æ–‡è®¿é—®æ•°æ®ï¼Œè€Œæ— éœ€æ˜¾å¼ä¼ é€’æ•°æ®ã€‚</font>

```python
@step
async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StopEvent:
    # do something with the data
    print("Data is ", await ctx.get("some_database"))

    return StopEvent(result=await ctx.get("some_database"))

w = StatefulFlow(timeout=10, verbose=False)
result = await w.run(query="Some query")
print(result)
```

### ç»†ç²’åº¦æ§åˆ¶ï¼ˆControl Granularityï¼‰
#### ğŸ“Œ åˆ†æ”¯ï¼ˆbranchï¼‰
å¦‚ä¸‹æ‰€ç¤ºï¼Œæˆ‘ä»¬æ–°å»ºäº†ä¸¤ä¸ªäº‹ä»¶ç±»å‹ï¼Œ`Start`<font style="color:rgba(0, 0, 0, 0.87);"> éšæœºå†³å®šé‡‡ç”¨ä¸€ä¸ªåˆ†æ”¯æˆ–å¦ä¸€ä¸ªåˆ†æ”¯ï¼Œç„¶åæ¯ä¸ªåˆ†æ”¯ä¸­çš„å¤šä¸ªæ­¥éª¤å®Œæˆå·¥ä½œæµã€‚</font>

> ğŸ’¡ <font style="color:rgba(0, 0, 0, 0.87);">æ”¯æŒæŒ‰ä»»ä½• Order ç»„åˆåˆ†æ”¯å’Œå¾ªç¯æ¥æ»¡è¶³ä¸åŒä¸šåŠ¡åº”ç”¨éœ€æ±‚ã€‚è¿˜å¯ä»¥ </font>`send_event`<font style="color:rgba(0, 0, 0, 0.87);"> å¹¶è¡Œè¿è¡Œå¤šä¸ªåˆ†æ”¯ï¼Œå¹¶ä½¿ç”¨ </font>`collect_events`<font style="color:rgba(0, 0, 0, 0.87);"> åŒæ­¥å®ƒä»¬</font>
>

```python
class BranchA1Event(Event):
    payload: str
    
class BranchB1Event(Event):
    payload: str
    
class BranchWorkflow(Workflow):
    @step
    async def start(self, ev: StartEvent) -> BranchA1Event | BranchB1Event:
        if random.randint(0, 1) == 0:
            print("Go to branch A")
            return BranchA1Event(payload="Branch A")
        else:
            print("Go to branch B")
            return BranchB1Event(payload="Branch B")
```

#### ğŸ“Œ å¾ªç¯ï¼ˆloopï¼‰
<font style="color:rgba(0, 0, 0, 0.87);">è¦åˆ›å»ºå¾ªç¯ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨ä¸Šä¸€æ•™ç¨‹ä¸­çš„ç¤ºä¾‹ </font>`MyWorkflow`<font style="color:rgba(0, 0, 0, 0.87);"> å¹¶æ·»åŠ ä¸€ä¸ªæ–°çš„è‡ªå®šä¹‰äº‹ä»¶ç±»å‹ã€‚æˆ‘ä»¬å°†å…¶å‘½åä¸º </font>`LoopEvent`<font style="color:rgba(0, 0, 0, 0.87);">ï¼Œä½†åŒæ ·ï¼Œå®ƒå¯ä»¥å…·æœ‰ä»»æ„åç§°ã€‚</font>

```python
class LoopEvent(Event):
    loop_output: str

@step
async def text_summary_step(self, ev: ParsedTextEvent | LoopEvent) -> SummarizedTextEvent | LoopEvent:
    if random.randint(0, 1) == 0:
        print("fail")
        return LoopEvent(loop_output="Back to step one.")
    else:
        print(f"Summarizing parsed text: {ev.parsed_text}")
        return SummarizedTextEvent(summary="Summary of the parsed text.")
```

![](pictures/loop.png)

####  ğŸ“Œå­ç±»åŒ–å·¥ä½œæµï¼ˆSubclassingï¼‰  
å¯ä»¥å‘åƒæ™®é€š Python ç±»ä¸€æ ·ï¼Œé€šè¿‡ç»§æ‰¿ï¼ˆ`class NewWorkflow(BaseWorkflow)`ï¼‰æ¥æ‰©å±•æˆ–é‡å®šä¹‰å·²æœ‰å·¥ä½œæµä¸­çš„æ­¥éª¤ (`@step` ä¿®é¥°çš„æ–¹æ³•)ã€‚  

+ å­ç±»ä¸­å¯ä»¥é‡å†™çˆ¶ç±»çš„æŸä¸ªæ­¥éª¤ï¼ˆæ–¹æ³•åç›¸åŒï¼Œäº‹ä»¶ç±»å‹å¯å˜åŒ–ï¼‰ã€‚
+ ä¹Ÿå¯ä»¥åœ¨å­ç±»ä¸­æ·»åŠ æ–°çš„æ­¥éª¤ã€‚
+ æ­¥éª¤çš„æ‰§è¡Œé¡ºåºæ˜¯æ ¹æ®äº‹ä»¶ä¼ é€’é“¾ï¼ˆäº‹ä»¶ç±»å‹ï¼‰è€Œä¸æ˜¯æ–¹æ³•é¡ºåºå†³å®šçš„ã€‚

```python
class CustomWorkflow(MainWorkflow):
    @step
    async def step_two(self, ev: Step2Event) -> Step2BEvent:
        print("Sending an email")
        return Step2BEvent(query=ev.query)

    @step
    async def step_two_b(self, ev: Step2BEvent) -> Step3Event:
        print("Also sending a text message")
        return Step3Event(query=ev.query)
```

+  è¿™é‡Œï¼Œå­ç±» **é‡å†™**äº† `step_two`ï¼Œå¹¶ä¸”**æ–°å¢**äº† `step_two_b`ï¼Œæ‰©å±•äº†å¤„ç†æµç¨‹ã€‚  

####  ğŸ“Œå·¥ä½œæµåµŒå¥—
 åœ¨ä¸»å·¥ä½œæµä¸­ï¼Œé¢„ç•™ä¸€ä¸ªæˆ–å¤šä¸ª **å­å·¥ä½œæµæ’æ§½ï¼ˆWorkflow Slotï¼‰**ï¼Œåœ¨è¿è¡Œæ—¶åŠ¨æ€ä¼ å…¥å®Œæ•´çš„å­å·¥ä½œæµå®ä¾‹ã€‚  

+ åœ¨ä¸»å·¥ä½œæµçš„æ­¥éª¤æ–¹æ³•ä¸­ï¼Œæ¥æ”¶ä¸€ä¸ª `Workflow` ç±»å‹çš„å‚æ•°ï¼ˆå¦‚ `reflection_workflow`ï¼‰ã€‚
+ ä½¿ç”¨ `.run()` å¯åŠ¨å­å·¥ä½œæµï¼Œå­å·¥ä½œæµè‡ªå·±å¤„ç†å†…éƒ¨é€»è¾‘ã€‚
+ å¯é€šè¿‡ `add_workflows(reflection_workflow=YourSubWorkflow())` æ³¨å…¥å­æµç¨‹ã€‚
+ ä¹Ÿå¯ä»¥ä¸ºå­å·¥ä½œæµå‚æ•°è®¾ç½®ä¸€ä¸ª**é»˜è®¤å­æµç¨‹**ï¼Œä½¿ä¸»æµç¨‹å¯ä»¥å•ç‹¬è¿è¡Œã€‚

ç¤ºä¾‹ï¼š å®šä¹‰ä¸€ä¸ªæœ‰å­æµç¨‹æ’æ§½çš„ä¸»å·¥ä½œæµå’Œä¸€ä¸ªå­å·¥ä½œæµ

```python
class MainWorkflow(Workflow):
    @step
    async def start(self, ctx: Context, ev: StartEvent, reflection_workflow: Workflow = DefaultSubflow()) -> Step2Event:
        print("Need to run reflection")
        res = await reflection_workflow.run(query=ev.query)
        return Step2Event(query=res)

class ReflectionFlow(Workflow):
    @step
    async def sub_start(self, ctx: Context, ev: StartEvent) -> StopEvent:
        print("Doing custom reflection")
        return StopEvent(result="Improved query")
```

 è¿è¡Œæ—¶æ›¿æ¢é»˜è®¤å­å·¥ä½œæµï¼š  

```python
w = MainWorkflow(timeout=10, verbose=False)
w.add_workflows(reflection_workflow=ReflectionFlow())
result = await w.run(query="Initial query")
```



### å¼‚æ­¥å¹¶å‘
åœ¨å·¥ä½œæµä¸­å¹¶å‘æ‰§è¡Œæ­¥éª¤å¯ä»¥æ˜¾è‘—æé«˜æ•ˆç‡ï¼Œç‰¹åˆ«æ˜¯å½“æ­¥éª¤å½¼æ­¤ç‹¬ç«‹ä¸”æ‰§è¡Œæ—¶é—´è¾ƒé•¿æ—¶ã€‚é€šè¿‡å‘å‡ºå¤šä¸ªäº‹ä»¶ï¼Œå·¥ä½œæµå¯ä»¥å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡ï¼Œå‡å°‘æ•´ä½“æ‰§è¡Œæ—¶é—´ã€‚  

#### ğŸ“Œ **å‘å‡ºå¤šä¸ªäº‹ä»¶**
```python
class ParallelFlow(Workflow):
    @step
    async def start(self, ctx: Context, ev: StartEvent) -> StepTwoEvent:
        # å‘é€å¤šä¸ªäº‹ä»¶ï¼Œå¯åŠ¨å¤šä¸ªç‹¬ç«‹çš„ä»»åŠ¡
        ctx.send_event(StepTwoEvent(query="Query 1"))
        ctx.send_event(StepTwoEvent(query="Query 2"))
        ctx.send_event(StepTwoEvent(query="Query 3"))

    @step(num_workers=4)
    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StopEvent:
        print("Running slow query ", ev.query)
        await asyncio.sleep(random.randint(1, 5))  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
        return StopEvent(result=ev.query)

```

+ åœ¨ `start` æ­¥éª¤ä¸­ï¼Œä¸‰ä¸ªæŸ¥è¯¢è¢«å¹¶è¡Œå‘é€ã€‚
+ `step_two` æ­¥éª¤é€šè¿‡è®¾ç½® `num_workers=4`ï¼ŒæŒ‡ç¤ºæœ€å¤š4ä¸ªå¹¶å‘å®ä¾‹åŒæ—¶æ‰§è¡Œï¼Œå³ä½¿æœ‰å¤šä¸ªæŸ¥è¯¢ã€‚

#### ğŸ“Œ **æ”¶é›†äº‹ä»¶**
å¦‚æœæˆ‘ä»¬éœ€è¦ç­‰å¾…æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å®Œæˆåå†æ‰§è¡Œä¸‹ä¸€æ­¥ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹å¯ä»¥ä½¿ç”¨ `collect_events` æ–¹æ³•æ¥ç­‰å¾…å¤šä¸ªäº‹ä»¶å®Œæˆã€‚`collect_events` ä¼šç­‰å¾…æŒ‡å®šç±»å‹çš„æ‰€æœ‰äº‹ä»¶ï¼Œç›´åˆ°æ”¶åˆ°è¶³å¤Ÿæ•°é‡çš„äº‹ä»¶åæ‰ç»§ç»­æ‰§è¡Œã€‚  

```python
class ConcurrentFlow(Workflow):
    @step
    async def start(self, ctx: Context, ev: StartEvent) -> StepTwoEvent:
        # å‘å‡ºå¤šä¸ªäº‹ä»¶ï¼Œå¯åŠ¨å¤šä¸ªç‹¬ç«‹çš„ä»»åŠ¡
        ctx.send_event(StepTwoEvent(query="Query 1"))
        ctx.send_event(StepTwoEvent(query="Query 2"))
        ctx.send_event(StepTwoEvent(query="Query 3"))

    @step(num_workers=4)
    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StepThreeEvent:
        print("Running query ", ev.query)
        await asyncio.sleep(random.randint(1, 3))  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
        return StepThreeEvent(result=ev.query)

    @step
    async def step_three(self, ctx: Context, ev: StepThreeEvent) -> StopEvent:
        # ç­‰å¾…æ‰€æœ‰3ä¸ªäº‹ä»¶
        result = ctx.collect_events(ev, [StepThreeEvent] * 3)
        if result is None:
            return None  # å¦‚æœäº‹ä»¶ä¸å®Œæ•´ï¼Œåˆ™è¿”å›

        # æ”¶é›†åˆ°æ‰€æœ‰ç»“æœåï¼Œæ‰§è¡Œåç»­æ“ä½œ
        print(result)
        return StopEvent(result="Done")

```

> ğŸ’¡`collect_events` è¿”å›ä¸€ä¸ªæŒ‰æ¥æ”¶é¡ºåºæ’åˆ—çš„äº‹ä»¶åˆ—è¡¨ã€‚  
>

#### ğŸ“Œ ç­‰å¾…å¤šç§ç±»å‹çš„äº‹ä»¶
å¯ä»¥é€šè¿‡ `collect_events` æ–¹æ³•ç­‰å¾…äº‹ä»¶ç±»å‹çš„ç»„åˆï¼Œå¹¶æŒ‰æ¥æ”¶åˆ°äº‹ä»¶çš„é¡ºåºç»§ç»­å¤„ç†ã€‚  

```python
    @step
    async def step_three(
        self,
        ctx: Context,
        ev: StepACompleteEvent | StepBCompleteEvent | StepCCompleteEvent,
    ) -> StopEvent:
        print("Received event ", ev.result)

        # ç­‰å¾…ä¸‰ç§ç±»å‹çš„äº‹ä»¶
        if (
            ctx.collect_events(
                ev,
                [StepCCompleteEvent, StepACompleteEvent, StepBCompleteEvent],
            )
            is None
        ):
            return None  # å¦‚æœäº‹ä»¶ä¸å®Œæ•´ï¼Œåˆ™è¿”å›

        # æ”¶é›†åˆ°æ‰€æœ‰äº‹ä»¶åï¼Œæ‰§è¡Œåç»­æ“ä½œ
        return StopEvent(result="Done")
```

### åˆ†å¸ƒå¼æ”¯æŒï¼ˆ<font style="color:rgb(32, 33, 34);">Distributed Support</font>ï¼‰
+ LlamaIndexæœ¬èº«åŸºäºå¼‚æ­¥äº‹ä»¶é©±åŠ¨ï¼Œé€‚åˆå•æœºå¹¶å‘ï¼Œä½†éœ€è¦å¤–éƒ¨æ¡†æ¶ï¼ˆå¦‚ Rayï¼‰å®ç°åˆ†å¸ƒå¼æ‰§è¡Œã€‚
+ æ”¯æŒåˆ†å¸ƒå¼æ•°æ®æ‘„å–ã€ç´¢å¼•å’ŒæŸ¥è¯¢ï¼Œå¯ä»¥é€šè¿‡åˆ†ç‰‡å’Œå¹¶è¡ŒåŒ–å¤„ç†å¤§è§„æ¨¡ä»»åŠ¡ã€‚
+ LlamaIndex å®˜æ–¹æ”¯æŒä¸ Ray çš„é›†æˆï¼Œé€šè¿‡ @ray.remoteã€Ray Datasets å’Œ Ray Serve å®ç° Workflow çš„åˆ†å¸ƒå¼è¿è¡Œã€‚
+ é€‚ç”¨äºå¹¶è¡Œæ•°æ®å¤„ç†ã€ç´¢å¼•æ„å»ºå’Œé«˜å¹¶å‘æŸ¥è¯¢ï¼Œé€‚åˆç”Ÿäº§çº§ RAG åº”ç”¨ã€‚

**é›†æˆrayç¤ºä¾‹ï¼š**

```python
import ray
from llama_index.core.workflow import Workflow, step, StartEvent, StopEvent
from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader

# åˆå§‹åŒ– Ray
ray.init()

# å®šä¹‰åˆ†å¸ƒå¼ Workflow
@ray.remote
class DistributedWorkflow(Workflow):
    @step
    async def ingest_data(self, ev: StartEvent) -> None:
        # å¹¶è¡ŒåŠ è½½æ–‡æ¡£
        documents = SimpleDirectoryReader("data_directory").load_data()
        index = VectorStoreIndex.from_documents(documents)
        return {"index": index}

    @step
    async def query_step(self, ev: dict) -> StopEvent:
        index = ev["index"]
        query_engine = index.as_query_engine()
        result = query_engine.query("What is the main topic?")
        return StopEvent(result=str(result))

# è¿è¡Œåˆ†å¸ƒå¼ Workflow
workflow = DistributedWorkflow.remote()
result = ray.get(workflow.run.remote())
print(result)
```

### **æµå¼è¾“å‡ºï¼ˆStreaming Outputï¼‰**
LlamaIndexæ”¯æŒé€šè¿‡ `ctx.write_event_to_stream()` æ–¹æ³•å°†äº‹ä»¶å†™å…¥æµä¸­ï¼Œè¿™æ ·ç”¨æˆ·å°±èƒ½å®æ—¶çœ‹åˆ°è¿›åº¦ã€‚  è¿™é‡Œæˆ‘ä»¬å…ˆä½¿ç”¨ `Workflow` ç±»æ¥å®šä¹‰å·¥ä½œæµï¼Œå¹¶åœ¨æ¯ä¸ªæ­¥éª¤ä¸­å®šä¹‰äº‹ä»¶æµçš„è¾“å‡ºã€‚  

```python
from llama_index.utils.workflow import draw_all_possible_flows

...

class MyWorkflow(Workflow):
    @step
    async def step_one(self, ctx: Context, ev: StartEvent) -> FirstEvent:
        ctx.write_event_to_stream(ProgressEvent(msg="Step one is happening"))
        return FirstEvent(first_output="First step complete.")

    @step
    async def step_two(self, ctx: Context, ev: FirstEvent) -> SecondEvent:
        llm = OpenAI(model="gpt-4o-mini")
        generator = await llm.astream_complete(
            "Please give me the first 3 paragraphs of Moby Dick, a book in the public domain."
        )
        async for response in generator:
            # æ¯æ¬¡æ¥æ”¶åˆ°å“åº”å—æ—¶å‘é€è¿›åº¦äº‹ä»¶
            ctx.write_event_to_stream(ProgressEvent(msg=response.delta))
        return SecondEvent(
            second_output="Second step complete, full response attached",
            response=str(response),
        )

    @step
    async def step_three(self, ctx: Context, ev: SecondEvent) -> StopEvent:
        ctx.write_event_to_stream(ProgressEvent(msg="Step three is happening"))
        return StopEvent(result="Workflow complete.")

```

+ åœ¨ `step_one` å’Œ `step_three` ä¸­ï¼Œç›´æ¥å†™å…¥äº†è¿›åº¦äº‹ä»¶ã€‚
+ åœ¨ `step_two` ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `OpenAI` ç”Ÿæˆå™¨å¼‚æ­¥è·å– LLM å“åº”ï¼Œå¹¶ä¸ºæ¯ä¸ªå“åº”å—å‘é€è¿›åº¦äº‹ä»¶ã€‚

ç„¶åæˆ‘ä»¬éœ€è¦å¼‚æ­¥è¿è¡Œå·¥ä½œæµï¼Œå¹¶é€šè¿‡ `stream_events()` æ–¹æ³•ç›‘å¬äº‹ä»¶ã€‚`stream_events()` ä¼šè¿”å›æ¯ä¸ªæµå¼äº‹ä»¶ï¼Œç›´åˆ°å·¥ä½œæµæ‰§è¡Œå®Œæ¯•ã€‚  

```python
async def main():
    w = MyWorkflow(timeout=30, verbose=True)
    handler = w.run(first_input="Start the workflow.")

    async for ev in handler.stream_events():
        if isinstance(ev, ProgressEvent):
            print(ev.msg)  # è¾“å‡ºå®æ—¶è¿›åº¦ä¿¡æ¯

    final_result = await handler
    print("Final result", final_result)

```

### æŒä¹…åŒ–ï¼ˆPersistenceï¼‰
é»˜è®¤æƒ…å†µä¸‹ï¼ŒLlamaIndex çš„æ•°æ®å­˜åœ¨**å†…å­˜ä¸­**ï¼Œ**éœ€è¦æ˜¾å¼è°ƒç”¨**æ‰èƒ½å°†å…¶æŒä¹…åŒ–åˆ°ç£ç›˜æˆ–å…¶ä»–åç«¯ã€‚

åœ¨ LlamaIndex ä¸­ï¼Œ**å­˜å‚¨å±‚**æ˜¯é«˜åº¦æ¨¡å—åŒ–ã€å¯æ’æ‹”çš„ï¼Œä¸»è¦æ”¯æŒä»¥ä¸‹å‡ ç§æ•°æ®ç±»å‹çš„å­˜å‚¨ï¼š

| ç±»å‹ | è¯´æ˜ |
| --- | --- |
| æ–‡æ¡£å­˜å‚¨ï¼ˆDocument Storeï¼‰ | å­˜å‚¨æ‘„å–åçš„æ–‡æ¡£ï¼ˆNode å¯¹è±¡ï¼‰ |
| ç´¢å¼•å­˜å‚¨ï¼ˆIndex Storeï¼‰ | å­˜å‚¨ç´¢å¼•ç»“æ„åŠå…ƒæ•°æ® |
| å‘é‡å­˜å‚¨ï¼ˆVector Storeï¼‰ | å­˜å‚¨åµŒå…¥åçš„å‘é‡ |
| çŸ¥è¯†å›¾è°±å­˜å‚¨ï¼ˆProperty Graph Storeï¼‰ | å­˜å‚¨å±æ€§å›¾æ•°æ®ï¼ˆç”¨äºçŸ¥è¯†å›¾è°±ç´¢å¼•ï¼‰ |
| èŠå¤©è®°å½•å­˜å‚¨ï¼ˆChat Storeï¼‰ | å­˜å‚¨èŠå¤©æ¶ˆæ¯å’Œå¯¹è¯å†å² |


æ–‡æ¡£ã€ç´¢å¼•å­˜å‚¨éƒ½åŸºäºç»Ÿä¸€çš„**Key-Valueå­˜å‚¨æŠ½è±¡å±‚**ã€‚

#### ğŸ“Œ æœ¬åœ°æŒä¹…åŒ–
```python
storage_context.persist(persist_dir="<persist_dir>")
```

+ `<persist_dir>`ï¼šæŒ‡å®šæŒä¹…åŒ–çš„ç›®å½•ï¼Œé»˜è®¤æ˜¯ `./storage`ã€‚
+ å¯ä»¥åœ¨åŒä¸€ç›®å½•ä¸‹ä¿å­˜**å¤šä¸ªç´¢å¼•**ï¼Œä½†éœ€è¦ç®¡ç†å¥½å„è‡ªçš„ `index_id`ã€‚
+ æœ¬åœ°æŒä¹…åŒ–é€‚åˆå¼€å‘é˜¶æ®µã€å•æœºåº”ç”¨ã€ç®€å•éƒ¨ç½²ã€‚

æ³¨æ„ï¼šå¦‚æœä½ è‡ªå®šä¹‰äº†è¿œç¨‹å­˜å‚¨ï¼ˆå¦‚ MongoDBï¼‰ï¼Œè°ƒç”¨ `persist()` å¯èƒ½**ä¸éœ€è¦æˆ–æ— æ•ˆ**ï¼Œå…·ä½“å–å†³äºå­˜å‚¨åç«¯å®ç°ã€‚

#### ğŸ“Œ åŠ è½½ï¼ˆLoadingï¼‰
åŠ è½½æŒä¹…åŒ–çš„æ•°æ®ï¼Œæœ¬è´¨æ˜¯**é‡å»º **`**StorageContext**`ï¼Œç„¶å**ç”¨è¾…åŠ©å‡½æ•°åŠ è½½ç´¢å¼•æˆ–å›¾ç»“æ„**ã€‚

å…¸å‹æµç¨‹ï¼š

+ **é‡å»º **`**StorageContext**`**ï¼š**

```python
from llama_index.core import StorageContext
from llama_index.core.storage.docstore import SimpleDocumentStore
from llama_index.core.storage.index_store import SimpleIndexStore
from llama_index.core.vector_stores import SimpleVectorStore

storage_context = StorageContext.from_defaults(
    docstore=SimpleDocumentStore.from_persist_dir(persist_dir="<persist_dir>"),
    vector_store=SimpleVectorStore.from_persist_dir(persist_dir="<persist_dir>"),
    index_store=SimpleIndexStore.from_persist_dir(persist_dir="<persist_dir>"),
)
```

+ **åŠ è½½å¯¹è±¡ï¼ˆå•ä¸ªç´¢å¼• / å¤šä¸ªç´¢å¼• / å›¾ç»“æ„ï¼‰ï¼š**

```python
from llama_index.core import (
load_index_from_storage,
load_indices_from_storage,
load_graph_from_storage,
)

# åŠ è½½å•ä¸ªç´¢å¼•ï¼ˆæŒ‡å®š index_idï¼‰
index = load_index_from_storage(storage_context, index_id="<index_id>")

# åŠ è½½æ‰€æœ‰ç´¢å¼•
indices = load_indices_from_storage(storage_context)

# åŠ è½½çŸ¥è¯†å›¾ï¼ˆæŒ‡å®š root_idï¼‰
graph = load_graph_from_storage(storage_context, root_id="<root_id>")
```

> ç‰¹åˆ«æ³¨æ„ï¼š
>
> + å¦‚æœåŒä¸€ç›®å½•ä¸‹åªæœ‰ä¸€ä¸ªç´¢å¼•ï¼Œå¯ä»¥ä¸æŒ‡å®š `index_id`ï¼›
> + å¦‚æœæœ‰å¤šä¸ªç´¢å¼•ï¼Œ**å¿…é¡»æŒ‡å®š**è¦åŠ è½½çš„ `index_id`ã€‚
>

####  ğŸ“Œ ä½¿ç”¨è¿œç¨‹åç«¯ï¼ˆå¦‚ S3/R2ï¼‰  
### å¯è§‚æµ‹æ€§ï¼ˆMonitoringï¼‰
####  ğŸ“Œ å¯è§†åŒ–å·¥ä½œæµç»“æ„ï¼ˆå…¨å±€è§†è§’ï¼‰  
**ç›®çš„**ï¼šæŸ¥çœ‹ **æ‰€æœ‰å¯èƒ½çš„æ­¥éª¤æµè½¬è·¯å¾„**ï¼Œå¸®åŠ©ç†è§£å’Œè®¾è®¡æµç¨‹ã€‚  .

+ è¾“å‡ºæˆ HTMLï¼Œå¯åœ¨æµè§ˆå™¨äº¤äº’å¼æŸ¥çœ‹ã€‚
+ **é’ˆå¯¹ç±»ï¼ˆWorkflow Classï¼‰**ï¼Œè€Œä¸æ˜¯å®ä¾‹ã€‚

```python
from llama_index.utils.workflow import draw_all_possible_flows

draw_all_possible_flows(MyWorkflow, filename="workflow.html")
```

#### ğŸ“Œ Verbose æ¨¡å¼ï¼ˆè¯¦ç»†æ—¥å¿—ï¼‰  
**ç›®çš„**ï¼šå®æ—¶è§‚å¯Ÿæ¯ä¸ªæ­¥éª¤çš„è¿è¡Œæƒ…å†µã€äº‹ä»¶æµè½¬ã€‚

```python
w = MyWorkflow(timeout=10, verbose=True)
result = await w.run()
```

ä¼šæ‰“å°æ¯ä¸ªæ­¥éª¤ï¼š

+ **æ‰§è¡Œä¸­**
+ **æ˜¯å¦äº§ç”Ÿäº‹ä»¶**
+ **äº‹ä»¶ç±»å‹**

#### ğŸ“Œ é€æ­¥æ‰§è¡Œï¼ˆStepwise Executionï¼‰  
**ç›®çš„**ï¼š**æ‰‹åŠ¨æ¨è¿›æ¯ä¸€æ­¥**ï¼Œç»†ç²’åº¦æ§åˆ¶è°ƒè¯•ï¼Œé€‚åˆå¤æ‚å¹¶å‘æˆ–åˆ†æ”¯æµç¨‹  

```python
w = MyWorkflow(timeout=10, verbose=True)
handler = w.run(stepwise=True)

while produced_events := await handler.run_step():
    for ev in produced_events:
        handler.ctx.send_event(ev)

result = await handler
```

+ æ¯è°ƒç”¨ä¸€æ¬¡ `run_step()`ï¼Œæ¨è¿›ä¸€å°æ­¥ã€‚
+ éœ€è¦**æ‰‹åŠ¨å‘é€**æ–°äº§ç”Ÿçš„äº‹ä»¶ç»§ç»­é©±åŠ¨åç»­æ­¥éª¤ã€‚

#### ğŸ“Œ æ£€æŸ¥ç‚¹ï¼ˆCheckpointsï¼‰  
**ç›®çš„**ï¼š**ä¿å­˜å¹¶æ¢å¤**ä¸­é—´æ‰§è¡ŒçŠ¶æ€ï¼Œé¿å…é‡å¤ä»å¤´è¿è¡Œã€‚

**ç”¨æ³•**ï¼š

```python

from llama_index.core.workflow.checkpointer import WorkflowCheckpointer

w = MyWorkflow()
w_ckptr = WorkflowCheckpointer(workflow=w)

handler = w_ckptr.run()
await handler

# æŸ¥çœ‹äº§ç”Ÿçš„æ‰€æœ‰æ£€æŸ¥ç‚¹
w_ckptr.checkpoints[handler.run_id]

# ä»æŸä¸ªæ£€æŸ¥ç‚¹ç»§ç»­è¿è¡Œ
ckpt = w_ckptr.checkpoints[handler.run_id][0]
handler = w_ckptr.run_from(checkpoint=ckpt)
await handler
```

+ æ¯æ­¥éƒ½ä¼šè®°å½•ä¸€ä¸ªæ£€æŸ¥ç‚¹ã€‚
+ å¯ä»¥**å¿«é€Ÿå¤ç°ç‰¹å®šçŠ¶æ€**ï¼ŒåŠ é€Ÿå¼€å‘è°ƒè¯•å¾ªç¯ã€‚

#### ğŸ“Œ ç¬¬ä¸‰æ–¹å¯è§‚æµ‹æ€§å·¥å…·  
+ æ¯”å¦‚æ¥å…¥ **Arize** ç­‰å¤–éƒ¨å¹³å°è¿›è¡Œé«˜çº§ç›‘æ§å’Œå¯è§†åŒ–ã€‚
+ ç›®å‰å®˜æ–¹åŸç”Ÿä¸»è¦æ”¯æŒçš„æ˜¯ LlamaIndex è‡ªå·±çš„ä¸€å¥—æ–¹æ³•ã€‚

---

# Pydantic AI
## åŸºæœ¬ä»‹ç»
Pydantic AIæ¥è‡ªäºè‘—åçš„Pydanticåº“å¼€å‘è€…ï¼Œæ˜¯ä¸€ä¸ªå°†Pydanticä¸LLMé›†æˆçš„Agentså¼€å‘æ¡†æ¶ã€‚å…¶ç‹¬ç‰¹ä¹‹å¤„åœ¨äºä¸“æ³¨äºåœ¨AIåº”ç”¨ä¸­åˆ©ç”¨Pydanticçš„**ç±»å‹éªŒè¯ã€åºåˆ—åŒ–ä¸ç»“æ„åŒ–è¾“å‡º**ç­‰åŠŸèƒ½ã€‚Pydantic AIçš„ç‰¹ç‚¹æ˜¯**å¤©ç„¶çš„ç»“æ„åŒ–è¾“å‡ºä¸å¼ºç±»å‹éªŒè¯**ï¼Œä¸”ç®€æ´æ˜“ç”¨ï¼Œä¸å…¶ä»–æ¡†æ¶ä¹Ÿæœ‰è‰¯å¥½çš„é›†æˆï¼Œå¯ä»¥ç»“åˆä½¿ç”¨ã€‚

> _å®˜æ–¹å‚è€ƒ_ï¼š[PydanticAIæ–‡æ¡£](https://ai.pydantic.dev/)ï¼Œ[PydanticAI GitHub](https://github.com/pydantic/pydantic-ai)ã€‚
>

## æ¡†æ¶è¯„æµ‹
### ä½¿ç”¨è¯´æ˜
#### ğŸ“Œ ä»£ç†ï¼ˆagentï¼‰
 PydanticAI çš„ä»£ç†ï¼ˆAgentï¼‰æ¨¡å—æ˜¯å…¶æ ¸å¿ƒç»„ä»¶ï¼Œæ—¨åœ¨æä¾›ä¸€ç§ç»“æ„åŒ–ã€ç±»å‹å®‰å…¨ä¸”é«˜åº¦å¯æ‰©å±•çš„æ–¹å¼ï¼Œä»¥æ„å»ºä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’çš„ AI åº”ç”¨ã€‚  

ä¸€ä¸ªä»£ç†å®ä¾‹å¯è§†ä¸ºä»¥ä¸‹å…ƒç´ çš„ç»„åˆï¼š

+ **ç³»ç»Ÿæç¤ºï¼ˆSystem Promptï¼‰**ï¼šå¼€å‘è€…å®šä¹‰çš„æŒ‡ä»¤é›†ï¼Œå¼•å¯¼ LLM çš„è¡Œä¸ºã€‚
+ **å‡½æ•°å·¥å…·ï¼ˆFunction Toolsï¼‰**ï¼šLLM åœ¨ç”Ÿæˆå“åº”æ—¶å¯è°ƒç”¨çš„å‡½æ•°ï¼Œç”¨äºè·å–ä¿¡æ¯æˆ–æ‰§è¡Œæ“ä½œã€‚
+ **ç»“æ„åŒ–ç»“æœç±»å‹ï¼ˆStructured Result Typeï¼‰**ï¼šæŒ‡å®š LLM è¿è¡Œç»“æŸæ—¶å¿…é¡»è¿”å›çš„ç»“æ„åŒ–æ•°æ®ç±»å‹ã€‚
+ **ä¾èµ–ç±»å‹çº¦æŸï¼ˆDependency Type Constraintï¼‰**ï¼šç³»ç»Ÿæç¤ºå‡½æ•°ã€å·¥å…·å’Œç»“æœéªŒè¯å™¨åœ¨è¿è¡Œæ—¶å¯ä½¿ç”¨çš„ä¾èµ–é¡¹ã€‚
+ **LLM æ¨¡å‹ï¼ˆLLM Modelï¼‰**ï¼šä¸ä»£ç†å…³è”çš„é»˜è®¤ LLM æ¨¡å‹ï¼Œä¹Ÿå¯åœ¨è¿è¡Œæ—¶æŒ‡å®šã€‚
+ **æ¨¡å‹è®¾ç½®ï¼ˆModel Settingsï¼‰**ï¼šç”¨äºå¾®è°ƒè¯·æ±‚çš„å¯é€‰é»˜è®¤æ¨¡å‹è®¾ç½®ï¼Œä¹Ÿå¯åœ¨è¿è¡Œæ—¶æŒ‡å®šã€‚

> ğŸ’¡ åœ¨ç±»å‹æœ¯è¯­ä¸­ï¼Œä»£ç†åœ¨å…¶ä¾èµ–ç±»å‹å’Œç»“æœç±»å‹æ–¹é¢æ˜¯é€šç”¨çš„ï¼Œä¾‹å¦‚ï¼Œä¸€ä¸ªä»£ç†éœ€è¦ `Foobar` ç±»å‹çš„ä¾èµ–é¡¹å¹¶è¿”å› `list[str]` ç±»å‹çš„ç»“æœï¼Œåˆ™å…¶ç±»å‹ä¸º `Agent[Foobar, list[str]]`ã€‚
>

PydanticAI æä¾›äº†å¤šç§è¿è¡Œä»£ç†çš„æ–¹æ³•ï¼Œä»¥é€‚åº”ä¸åŒçš„ä½¿ç”¨åœºæ™¯ï¼š

1. **å¼‚æ­¥è¿è¡Œ**ï¼š`agent.run()` è¿”å›ä¸€ä¸ªåç¨‹ï¼Œé€‚ç”¨äºå¼‚æ­¥ç¯å¢ƒã€‚
2. **åŒæ­¥è¿è¡Œ**ï¼š`agent.run_sync()` æ˜¯ä¸€ä¸ªåŒæ­¥å‡½æ•°ï¼Œé€‚ç”¨äºåŒæ­¥ç¯å¢ƒã€‚
3. **æµå¼è¿è¡Œ**ï¼š`agent.run_stream()` è¿”å›ä¸€ä¸ªå¼‚æ­¥å¯è¿­ä»£å¯¹è±¡ï¼Œæ”¯æŒæµå¼å“åº”ã€‚
4. **è¿­ä»£è¿è¡Œ**ï¼š`agent.iter()` è¿”å›ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå…è®¸æ‰‹åŠ¨æ§åˆ¶ä»£ç†çš„è¿è¡Œè¿‡ç¨‹ã€‚

#### ğŸ“Œ åŠŸèƒ½å·¥å…·ï¼ˆFunction Toolsï¼‰
 PydanticAI çš„åŠŸèƒ½å·¥å…·ï¼ˆFunction Toolsï¼‰æœºåˆ¶å…è®¸ä»£ç†åœ¨è¿è¡Œæ—¶è°ƒç”¨å¤–éƒ¨å‡½æ•°ï¼Œä»¥è·å–é¢å¤–ä¿¡æ¯æˆ–æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„å“åº”èƒ½åŠ›ã€‚  

**æ³¨å†Œæ–¹å¼**ï¼š

+ ä½¿ç”¨ `@agent.tool` è£…é¥°å™¨æ³¨å†Œéœ€è¦è®¿é—®ä»£ç†ä¸Šä¸‹æ–‡çš„å·¥å…·ã€‚
+ ä½¿ç”¨ `@agent.tool_plain` è£…é¥°å™¨æ³¨å†Œä¸éœ€è¦è®¿é—®ä»£ç†ä¸Šä¸‹æ–‡çš„å·¥å…·ã€‚
+ é€šè¿‡ `Agent` æ„é€ å‡½æ•°çš„ `tools` å‚æ•°æ³¨å†Œå·¥å…·å‡½æ•°æˆ– `Tool` å®ä¾‹

** åŠ¨æ€åŠŸèƒ½å·¥å…·  **

PydanticAI æ”¯æŒåŠ¨æ€åŠŸèƒ½å·¥å…·ï¼Œå³å·¥å…·çš„å®šä¹‰å¯ä»¥åœ¨è¿è¡Œæ—¶æ ¹æ®ä¸Šä¸‹æ–‡è¿›è¡Œä¿®æ”¹æˆ–å†³å®šæ˜¯å¦åŒ…å«ã€‚è¿™é€šè¿‡ä¸ºå·¥å…·å®šä¹‰ä¸€ä¸ª `prepare` å‡½æ•°å®ç°ï¼Œè¯¥å‡½æ•°åœ¨æ¯æ¬¡è¿è¡Œæ—¶è¢«è°ƒç”¨ï¼Œä»¥è‡ªå®šä¹‰å·¥å…·çš„è¡Œä¸ºæˆ–å†³å®šæ˜¯å¦æ³¨å†Œè¯¥å·¥å…·

```python
# å®šä¹‰ prepare å‡½æ•°
async def only_if_42(ctx: RunContext[int], tool_def: ToolDefinition) -> Union[ToolDefinition, None]:
    if ctx.deps == 42:
        return tool_def

# å®šä¹‰å·¥å…·å¹¶æ³¨å†Œ prepare å‡½æ•°
@agent.tool(prepare=only_if_42)
def hitchhiker(ctx: RunContext[int], answer: str) -> str:
    return f'{ctx.deps} {answer}'

# è¿è¡Œä»£ç†
result = agent.run_sync('testing...', deps=41)
print(result.data)  # å·¥å…·æœªæ³¨å†Œ
result = agent.run_sync('testing...', deps=42)
print(result.data)  # å·¥å…·è¢«æ³¨å†Œå¹¶è°ƒç”¨
```

** å·¥å…·ä¸ç»“æ„åŒ–ç»“æœçš„å…³ç³»  **

å·¥å…·çš„å‚æ•°å’Œè¿”å›å€¼å¯ä»¥å®šä¹‰ä¸º Pydantic æ¨¡å‹ï¼Œä»è€Œç¡®ä¿æ•°æ®çš„ç»“æ„åŒ–å’Œç±»å‹å®‰å…¨ã€‚æ­¤å¤–ï¼ŒPydanticAI èƒ½å¤Ÿä»å‡½æ•°çš„æ–‡æ¡£å­—ç¬¦ä¸²ä¸­æå–å‚æ•°æè¿°ï¼Œè‡ªåŠ¨ç”Ÿæˆå·¥å…·çš„ JSON æ¨¡å¼ï¼Œå¢å¼ºæ¨¡å‹å¯¹å·¥å…·çš„ç†è§£ã€‚

#### ğŸ“Œ ç»“æœéªŒè¯
PydanticAI çš„ç»“æœæ¨¡å—ï¼ˆ`pydantic_ai.result`ï¼‰æä¾›äº†ç»“æ„åŒ–çš„æ–¹å¼æ¥å¤„ç†ä»£ç†ï¼ˆAgentï¼‰æ‰§è¡Œåçš„è¾“å‡ºï¼Œç¡®ä¿ç”Ÿæˆçš„å“åº”ç¬¦åˆé¢„æœŸçš„æ ¼å¼å’Œç±»å‹ã€‚

+ **ç»“æœç±»å‹ï¼ˆResult Typeï¼‰**ï¼šå®šä¹‰ä»£ç†æœŸæœ›çš„è¾“å‡ºæ ¼å¼ã€‚å¯ä»¥æ˜¯ç®€å•çš„ `str` ç±»å‹ï¼Œä¹Ÿå¯ä»¥æ˜¯å¤æ‚çš„ Pydantic æ¨¡å‹ã€‚
+ **ç»“æœå°è£…ç±»**ï¼š
+ `AgentRunResult`: ç”¨äºåŒæ­¥è¿è¡Œçš„ç»“æœå°è£…ã€‚
+ `StreamedRunResult`: ç”¨äºæµå¼å¤„ç†çš„ç»“æœå°è£…ã€‚
+ **ç»“æ„åŒ–å“åº”**ï¼šå½“ç»“æœç±»å‹ä¸º Pydantic æ¨¡å‹æ—¶ï¼ŒPydanticAI ä¼šè‡ªåŠ¨ç”Ÿæˆç›¸åº”çš„ JSON æ¨¡å¼ï¼Œå¹¶éªŒè¯æ¨¡å‹è¿”å›çš„æ•°æ®ï¼Œç¡®ä¿ç±»å‹å®‰å…¨å’Œç»“æ„ä¸€è‡´æ€§ã€‚

#### ğŸ“Œ ä¾èµ–æ³¨å…¥
PydanticAIæä¾›äº†ä¸€ä¸ªç‹¬ç‰¹çš„ä¾èµ–å…³ç³»æ³¨å…¥ç³»ç»Ÿï¼Œç”¨äºå‘ä»£ç†ç³»ç»Ÿã€æç¤ºã€å·¥å…·å’Œç»“æœéªŒè¯å™¨æä¾›æ•°æ®å’ŒæœåŠ¡ï¼Œè¿™å¯¹äºæµ‹è¯•ç‰¹åˆ«æœ‰ç”¨ã€‚

+ **å®šä¹‰ä¾èµ–é¡¹**ï¼šä¾èµ–é¡¹å¯ä»¥æ˜¯ä»»ä½• Python ç±»å‹ï¼Œé€šå¸¸ä½¿ç”¨æ•°æ®ç±»ï¼ˆ`@dataclass`ï¼‰æ¥å°è£…å¤šä¸ªä¾èµ–å¯¹è±¡ï¼Œå¦‚ API å¯†é’¥å’Œ HTTP å®¢æˆ·ç«¯ã€‚

```python
from dataclasses import dataclass
import httpx

@dataclass
class MyDeps:
    api_key: str
    http_client: httpx.AsyncClient
```

+ **æ³¨å†Œä¾èµ–ç±»å‹**ï¼šåœ¨åˆ›å»ºä»£ç†æ—¶ï¼Œé€šè¿‡ `deps_type` å‚æ•°æŒ‡å®šä¾èµ–é¡¹çš„æ•°æ®ç±»ç±»å‹ï¼Œä»¥å¯ç”¨ç±»å‹æ£€æŸ¥ã€‚

```python
from pydantic_ai import Agent

agent = Agent(
    model='openai:gpt-4o',
    deps_type=MyDeps
)
```

+ **è®¿é—®ä¾èµ–é¡¹**ï¼šåœ¨ç³»ç»Ÿæç¤ºå‡½æ•°ã€å·¥å…·å‡½æ•°å’Œç»“æœéªŒè¯å™¨ä¸­ï¼Œé€šè¿‡ `RunContext` ç±»å‹è®¿é—®ä¾èµ–é¡¹ã€‚`RunContext` ä½¿ç”¨æ³›å‹å‚æ•°æŒ‡å®šä¾èµ–é¡¹çš„ç±»å‹ï¼Œç¡®ä¿ç±»å‹å®‰å…¨ã€‚

```python
from pydantic_ai import RunContext

@agent.system_prompt
async def get_system_prompt(ctx: RunContext[MyDeps]) -> str:
    response = await ctx.deps.http_client.get(
        'https://example.com',
        headers={'Authorization': f'Bearer {ctx.deps.api_key}'}
    )
    return f'Prompt: {response.text}'
```

> ğŸ’¡ç³»ç»Ÿæç¤ºå‡½æ•°ã€å‡½æ•°å·¥å…· å’Œ ç»“æœéªŒè¯å™¨ <font style="color:rgba(0, 0, 0, 0.87);">éƒ½åœ¨ä»£ç†è¿è¡Œçš„å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œã€‚å¦‚æœè¿™äº›å‡½æ•°ä¸æ˜¯åç¨‹ï¼ˆä¾‹å¦‚</font>`async for`<font style="color:rgba(0, 0, 0, 0.87);">ï¼‰ï¼Œåˆ™ä¼šä½¿ç”¨</font>`run_in_executor` <font style="color:rgba(0, 0, 0, 0.87);">åœ¨çº¿ç¨‹æ± ä¸­è°ƒç”¨å®ƒä»¬ï¼Œå› æ­¤ï¼Œå¦‚æœä¾èµ–é¡¹æ‰§è¡Œ IO æ“ä½œï¼Œåˆ™æœ€å¥½ä½¿ç”¨</font>`async`<font style="color:rgba(0, 0, 0, 0.87);">æ–¹æ³•ï¼Œå°½ç®¡åŒæ­¥ä¾èµ–é¡¹ä¹Ÿå¯ä»¥æ­£å¸¸å·¥ä½œã€‚</font>
>

#### ğŸ“Œ ç±»å‹å®‰å…¨
æ ¹æ®å‰æ–‡å†…å®¹ï¼Œè¯¥æ¡†æ¶å¯ä»¥æ”¯æŒé€šè¿‡ä»¥ä¸‹å‡ ç§æ–¹å¼å®æ–½ç±»å‹å®‰å…¨ï¼š

+ Pydantic æ¨¡å‹
+ é™æ€ç±»å‹æ£€æŸ¥
+ è¿è¡Œæ—¶éªŒè¯
+ ç»“æ„åŒ–è¾“å‡º

åŒæ—¶ä¹Ÿæ”¯æŒé€šè¿‡ä¸ mypy å’Œ pyrite ç­‰é™æ€ç±»å‹æ£€æŸ¥å™¨é›†æˆï¼Œä½¿ç±»å‹æ£€æŸ¥å°½å¯èƒ½ç®€å•ã€‚

### æ¶ˆæ¯å†å²è®°å½•
#### **è®¿é—®æ¶ˆæ¯å†å²**
+ `RunResult` å’Œ `StreamedRunResult` å¯¹è±¡æä¾›äº†ä»¥ä¸‹æ–¹æ³•æ¥è®¿é—®æ¶ˆæ¯ï¼š
+ `all_messages()`: è¿”å›å½“å‰è¿è¡Œçš„æ‰€æœ‰æ¶ˆæ¯ï¼ŒåŒ…æ‹¬ç³»ç»Ÿæç¤ºã€ç”¨æˆ·è¾“å…¥å’Œæ¨¡å‹å“åº”ã€‚
+ `new_messages()`: ä»…è¿”å›å½“å‰è¿è¡Œä¸­æ–°ç”Ÿæˆçš„æ¶ˆæ¯ã€‚
+ `all_messages_json()` å’Œ `new_messages_json()`: åˆ†åˆ«è¿”å›ä¸Šè¿°æ–¹æ³•çš„ JSON å­—èŠ‚è¡¨ç¤ºã€‚

> ğŸ’¡åœ¨**æµå¼è¿è¡Œ**ï¼ˆ`run_stream`ï¼‰ä¸­ï¼Œæœ€ç»ˆçš„è¾“å‡ºæ¶ˆæ¯ä¸ä¼šç«‹å³åŒ…å«åœ¨ `all_messages()` ä¸­ï¼Œç›´åˆ°æµå®Œæˆåæ‰ä¼šæ·»åŠ è¿›æ¥ï¼Œå¦‚ä¸‹ç¤ºä¾‹æ‰€ç¤ºï¼š
>

```python
agent = Agent(model=llm, system_prompt='Be a helpful assistant.')

async def main():
    async with agent.run_stream('Tell me a joke.') as result:
        # incomplete messages before the stream finishes
        # print(result.all_messages())
        async for text in result.stream_text():
            print(text)
            #> Did you hear
            #> Did you hear about the toothpaste
            #> Did you hear about the toothpaste scandal? They called
            #> Did you hear about the toothpaste scandal? They called it Colgate.

        # complete messages once the stream finishes
        # print(result.all_messages())

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())

```

#### åœ¨å¤šè½®å¯¹è¯ä¸­ä¼ é€’æ¶ˆæ¯  
 åœ¨åç»­çš„ä»£ç†è¿è¡Œä¸­ï¼Œå¯ä»¥å°†å…ˆå‰çš„æ¶ˆæ¯ä¼ é€’ç»™ `message_history` å‚æ•°ï¼Œä»¥ç»´æŒå¯¹è¯ä¸Šä¸‹æ–‡  

```python
result2 = agent.run_sync('Explain?', message_history=result1.new_messages())
```

 å¦‚æœ `message_history` ä¸ä¸ºç©ºï¼Œç³»ç»Ÿæç¤ºå°†ä¸ä¼šè¢«é‡æ–°ç”Ÿæˆï¼Œå‡è®¾ç°æœ‰çš„æ¶ˆæ¯å†å²å·²åŒ…å«ç³»ç»Ÿæç¤ºã€‚  

####  å­˜å‚¨å’ŒåŠ è½½æ¶ˆæ¯  
 å¯ä»¥å°†æ¶ˆæ¯å†å²**åºåˆ—åŒ–**ä¸º JSON æ ¼å¼ï¼Œå­˜å‚¨åˆ°æ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿åç»­åŠ è½½å’Œä½¿ç”¨ï¼š  

```python
def log_messages(messages):
    serialized = [
        {
            "role": m.role if hasattr(m, "role") else "unknown", 
            "content": m.content if hasattr(m, "content") else str(m),
        }
        for m in messages
    ]
    with open("all_messages.json", "w") as f:
        json.dump(serialized, f, indent=2)
```

 è¿™ç§æ–¹å¼é€‚ç”¨äºæ„å»ºå¤šä»£ç†ç³»ç»Ÿï¼Œæˆ–åœ¨ä»£ç†å›¾ï¼ˆAgent Graphï¼‰ä¸­å…±äº«æ¶ˆæ¯å†å²ã€‚  

### **æµå¼è¾“å‡ºï¼ˆStreaming Outputï¼‰**
+ é€šè¿‡ `run_stream` æ–¹æ³•ï¼Œå¯ä»¥å¯åŠ¨ä¸€ä¸ªæµå¼ä¼šè¯ï¼Œé€æ­¥æ¥æ”¶æ¨¡å‹çš„è¾“å‡ºï¼š

```python
async with agent.run_stream('Tell me a joke.') as result:
    async for message in result.stream_text(delta=True):
        print(message)
```

+ åœ¨æµå¼è¾“å‡ºä¸­ï¼Œ`stream_text(delta=True)` æ–¹æ³•å…è®¸ä»¥å¢é‡çš„æ–¹å¼è·å–æ¨¡å‹çš„æ–‡æœ¬å“åº”ï¼Œé€‚ç”¨äºå®æ—¶æ˜¾ç¤ºæ¨¡å‹ç”Ÿæˆå†…å®¹çš„åœºæ™¯ã€‚

### æŒä¹…åŒ–ï¼ˆPersistenceï¼‰
**æ•°æ®æŒä¹…åŒ–æ–¹å¼**ï¼š 

+ PydanticAI ä½¿ç”¨ Pydantic æ¨¡å‹å®šä¹‰ç»“æ„åŒ–è¾“å‡ºï¼ˆå¦‚ BaseModelï¼‰ï¼Œè¿™äº›è¾“å‡ºå¯ä»¥åœ¨è¿è¡Œæ—¶é€šè¿‡å·¥å…·æˆ–å¤–éƒ¨æœåŠ¡ï¼ˆå¦‚æ•°æ®åº“ï¼‰æŒä¹…åŒ–ã€‚ä¾‹å¦‚ï¼Œä»£ç†è¿è¡Œçš„ç»“æœå¯ä»¥ä¿å­˜åˆ°å¤–éƒ¨æ•°æ®åº“ï¼ˆå¦‚ PostgreSQLï¼‰æˆ–æ–‡ä»¶ç³»ç»Ÿä¸­ã€‚
+ é€šè¿‡ä¾èµ–æ³¨å…¥ï¼ˆDependency Injectionï¼‰ï¼Œå¼€å‘è€…å¯ä»¥æ³¨å…¥æ•°æ®åº“è¿æ¥ï¼ˆå¦‚ DatabaseConnï¼‰ï¼Œå°†ä»£ç†ç”Ÿæˆçš„ç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚ SupportOutputï¼‰å†™å…¥æ•°æ®åº“æˆ–æŸ¥è¯¢å†å²æ•°æ®ã€‚
+ é›†æˆ **Pydantic Logfire** å¯æŒä¹…åŒ–æ—¥å¿—ã€è¿½è¸ªå’ŒæŒ‡æ ‡æ•°æ®åˆ° Logfire åç«¯ï¼Œæ”¯æŒ 30 å¤©ä¿ç•™æœŸï¼Œé€‚åˆè°ƒè¯•å’Œç›‘æ§ã€‚

**è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ä¸æ¶ˆæ¯å†å²**ï¼š 

+ PydanticAI æ”¯æŒé€šè¿‡ Messages and Chat History ä¼ é€’å…ˆå‰è¿è¡Œçš„æ¶ˆæ¯ï¼Œæä¾›çŸ­æœŸä¸Šä¸‹æ–‡æŒä¹…åŒ–ï¼Œé€‚åˆå¤šè½®å¯¹è¯åœºæ™¯ã€‚
+ é•¿æœŸä¸Šä¸‹æ–‡æŒä¹…åŒ–éœ€å¼€å‘è€…è‡ªè¡Œå®ç°ï¼Œä¾‹å¦‚é€šè¿‡å¤–éƒ¨çŠ¶æ€ç®¡ç†ï¼ˆå¦‚ Postgre ç­‰ï¼‰ä¿å­˜ä»£ç†çŠ¶æ€æˆ–æ¶ˆæ¯å†å²ã€‚

### è°ƒè¯•ä¸ç›‘æ§ï¼ˆDebugging and Monitoringï¼‰
Pydantic Logfire æ˜¯ä¸€ä¸ªç”±åˆ›å»ºå’Œç»´æŠ¤ Pydantic å’Œ PydanticAI çš„å›¢é˜Ÿå¼€å‘çš„å¯è§‚å¯Ÿæ€§å¹³å°ã€‚Logfire æ—¨åœ¨è§‚æµ‹æ•´ä¸ªåº”ç”¨ç¨‹åºï¼šGen AIã€ç»å…¸é¢„æµ‹ AIã€HTTP æµé‡ã€æ•°æ®åº“æŸ¥è¯¢ä»¥åŠç°ä»£åº”ç”¨ç¨‹åºæ‰€éœ€çš„ä¸€åˆ‡ã€‚PydanticAI å…·æœ‰å¯¹ Logfire çš„å†…ç½®ï¼ˆä½†å¯é€‰ï¼‰æ”¯æŒã€‚å¦‚æœå®‰è£…å¹¶é…ç½®äº† `logfire` è½¯ä»¶åŒ…å¹¶å¯ç”¨äº†ä»£ç†æ£€æµ‹ï¼Œåˆ™ä¼šå°†æœ‰å…³ä»£ç†è¿è¡Œçš„è¯¦ç»†ä¿¡æ¯å‘é€åˆ° Logfireã€‚å¦åˆ™ï¼Œå‡ ä¹æ²¡æœ‰å¼€é”€ï¼Œä¹Ÿä¸ä¼šå‘é€ä»»ä½•å†…å®¹ã€‚

> <font style="color:rgba(0, 0, 0, 0.87);">Logfire æ˜¯ä¸€ä¸ªå•†ä¸šæ”¯æŒçš„æ‰˜ç®¡å¹³å°ï¼Œå¹¶é€šè¿‡å¼€æº SDKï¼ˆMIT è®¸å¯ï¼‰å’Œæä¾›å…è´¹å¥—é¤é™ä½ä½¿ç”¨é—¨æ§›</font>
>

<font style="color:rgba(0, 0, 0, 0.87);">å®˜æ–¹ç•Œé¢ç¤ºä¾‹ï¼š</font>

![](pictures/logfire-weather-agent.png)

### åŸºäºå›¾çš„å¼‚æ­¥çŠ¶æ€æœº  
`**pydantic-graph**` æ˜¯ä¸€ä¸ªå®˜æ–¹ç‹¬ç«‹å‡ºæ¥çš„åº“ï¼Œå¯ç”¨äºæ„å»ºåŸºäºå›¾çš„å¼‚æ­¥çŠ¶æ€æœº ã€‚å®ƒä¸ä¾èµ–äº `pydantic-ai`ï¼Œå¯ç”¨äºä»»ä½•éœ€è¦å›¾æˆ–çŠ¶æ€æœºçš„å·¥ä½œæµï¼Œå¦‚ä»»åŠ¡è°ƒåº¦ã€æµç¨‹è‡ªåŠ¨åŒ–æˆ–äº‹ä»¶é©±åŠ¨ç³»ç»Ÿã€‚ å®ƒé‡‡ç”¨å›¾ç»“æ„ï¼ˆGraphï¼‰æ¥ç»„ç»‡èŠ‚ç‚¹ï¼ˆNodeï¼‰å’ŒçŠ¶æ€ï¼ˆStateï¼‰ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥ä»¥å£°æ˜å¼çš„æ–¹å¼å®šä¹‰å’Œæ‰§è¡Œå¤šæ­¥éª¤çš„æµç¨‹æ§åˆ¶ã€‚ 

è™½ç„¶**å›¾** å’Œ **çŠ¶æ€æœº**(FSM)  æ˜¯å¼ºå¤§çš„å·¥å…·ï¼Œèƒ½å¤Ÿå¸®åŠ©å»ºæ¨¡å’Œæ§åˆ¶å¤æ‚å·¥ä½œæµï¼Œä½†å®ƒä»¬å¹¶ä¸é€‚åˆæ¯ä¸€ä¸ªåœºæ™¯ã€‚å®˜æ–¹å¯¹è¿™å—çš„è¯´æ³•æ˜¯ï¼š å¦‚æœä½ ä¸å–œæ¬¢ Python çš„ç±»å‹æç¤ºï¼Œé‚£ä¹ˆè¿™ç§å›¾çš„æ–¹æ³•å¯èƒ½å¹¶ä¸é€‚åˆä½ ï¼Œå› ä¸º `pydantic-graph` ä¾èµ–**ç±»å‹æç¤º**å’Œ**æ³›å‹**ï¼Œä¸»è¦é¢å‘æœ‰ä¸€å®šåŸºç¡€çš„é«˜çº§å¼€å‘è€…å’Œæ›´å¤æ‚ä¸šåŠ¡éœ€æ±‚çš„æƒ…å†µã€‚ åœ¨ä½¿ç”¨å›¾ä¹‹å‰ï¼Œåº”è¯¥è€ƒè™‘æ˜¯å¦çœŸçš„éœ€è¦è¿™ä¹ˆå¤æ‚çš„å·¥å…·ã€‚

#### ğŸ“Œ æ ¸å¿ƒç»„ä»¶
`pydantic-graph` çš„ä¸»è¦ç»„ä»¶åŒ…æ‹¬ï¼š

+ **GraphRunContext**ï¼š<font style="color:rgba(0, 0, 0, 0.87);">å›¾è¿è¡Œçš„ä¸Šä¸‹æ–‡ï¼Œç±»ä¼¼äº PydanticAI çš„</font> `RunContext`<font style="color:rgba(0, 0, 0, 0.87);">ã€‚å®ƒä¿å­˜å›¾çš„çŠ¶æ€å’Œä¾èµ–é¡¹ï¼Œå¹¶åœ¨èŠ‚ç‚¹è¿è¡Œæ—¶ä¼ é€’ç»™èŠ‚ç‚¹ã€‚</font>
+ **BaseNode**ï¼š å®šä¹‰å›¾ä¸­æ‰§è¡Œçš„èŠ‚ç‚¹ã€‚èŠ‚ç‚¹é€šå¸¸ç”±ä»¥ä¸‹éƒ¨åˆ†ç»„æˆï¼š
    - åŒ…å«è°ƒç”¨èŠ‚ç‚¹æ—¶éœ€è¦çš„ä»»ä½•å¿…éœ€/å¯é€‰å‚æ•°çš„å­—æ®µ
    - æ‰§è¡ŒèŠ‚ç‚¹çš„ä¸šåŠ¡é€»è¾‘ï¼Œåœ¨ `run` æ–¹æ³•ä¸­
    - `run` æ–¹æ³•çš„è¿”å›æ³¨é‡Šï¼Œ`pydantic-graph` è¯»å–è¿™äº›æ³¨é‡Šä»¥ç¡®å®šèŠ‚ç‚¹çš„ä¼ å‡ºè¾¹
+ **End**ï¼šè¡¨ç¤ºå›¾çš„æ‰§è¡Œç»“æŸï¼Œè¿”å›æœ€ç»ˆç»“æœã€‚
+ **Graph**ï¼šç”±å¤šä¸ªèŠ‚ç‚¹ç»„æˆçš„å›¾ï¼Œç®¡ç†èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥å’Œæ‰§è¡Œæµç¨‹ã€‚  å›´ç»•ç±»å‹å®‰å…¨æœ‰ä¸‹é¢ä¸‰ä¸ªæ³›å‹ï¼š
    - <font style="color:rgb(31, 35, 40);">StateType</font>
    - <font style="color:rgb(31, 35, 40);">DepsType</font>
    - <font style="color:rgb(31, 35, 40);">ReturnType</font>

#### ğŸ“Œ ç‰¹æ€§äº®ç‚¹
+ **ç±»å‹å®‰å…¨**
    - **ç±»å‹æç¤ºä¸æ³›å‹æ”¯æŒ**ï¼špydanticai-graph åˆ©ç”¨ Python çš„ç±»å‹æç¤ºå’Œæ³›å‹æœºåˆ¶ï¼Œç¡®ä¿èŠ‚ç‚¹é—´æ•°æ®ä¼ é€’ã€çŠ¶æ€ç®¡ç†å’Œä¾èµ–æ³¨å…¥çš„ç±»å‹ä¸€è‡´æ€§ã€‚æ¯ä¸ªèŠ‚ç‚¹ï¼ˆç»§æ‰¿è‡ª BaseNodeï¼‰é€šè¿‡æ³›å‹å‚æ•°æ˜ç¡®æŒ‡å®šçŠ¶æ€ç±»å‹ï¼ˆStateTï¼‰ã€ä¾èµ–ç±»å‹ï¼ˆDepsTï¼‰å’Œè¿”å›ç±»å‹ï¼ˆRunEndTï¼‰ï¼Œåœ¨ç¼–è¯‘æ—¶å³å¯æ•è·ç±»å‹é”™è¯¯ã€‚
    - **åŠ¨æ€è¾¹ç¼˜ç±»å‹æ£€æŸ¥**ï¼šèŠ‚ç‚¹é€šè¿‡ run æ–¹æ³•çš„è¿”å›ç±»å‹æ³¨è§£å®šä¹‰å‡ºè¾¹ï¼ˆæŒ‡å‘ä¸‹ä¸€ä¸ªèŠ‚ç‚¹æˆ– Endï¼‰ï¼Œç¡®ä¿å›¾çš„ç»“æ„åœ¨ç±»å‹å±‚é¢æ˜¯å®‰å…¨çš„ã€‚ä¾‹å¦‚ï¼ŒUnion[AnotherNode, End[int]] å…è®¸èŠ‚ç‚¹åŠ¨æ€å†³å®šåç»­è·¯å¾„ï¼ŒåŒæ—¶ä¿æŒç±»å‹çº¦æŸã€‚
+ **å¼‚æ­¥æ”¯æŒ**
    - **å…¨å¼‚æ­¥èŠ‚ç‚¹æ‰§è¡Œ**ï¼šæ‰€æœ‰èŠ‚ç‚¹çš„ run æ–¹æ³•å‡ä¸ºå¼‚æ­¥ï¼ˆasync defï¼‰ï¼Œæ”¯æŒå¤„ç†å¼‚æ­¥æ“ä½œï¼Œå¦‚ç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶ IO æˆ–è°ƒç”¨å¤–éƒ¨ APIã€‚è¿™ä½¿å¾— `pydanticai-graph` éå¸¸é€‚åˆé«˜å¹¶å‘åœºæ™¯ï¼Œä¾‹å¦‚å®æ—¶æ•°æ®å¤„ç†æˆ–ä¸ LLM çš„äº¤äº’ã€‚
    - **å¼‚æ­¥è¿­ä»£**ï¼š<font style="color:rgba(0, 0, 0, 0.87);">æœ‰æ—¶ä½ å¸Œæœ›åœ¨å›¾æ‰§è¡Œæ—¶ç›´æ¥æ§åˆ¶æˆ–æ·±å…¥äº†è§£æ¯ä¸ªèŠ‚ç‚¹ã€‚æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨</font>` Graph.iter`<font style="color:rgba(0, 0, 0, 0.87);">æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è¿”å›ä¸€ä¸ª</font>**<font style="color:rgba(0, 0, 0, 0.87);">ä¸Šä¸‹æ–‡ç®¡ç†å™¨</font>**<font style="color:rgba(0, 0, 0, 0.87);">ï¼Œè¯¥ç®¡ç†å™¨äº§ç”Ÿä¸€ä¸ª</font>`GraphRun`<font style="color:rgba(0, 0, 0, 0.87);"> å¯¹è±¡ã€‚</font>`GraphRun`<font style="color:rgba(0, 0, 0, 0.87);"> æ˜¯å›¾ä¸­èŠ‚ç‚¹çš„å¼‚æ­¥å¯è¿­ä»£å¯¹è±¡ï¼Œå…è®¸ä½ åœ¨èŠ‚ç‚¹æ‰§è¡Œæ—¶è®°å½•æˆ–ä¿®æ”¹å®ƒä»¬</font>
+ **ä¾èµ–æ³¨å…¥**
    - **ç±»å‹å®‰å…¨çš„ä¾èµ–æ³¨å…¥**ï¼šé€šè¿‡ GraphRunContext.deps å’Œæ³›å‹å‚æ•° DepsTï¼Œæ”¯æŒåœ¨èŠ‚ç‚¹ä¸­æ³¨å…¥å¤–éƒ¨ä¾èµ–ï¼ˆå¦‚æ•°æ®åº“è¿æ¥ã€æ‰§è¡Œå™¨æˆ–é…ç½®å¯¹è±¡ï¼‰ã€‚å¼€å‘è€…å¯é€šè¿‡ dataclass æˆ– Pydantic æ¨¡å‹å®šä¹‰ä¾èµ–ç»“æ„ã€‚
    - **æµ‹è¯•å‹å¥½**ï¼šä¾èµ–æ³¨å…¥ä¾¿äºæ¨¡æ‹Ÿä¾èµ–é¡¹ï¼Œæ”¯æŒå•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥æ³¨å…¥æ¨¡æ‹Ÿçš„æ•°æ®åº“å®¢æˆ·ç«¯æˆ–æ—¥å¿—è®°å½•å™¨ã€‚
    - **è·¨è¿›ç¨‹æ”¯æŒ**ï¼šæ”¯æŒæ³¨å…¥å¦‚ ProcessPoolExecutor çš„èµ„æºï¼Œç”¨äºå°†è®¡ç®—ä»»åŠ¡å¸è½½åˆ°å•ç‹¬è¿›ç¨‹ï¼ˆå¦‚ deps_example.py ä¸­çš„ç¤ºä¾‹ï¼‰ã€‚

```python
@dataclass
class GraphDeps:
    executor: ProcessPoolExecutor

@dataclass
class Increment(BaseNode[None, GraphDeps]):
    foo: int
    async def run(self, ctx: GraphRunContext[None, GraphDeps]) -> DivisibleBy5:
        loop = asyncio.get_running_loop()
        result = await loop.run_in_executor(ctx.deps.executor, self.compute)
        return DivisibleBy5(result)
```

+ **çŠ¶æ€å›¾**
    - **çŠ¶æ€ä¼ é€’ä¸æ›´æ–°**ï¼šå›¾çš„çŠ¶æ€ï¼ˆStateT ç±»å‹ï¼Œé€šå¸¸ä¸ºæ•°æ®ç±»æˆ– Pydantic æ¨¡å‹ï¼‰å¯åœ¨èŠ‚ç‚¹é—´ä¼ é€’å’Œä¿®æ”¹ã€‚æ¯ä¸ªèŠ‚ç‚¹é€šè¿‡ GraphRunContext.state è®¿é—®å’Œæ›´æ–°çŠ¶æ€ï¼Œç±»ä¼¼ç”Ÿäº§çº¿ä¸Šé€æ­¥æ„å»ºçš„å·¥ä»¶ã€‚
    - **çµæ´»çŠ¶æ€ç®¡ç†**ï¼šæ”¯æŒæ— çŠ¶æ€å›¾ï¼ˆStateT é»˜è®¤ä¸º Noneï¼‰å’Œæœ‰çŠ¶æ€å›¾ï¼Œé€‚åº”ä»ç®€å•é€»è¾‘åˆ°å¤æ‚å¤šæ­¥å·¥ä½œæµçš„å„ç§åœºæ™¯ã€‚
+ **è¿­ä»£å›¾**
    - **å¼‚æ­¥è¿­ä»£ï¼ˆGraph.iterï¼‰**ï¼šGraph.iter æ–¹æ³•è¿”å›ä¸€ä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œäº§ç”Ÿ GraphRun å¯¹è±¡ï¼Œå…è®¸å¼€å‘è€…é€šè¿‡ async for é€èŠ‚ç‚¹è¿­ä»£å›¾çš„æ‰§è¡Œè¿‡ç¨‹ã€‚è¿™ç§æ–¹å¼é€‚åˆéœ€è¦ç²¾ç»†æ§åˆ¶æˆ–å®æ—¶ç›‘æ§çš„å·¥ä½œæµã€‚ **æ”¯æŒè®°å½•èŠ‚ç‚¹çŠ¶æ€ã€ä¿®æ”¹æ‰§è¡Œè·¯å¾„æˆ–æå‰ç»ˆæ­¢ã€‚**

```python
async def main():
    state = CountDownState(counter=3)
    async with count_down_graph.iter(CountDown(), state=state) as run:
        async for node in run:
            print('Node:', node)  # æ‰“å°æ¯ä¸ªèŠ‚ç‚¹
        print('Final result:', run.result.output)  # æ‰“å°æœ€ç»ˆç»“æœ

# Node: CountDown()
# Node: CountDown()
# Node: CountDown()
# Node: End(data=0)
# Final result: 0
```

+ **çŠ¶æ€æŒä¹…åŒ–**
    - **ä¸­æ–­ä¸æ¢å¤ï¼špydanticai-graph é€šè¿‡çŠ¶æ€æŒä¹…åŒ–æ”¯æŒå›¾æ‰§è¡Œçš„ä¸­æ–­å’Œæ¢å¤ï¼Œ**ç®€åŒ–äº†å¤„ç†æš‚åœã€ç”¨æˆ·è¾“å…¥æˆ–é•¿æ—¶é—´è¿è¡Œçš„å·¥ä½œæµã€‚**çŠ¶æ€æŒä¹…åŒ–åœ¨æ¯ä¸ªèŠ‚ç‚¹è¿è¡Œå‰åå¿«ç…§å›¾çŠ¶æ€ï¼Œå…è®¸ä»ä»»æ„ç‚¹æ¢å¤æ‰§è¡Œã€‚**
        * **SimpleStatePersistence**ï¼šå†…å­˜ä¸­ä¿å­˜æœ€æ–°å¿«ç…§ï¼Œé€‚åˆä¸´æ—¶è¿è¡Œï¼ˆé»˜è®¤å®ç°ï¼‰ã€‚
        * **FullStatePersistence****ï¼šå†…å­˜ä¸­ä¿å­˜æ‰€æœ‰å¿«ç…§å†å²ï¼Œé€‚åˆè°ƒè¯•æˆ–éœ€è¦å®Œæ•´æ‰§è¡Œè®°å½•çš„åœºæ™¯ã€‚**
        * **FileStatePersistence****ï¼šå°†å¿«ç…§ä¿å­˜ä¸º JSON æ–‡ä»¶ï¼Œé€‚åˆè·¨è¿›ç¨‹æˆ–æŒä¹…åŒ–å­˜å‚¨ã€‚**
        * **è‡ªå®šä¹‰æŒä¹…åŒ–ï¼šå¼€å‘è€…å¯é€šè¿‡ç»§æ‰¿ BaseStatePersistence å®ç°è‡ªå®šä¹‰å­˜å‚¨ï¼ˆå¦‚æ•°æ®åº“æŒä¹…åŒ–ï¼‰ã€‚**

#### ğŸ“Œ ç®€å•ç¤ºä¾‹
```python
from dataclasses import dataclass

from pydantic_graph import BaseNode, End, GraphRunContext


@dataclass
class MyNode(BaseNode[MyState, None, int]):  
    foo: int

    async def run(
        self,
        ctx: GraphRunContext[MyState],
    ) -> AnotherNode | End[int]:  
        if self.foo % 5 == 0:
            return End(self.foo)
        else:
            return AnotherNode()

async def main():
    graph = Graph(  
# é€šè¿‡å°†èŠ‚ç‚¹åˆ—è¡¨ä¼ é€’ç»™ Graph æ¥åˆ›å»ºå›¾ã€‚èŠ‚ç‚¹çš„é¡ºåºå¹¶ä¸é‡è¦ï¼Œä½†å®ƒå¯èƒ½ä¼šå½±å“å›¾çš„æ˜¾ç¤ºæ–¹å¼ã€‚
    nodes=[MyNode]
)
    state = MyState()
# åˆå§‹åŒ–çŠ¶æ€ã€‚è¿™å°†ä¼ é€’ç»™å›¾è¿è¡Œå¹¶åœ¨å›¾è¿è¡Œæ—¶å‘ç”Ÿå˜åŒ–ã€‚
    await graph.run(MyNode(), state=state)  
# ä½¿ç”¨åˆå§‹çŠ¶æ€è¿è¡Œå›¾ã€‚ç”±äºå›¾å¯ä»¥ä»ä»»ä½•èŠ‚ç‚¹è¿è¡Œï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»ä¼ é€’èµ·å§‹èŠ‚ç‚¹ â€”â€” åœ¨æœ¬ä¾‹ä¸­ä¸ºMyNode() ã€‚Graph.run è¿”å›ä¸€ä¸ª GraphRunResultï¼Œè¯¥ç»“æœæä¾›æœ€ç»ˆæ•°æ®å’Œè¿è¡Œå†å²è®°å½•ã€‚
```

+ `BaseNode[MachineState]`ï¼šè¡¨ç¤ºä¸€ä¸ªå›¾ä¸­çš„èŠ‚ç‚¹ï¼Œå¤„ç† `MachineState` ç±»å‹çš„çŠ¶æ€ã€‚æ¯ä¸ªèŠ‚ç‚¹éƒ½åŒ…å«ä¸šåŠ¡é€»è¾‘ï¼Œè¿è¡Œæ—¶ä¼šé€šè¿‡ `ctx` æ›´æ–°æˆ–è¯»å– `MachineState`ã€‚
+ `GraphRunContext[MachineState]`ï¼šè¡¨ç¤ºè¿è¡Œä¸Šä¸‹æ–‡ï¼ŒåŒ…å«å›¾è¿è¡Œæ—¶æ‰€éœ€çš„çŠ¶æ€ã€‚åœ¨æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œæ—¶ï¼Œ`GraphRunContext` æä¾›è®¿é—®ã€ä¿®æ”¹çŠ¶æ€çš„èƒ½åŠ›ã€‚

æ›´è¿›ä¸€æ­¥ï¼Œä»¥ä¸‹æ˜¯ä¸€ä¸ª**Graphç»“åˆAgent**çš„ç¤ºä¾‹ï¼š

```python
# Define the agents
@dataclass
class AgentResponse:
    property: bool
    field: str
    response: str

@dataclass
class AgentDeps:
    another_property: bool

agent_a = Agent(deps_type=AgentDeps, result_type=AgentResponse, system_prompt=..., tools=[...])
agent_b = Agent(deps_type=AgentDeps, result_type=AgentResponse, system_prompt=..., tools=[...])


# Graph state
class GraphState(BaseModel):
    user_prompt: str
    message_history: list[ModelMessage]
    graph_property: bool


# Graph nodes
class GraphNodeA(BaseNode[GraphState, None, str]):
    async def run(
        self, ctx: GraphRunContext[GraphState]
    ) -> GraphNodeA | GraphNodeB | End[str]:
        ...
        # extract relevant graph state into agent deps
        deps = AgentDeps(another_property = not ctx.state.graph_property)

        # run agent
        r: AgentRunResult[AgentResponse] = await agent_a.run(
            user_prompt=ctx.state.user_prompt, message_history=ctx.state.message_history, deps=deps
        )
        ...
        if r.data.property:
            return End(r.data.response)

        if r.data.field == "A":
            return GraphNodeA()

        return GraphNodeB()


class GraphNodeB(BaseNode[GraphState, None, str]):
    async def run(
        self, ctx: GraphRunContext[GraphState]
    ) -> GraphNodeA | GraphNodeB | End[str]:
        ...
       
        # extract relevant graph state into agent deps
        deps = AgentDeps(another_property = not ctx.state.graph_property)

        # run agent
        r: AgentRunResult[AgentResponse] = await agent_b.run(
            user_prompt=ctx.state.user_prompt, message_history=ctx.state.message_history, deps=deps
        )
        ...

        if r.data.property:
            return End(r.data.response)

        if r.data.field == "B":
            return GraphNodeB()

        return GraphNodeA()


# Define the graph
graph = Graph(nodes=[GraphNodeA, GraphNodeB])
state = GraphState(
    user_prompt="Hello, how are you?",
    message_history=[],
)

# Run the graph
r: GraphRunResult[GraphState, str] = await graph.run(
    start_node=GraphNodeA(), state=state
)

# Process the result
print(r.output)
```

#### ğŸ“Œ æ¡†æ¶å±€é™
+ æ³¨æ„ï¼Œç›®å‰ï¼Œå®˜æ–¹å°š**ä¸æ”¯æŒèŠ‚ç‚¹å¹¶è¡Œ**ï¼Œè§ [#704](https://github.com/pydantic/pydantic-ai/issues/704) ï¼Œ<font style="color:rgb(31, 35, 40);">å¦‚æœéœ€è¦è‡ªå·±å®ç°å¹¶è¡Œéœ€è¦è€ƒè™‘</font>**<font style="color:rgb(31, 35, 40);">èŠ‚ç‚¹é¡ºåºä¾èµ–</font>**<font style="color:rgb(31, 35, 40);">ï¼Œå³å¦‚ä½•çŸ¥é“ä½•æ—¶å¯åŠ¨ä¸€ä¸ªä¾èµ–å¤šä¸ªå…¶ä»–èŠ‚ç‚¹å®Œæˆçš„èŠ‚ç‚¹ï¼Ÿ</font>
+ å½“å‰ pydanticai-graph** ç¼ºä¹å†…ç½®çš„æµå¼è¾“å‡ºæ”¯æŒ**ï¼Œéœ€è¦è‡ªå·±å®ç°ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç±»å‹ã€ä»£ç†å†…éƒ¨é€»è¾‘å’Œé¡¶å±‚å›¾åˆ†åˆ«å®ç°æµå¼è¾“å‡ºé€»è¾‘ã€‚è¿™å¯¼è‡´ï¼š 
    - ä»£ç é‡å¤ï¼šå¤§å®¶éƒ½åœ¨é‡å¤é€ ç±»ä¼¼è½®å­ã€‚
    - å¤æ‚æ€§ï¼šå®ç°æµå¼è¾“å‡ºéœ€è¦æ·±å…¥äº†è§£ä»£ç†çš„å›¾ç»“æ„ã€èŠ‚ç‚¹é€»è¾‘å’Œå›¾çš„ç»„åˆæ–¹å¼ã€‚
    - æœ€å¥½é€šè¿‡ç®€å•çš„ APIï¼ˆå¦‚ graph.iterï¼‰å®ç°é¡¶å±‚å›¾çš„æµå¼è¾“å‡ºï¼Œç±»ä¼¼äº LangGraph çš„ graph.stream æ–¹æ³•ï¼Œèƒ½å¤Ÿé€ä¸ªäº§ç”Ÿäº‹ä»¶æˆ–æ¶ˆæ¯ï¼Œè€Œæ— éœ€ç­‰å¾…æ•´ä¸ªå›¾æ‰§è¡Œå®Œæˆï¼Œç±»ä¼¼ä¸‹é¢è¿™æ ·ï¼š

```python
async with graph.iter(start_node=GraphNodeA(), state=state) as graph_run:
    async for node in graph_run:
        async with node.stream(graph_run.ctx) as node_stream:
            async for event in node_stream:
                yield event
```

+ pydanticai-graphç›®å‰**ä¸æ”¯æŒå†…ç½®çš„åµŒå¥—å­å›¾ï¼ˆpipelineï¼‰åŠŸèƒ½**ï¼Œå³æ— æ³•ç›´æ¥å°†ä¸€ä¸ª Graph å®ä¾‹ä½œä¸ºå¦ä¸€ä¸ªå›¾çš„ BaseNode èŠ‚ç‚¹ã€‚è™½ç„¶å¯ä»¥é€šè¿‡æ‰‹åŠ¨å°è£…å­å›¾çš„é€»è¾‘åœ¨èŠ‚ç‚¹ä¸­è°ƒç”¨å­å›¾çš„æ‰§è¡Œï¼Œä»è€Œå®ç°ç±»ä¼¼åµŒå¥—çš„æ•ˆæœï¼Œä½†è¿™ç§æ–¹æ³•éœ€è¦å¼€å‘è€…æ˜¾å¼ç®¡ç†å­å›¾çš„æ‰§è¡Œå’ŒçŠ¶æ€ä¼ é€’ã€‚ 

---

# AutoGen
## åŸºæœ¬ä»‹ç»
AutoGen æ˜¯ç”±å¾®è½¯å¼€å‘çš„ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºæ„å»ºåä½œå¼å¯¹è¯ AI ä»£ç†ï¼Œèƒ½å¤Ÿé€šè¿‡å¤šä»£ç†å¯¹è¯å®Œæˆå¤æ‚ä»»åŠ¡ã€‚å®ƒå…è®¸å¼€å‘è€…åˆ›å»ºå¤šä»£ç†ç³»ç»Ÿï¼Œä»£ç†é€šè¿‡æ¶ˆæ¯äº¤æ¢åä½œï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªä¸»æˆ–ç»“åˆäººç±»è¾“å…¥å®Œæˆä»»åŠ¡ã€‚AutoGen æ”¯æŒçµæ´»çš„ä»£ç†é…ç½®ã€å·¥å…·é›†æˆå’Œå¯¹è¯é©±åŠ¨çš„å·¥ä½œæµï¼Œé€‚ç”¨äºéœ€è¦åŠ¨æ€ä»£ç†åè°ƒçš„åœºæ™¯ï¼Œå¦‚ä»£ç ç”Ÿæˆã€æ•°æ®åˆ†æå’Œä»»åŠ¡è‡ªåŠ¨åŒ–ã€‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

+ **å¤šä»£ç†å¯¹è¯**ï¼šä»£ç†é€šè¿‡æ¶ˆæ¯åä½œï¼Œæ¯ä¸ªä»£ç†å¯æ‹¥æœ‰ç‰¹å®šè§’è‰²æˆ–å·¥å…·ã€‚
+ **çµæ´»ä»£ç†ç±»å‹**ï¼šæ”¯æŒåŸºäº LLM çš„ä»£ç†ã€äººç±»å‚ä¸ä»£ç†å’Œå·¥å…·æ‰§è¡Œä»£ç†ã€‚
+ **å·¥å…·é›†æˆ**ï¼šä»£ç†å¯è°ƒç”¨å¤–éƒ¨å·¥å…·æˆ–å‡½æ•°ï¼Œå¦‚ä»£ç æ‰§è¡Œæˆ– API è¯·æ±‚ã€‚
+ **å¯¹è¯æ¨¡å¼**ï¼šæ”¯æŒè‡ªå®šä¹‰å¯¹è¯æµï¼ŒåŒ…æ‹¬é¡ºåºã€ç¾¤èŠæˆ–å±‚æ¬¡ç»“æ„ã€‚
+ **äººç±»åé¦ˆ**ï¼šæ”¯æŒæ— ç¼é›†æˆäººç±»è¾“å…¥ä»¥æŒ‡å¯¼æˆ–éªŒè¯ä»£ç†è¡Œä¸ºã€‚

AutoGen é€‚ç”¨äºéœ€è¦è¿­ä»£æ¨ç†å’Œåä½œçš„ä»»åŠ¡ï¼Œç›¸è¾ƒäºåŸºäºå›¾çš„æ¡†æ¶å¦‚ LangGraphï¼Œå…¶æ¶æ„æ›´è½»é‡ä¸”æ‰©å±•æ€§å¼ºã€‚

_å®˜æ–¹å‚è€ƒ_ï¼š[AutoGen æ–‡æ¡£](https://microsoft.github.io/autogen/)ï¼Œ[AutoGen GitHub](https://github.com/microsoft/autogen)ã€‚

## æ¡†æ¶æµ‹è¯„
### ä½¿ç”¨è¯´æ˜
AutoGen é€šè¿‡å¯¹è¯ä»£ç†ç»„ç»‡å·¥ä½œæµï¼Œä»£ç†åä½œå®Œæˆä»»åŠ¡ã€‚å¯¹äº PDF è§£æä¸æ‘˜è¦ä»»åŠ¡ï¼Œå¯å®šä¹‰ **PDF è§£æä»£ç†**ï¼ˆæå–æ–‡æœ¬ï¼‰å’Œ **æ‘˜è¦ä»£ç†**ï¼ˆç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ï¼‰ã€‚æ¯ä¸ªä»£ç†é…ç½®è§’è‰²ã€LLM æˆ–å·¥å…·ã€‚ã€

```python
from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

# Configure LLM (e.g., OpenAI or local model)
config_list = config_list_from_json("OAI_CONFIG_LIST")

# Define agents
parser_agent = AssistantAgent(
    name="PDFParser",
    system_message="Extract text chunks from a PDF and return structured data.",
    llm_config={"config_list": config_list}
)
summarizer_agent = AssistantAgent(
    name="Summarizer",
    system_message="Summarize provided text chunks into a structured format with problem_definition, problem_value, and existing_solutions.",
    llm_config={"config_list": config_list}
)
user_proxy = UserProxyAgent(
    name="User",
    human_input_mode="NEVER",
    code_execution_config={"work_dir": "output"}
)

# Initiate conversation
user_proxy.initiate_chat(
    parser_agent,
    message="Parse the PDF at 'upload/pdf/ai_foreveryone.pdf' and pass the text to the summarizer."
)

# Summarizer receives parsed text and generates summary
parser_agent.send(
    message="Here are the parsed text chunks: {...}",
    recipient=summarizer_agent
)
```

### çŠ¶æ€ç®¡ç†
AutoGen é€šè¿‡ **å¯¹è¯å†å²** ç®¡ç†çŠ¶æ€ï¼Œæ¯ä¸ªä»£ç†ç»´æŠ¤æ¶ˆæ¯æ—¥å¿—ï¼ˆåŒ…å«å‘é€è€…ã€æ¥æ”¶è€…å’Œå†…å®¹çš„å­—å…¸åˆ—è¡¨ï¼‰ã€‚çŠ¶æ€é€šè¿‡æ¶ˆæ¯éšå¼ä¼ é€’ï¼Œä¸åƒ LangGraph ä½¿ç”¨é›†ä¸­å¼ StateGraphã€‚å¼€å‘è€…å¯è®¿é—®æˆ–ä¿®æ”¹å¯¹è¯å†å²ä»¥è·Ÿè¸ªä»»åŠ¡è¿›åº¦ã€‚

+ **æœºåˆ¶**ï¼šä»£ç†çš„ chat_messages å­—å…¸å­˜å‚¨å¯¹è¯çŠ¶æ€ã€‚PDF ä»»åŠ¡ä¸­ï¼Œè§£æä»£ç†çš„è¾“å‡ºï¼ˆæ–‡æœ¬å—ï¼‰ä½œä¸ºæ¶ˆæ¯ä¼ é€’ç»™æ‘˜è¦ä»£ç†ã€‚
+ **å±€é™**ï¼šæ— å†…ç½®ç±»å‹åŒ–çŠ¶æ€schemaï¼ˆå¦‚ TypedDict æˆ– Pydanticï¼‰ï¼Œéœ€æ‰‹åŠ¨ç¡®ä¿æ¶ˆæ¯ä¸€è‡´æ€§ã€‚
+ **å®šåˆ¶**ï¼šå¯å®šä¹‰è‡ªå®šä¹‰çŠ¶æ€å¯¹è±¡å¹¶ä½œä¸ºæ¶ˆæ¯è´Ÿè½½ä¼ é€’ï¼Œä½†éœ€æ‰‹åŠ¨å®ç°ã€‚

### ç»†ç²’åº¦æ§åˆ¶
AutoGen é€šè¿‡å¯¹è¯æ¨¡å¼å’Œä»£ç†é…ç½®æä¾›çµæ´»æ§åˆ¶ï¼š

+ **é¡ºåºå·¥ä½œæµ**ï¼šä»£ç†æŒ‰é¢„å®šé¡ºåºé€šä¿¡ï¼ˆå¦‚è§£æ â†’ æ‘˜è¦ï¼‰ã€‚
+ **ç¾¤èŠ**ï¼šé€šè¿‡ GroupChatManager ç®¡ç†å¤šä»£ç†åä½œï¼Œé€‚åˆå¹¶è¡Œä»»åŠ¡ï¼ˆå¦‚åŒæ—¶è§£æå’Œå…³é”®è¯æå–ï¼‰ã€‚
+ **æ¡ä»¶é€»è¾‘**ï¼šä»£ç†å¯é€šè¿‡åˆ†ææ¶ˆæ¯å†…å®¹æˆ–å·¥å…·å‡½æ•°ä¸­çš„è‡ªå®šä¹‰ä»£ç å®ç°åˆ†æ”¯ã€‚
+ **é‡è¯•**ï¼šæ”¯æŒé€šè¿‡ LLM å“åº”éªŒè¯æˆ–è‡ªå®šä¹‰é”™è¯¯å¤„ç†å®ç°é‡è¯•ã€‚

```python
# Conditional branching example
def parse_document(message):
    text_chunks = extract_pdf_text(message["pdf_path"])
    if len(text_chunks) == 0:
        return {"error": "Empty PDF"}
    return {"text_chunks": text_chunks}

parser_agent.register_function(parse_document)
```

### å¼‚æ­¥æ‰§è¡Œ
AutoGen é€šè¿‡ Python çš„ asyncio æ”¯æŒå¼‚æ­¥æ‰§è¡Œã€‚ä»£ç†å¯å¹¶å‘å¤„ç†æ¶ˆæ¯æˆ–æ‰§è¡Œå·¥å…·ï¼Œé€‚åˆ I/O å¯†é›†ä»»åŠ¡å¦‚ API è°ƒç”¨æˆ– LLM æ¨ç†ã€‚

```python
import asyncio
from autogen import AssistantAgent

# Async PDF parsing simulation
async def async_parse_pdf(pdf_path):
    return {"text_chunks": ["Sample text"]}

parser_agent = AssistantAgent(
    name="AsyncParser",
    system_message="Parse PDF asynchronously.",
    llm_config={"config_list": config_list}
)
parser_agent.register_async_function(async_parse_pdf)

# Run async conversation
async def main():
    result = await parser_agent.a_initiate_chat(
        recipient=user_proxy,
        message={"pdf_path": "upload/pdf/ai_foreveryone.pdf"}
    )
asyncio.run(main())
```

### åˆ†å¸ƒå¼æ”¯æŒ
AutoGen æ— å†…ç½®åˆ†å¸ƒå¼è®¡ç®—æ”¯æŒï¼ˆå¦‚ Ray æˆ– Daskï¼‰ã€‚å¯é€šè¿‡åœ¨ä¸åŒè¿›ç¨‹æˆ–æœºå™¨ä¸Šè¿è¡Œä»£ç†å¹¶é€šè¿‡ API æˆ–æ¶ˆæ¯é˜Ÿåˆ—é€šä¿¡å®ç°åˆ†å¸ƒå¼ï¼Œä½†éœ€è‡ªå®šä¹‰ç¼–æ’ã€‚

### æµå¼è¾“å‡º
AutoGen é€šè¿‡å…¼å®¹çš„ LLM æä¾›å•†ï¼ˆå¦‚ OpenAI çš„æµå¼ APIï¼‰æ”¯æŒ LLM å“åº”çš„æµå¼è¾“å‡ºã€‚æµå¼ä¸­é—´ç»“æœï¼ˆå¦‚è§£æè¿‡ç¨‹ä¸­çš„éƒ¨åˆ†æ–‡æœ¬å—ï¼‰éœ€è‡ªå®šä¹‰å®ç°ï¼Œå› å¯¹è¯æ¨¡å‹é€šå¸¸ç­‰å¾…å®Œæ•´æ¶ˆæ¯ã€‚

```python
# Enable streaming for LLM output
parser_agent.llm_config["stream"] = True
user_proxy.initiate_chat(
    parser_agent,
    message="Parse and stream text chunks from the PDF."
)
```

> ğŸ’¡æµå¼è¾“å‡ºé™äº LLM å“åº”ï¼Œéå·¥ä½œæµäº‹ä»¶ï¼ˆå¦‚ LangGraph çš„ graph.streamï¼‰ã€‚
>

### æŒä¹…åŒ–
AutoGen æ— å†…ç½®çŠ¶æ€æŒä¹…åŒ–æ”¯æŒï¼Œéœ€æ‰‹åŠ¨å°†å¯¹è¯å†å²ä¿å­˜åˆ°æ–‡ä»¶æˆ–æ•°æ®åº“ï¼ˆå¦‚ JSONã€SQLiteï¼‰ï¼Œä¾‹å¦‚ï¼š

```python
import json
# Save state after each message
def save_state(state):
    with open("state.json", "w") as f:
        json.dump(state, f)

parser_agent.on_message(lambda msg: save_state(msg))
```

##### 8. æ—¥å¿—ä¸å¯è§‚æµ‹æ€§
AutoGen é€šè¿‡ Python çš„ logging æ¨¡å—æä¾›åŸºæœ¬æ—¥å¿—ï¼Œè®°å½•ä»£ç†äº¤äº’å’Œé”™è¯¯ã€‚å¯å¯ç”¨è¯¦ç»†æ¨¡å¼æˆ–é›†æˆ LangSmith è¿›è¡Œ LLM è°ƒç”¨è¿½è¸ªï¼Œ**æ— å†…ç½®å¯¹è¯æµå¯è§†åŒ–**ã€‚

---

# CrewAI
## åŸºæœ¬ä»‹ç»
 CrewAI æ˜¯ä¸€ä¸ªä»¥â€œå›¢é˜Ÿâ€æ¦‚å¿µä¸ºæ ¸å¿ƒçš„æ™ºèƒ½ä»£ç†æ¡†æ¶ï¼Œä¸»æ‰“å¤šä»£ç†åä½œã€‚å®ƒé€šè¿‡å…±äº«å†…å­˜ã€æ¶ˆæ¯ä¼ é€’å’Œä»£ç†è‡ªåŠ¨è¿æ¥ç­‰æœºåˆ¶ï¼ŒæŠŠå¤šä»£ç†åä½œä¸­çš„å¸¸è§åŠŸèƒ½å°è£…æˆå¯å¤ç”¨æ¨¡å—ï¼Œé™ä½äº†å¼€å‘å¤æ‚åº¦ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶å°±èƒ½å¿«é€Ÿæ­å»ºç³»ç»Ÿï¼ŒéæŠ€æœ¯äººå‘˜ä¹Ÿèƒ½å‚ä¸ã€‚æ•´ä½“æ¥çœ‹ï¼ŒCrewAI ä¸Šæ‰‹ç®€å•ã€åä½œèƒ½åŠ›å¼ºï¼Œé€‚åˆç”¨æ¥æ„å»ºéœ€è¦å¤šæ™ºèƒ½ä½“ååŒå·¥ä½œçš„åº”ç”¨ã€‚  <font style="color:rgb(36, 36, 36);">ä¸ LangGraph çš„ç¡®å®šæ€§ç»“æ„ä¸åŒï¼ŒCrewAI ä»£ç†æ—¨åœ¨çªå‡ºè‡ªä¸»å’Œåä½œã€‚</font>

**<font style="color:rgb(36, 36, 36);">ä¸»è¦ç»„æˆï¼š</font>**

+ **CrewAI Crews**ï¼šé’ˆå¯¹è‡ªä¸»æ€§å’Œåä½œæ™ºèƒ½è¿›è¡Œä¼˜åŒ–ï¼Œä½¿å¾—èƒ½å¤Ÿè‡ªç”±ç»„å»ºçš„AIå›¢é˜Ÿï¼Œå…¶ä¸­æ¯ä¸ªä»£ç†éƒ½æœ‰ç‰¹å®šçš„è§’è‰²ã€å·¥å…·å’Œç›®æ ‡ã€‚
+ **CrewAI Flows**ï¼šæ”¯æŒç²¾ç»†ã€äº‹ä»¶é©±åŠ¨çš„æ§åˆ¶ã€å•ä¸ª LLM è°ƒç”¨ä»¥å®ç°ç²¾ç¡®çš„ä»»åŠ¡ç¼–æ’ï¼Œå¹¶åŸç”Ÿæ”¯æŒ Crewsã€‚

**æŠ€æœ¯ç‰¹ç‚¹ï¼š**

**Crewsï¼šå›¢é˜Ÿå¼å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**

+ Crews æ˜¯ç”±å¤šä¸ª AI ä»£ç†ç»„æˆçš„åä½œå°ç»„ï¼Œæ¯ä¸ªä»£ç†éƒ½æ‰®æ¼”ä¸€ä¸ªå…·ä½“è§’è‰²ï¼ˆå¦‚ researcherã€writerï¼‰ï¼Œå¹¶å¯é…ç½®ä¸“å±å·¥å…·ï¼ˆå¦‚ç½‘é¡µçˆ¬è™«ã€æ–‡æ¡£è¯»å–å™¨ï¼‰å’Œç›®æ ‡ä»»åŠ¡ã€‚
+ ä»£ç†ä¹‹é—´æ”¯æŒæ¶ˆæ¯ä¼ é€’å’Œå…±äº«è®°å¿†ï¼Œå…·å¤‡ä¸€å®šçš„è‡ªä¸»åä½œèƒ½åŠ›ã€‚ä½ å¯ä»¥ç”¨ä»£ç æˆ– YAML æ–‡ä»¶æ¥å®šä¹‰ Crewsï¼Œå…¶ä¸­ YAML æ›´é€‚åˆå¤šäººåä½œå’Œå¤§è§„æ¨¡é¡¹ç›®ã€‚
+ Crews çš„é…ç½®çµæ´»ï¼Œæ”¯æŒä»»åŠ¡åˆ—è¡¨ã€æ‰§è¡Œé¡ºåºï¼ˆé¡ºåºæˆ–åµŒå¥—ï¼‰ã€æœ€å¤§è¯·æ±‚é¢‘ç‡ï¼ˆmax_rpmï¼‰ã€çŸ­æœŸ/é•¿æœŸ/å®ä½“è®°å¿†æœºåˆ¶ã€ç¼“å­˜æœºåˆ¶ã€åµŒå…¥å™¨ç­‰ã€‚åŒæ—¶è¿˜æ”¯æŒ step/task å›è°ƒå‡½æ•°å’Œæ—¥å¿—è¾“å‡ºï¼Œå¯ç”¨äºè°ƒè¯•å’Œç›‘æ§ã€‚

**Flowsï¼šæµç¨‹çº§ä»»åŠ¡ç¼–æ’ç³»ç»Ÿ**

+ Flows æ˜¯ä¸€ç§äº‹ä»¶é©±åŠ¨çš„å·¥ä½œæµæœºåˆ¶ï¼Œç”¨äºç»„ç»‡å’Œæ§åˆ¶å¤šä¸ªä»»åŠ¡æˆ– Crews çš„æ‰§è¡Œæµç¨‹ã€‚é€‚åˆæ„å»ºä»æ•°æ®æ”¶é›†åˆ°æ‰§è¡Œå†åˆ°ç”Ÿæˆçš„å¤šæ­¥éª¤æµç¨‹ã€‚
+ å®ƒæ”¯æŒæ¡ä»¶åˆ¤æ–­ï¼ˆå¦‚ or_ / and_ï¼‰ã€æµç¨‹åˆ†æ”¯ã€å¾ªç¯æ‰§è¡Œç­‰é€»è¾‘æ§åˆ¶ã€‚ä½ å¯ä»¥é€šè¿‡è£…é¥°å™¨ï¼ˆå¦‚ `@start`ã€`@listen`ã€`@router`ï¼‰æ¥å®šä¹‰æµç¨‹å…¥å£ã€ç›‘å¬äº‹ä»¶å’Œå†³ç­–è·¯å¾„ã€‚
+ Flows æ—¢å¯ä»¥ä¸²è”å¤šä¸ªä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥åµŒå¥—å¤šä¸ª Crewsï¼Œå®ç°â€œæ™ºèƒ½åä½œ + ç²¾å‡†æ§åˆ¶â€çš„ç»„åˆã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å†…ç½®çŠ¶æ€ç®¡ç†ï¼ˆæ”¯æŒç»“æ„åŒ–æˆ–éç»“æ„åŒ–çŠ¶æ€ï¼‰ã€æŒä¹…åŒ–ï¼ˆåŸºäº SQLiteï¼‰å’Œæµç¨‹å¯è§†åŒ–åŠŸèƒ½ï¼Œå¸®åŠ©å¼€å‘è€…æ›´å¥½åœ°ç†è§£å’Œè°ƒè¯•æµç¨‹é€»è¾‘ã€‚

> _å®˜æ–¹å‚è€ƒ_ï¼š[CrewAI æ–‡æ¡£](https://docs.crewai.com/)ï¼Œ[CrewAI GitHub](https://github.com/joaomdmoreno/crewai)ã€‚
>

## æ¡†æ¶æµ‹è¯„
### ä½¿ç”¨è¯´æ˜
+ <font style="color:rgb(36, 36, 36);">åˆ›å»ºAgent â†’ å®šä¹‰å…·æœ‰ç‹¬ç‰¹æŠ€èƒ½çš„ AI Agentã€‚</font>
+ <font style="color:rgb(36, 36, 36);">åˆ†é…è§’è‰² â†’ æ¯ä¸ªAgentéƒ½æœ‰ä¸€ä¸ªè§’è‰²ï¼ˆä¾‹å¦‚ï¼Œç ”ç©¶å‘˜ã€ä½œå®¶ã€éªŒè¯è€…ï¼‰ã€‚</font>
+ <font style="color:rgb(36, 36, 36);">æ‰§è¡Œ Crew Task â†’ Agent åä½œå®ç°ç›®æ ‡ã€‚</font>

```python
from crewai import Agent, Crew, Task

# Define Agents
researcher = Agent(role="Researcher", goal="Find recent AI advancements")
writer = Agent(role="Writer", goal="Summarize research into an article")

# Define Task
task = Task(agents=[researcher, writer], objective="Write an article on AI trends")

# Create and Run Crew
crew = Crew(agents=[researcher, writer], tasks=[task])
result = crew.kickoff()
print(result)
```

### çŠ¶æ€ç®¡ç†
+ **Crews**ï¼š
    - çŠ¶æ€é€šè¿‡ä»£ç†é—´æ¶ˆæ¯ä¼ é€’å’Œå…±äº«è®°å¿†ç®¡ç†ã€‚
    - æ”¯æŒçŸ­æœŸè®°å¿†ï¼ˆå½“å‰ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼‰ã€é•¿æœŸè®°å¿†ï¼ˆè·¨ä»»åŠ¡å­¦ä¹ ï¼‰å’Œå®ä½“è®°å¿†ï¼ˆç‰¹å®šå¯¹è±¡ä¿¡æ¯ï¼‰ã€‚
    - ç¼“å­˜æœºåˆ¶å­˜å‚¨å·¥å…·æ‰§è¡Œç»“æœï¼Œæé«˜é‡å¤ä»»åŠ¡æ•ˆç‡ã€‚
+ **Flows**ï¼š
    - å†…ç½®çŠ¶æ€ç®¡ç†ï¼Œæ”¯æŒä»»åŠ¡é—´çŠ¶æ€å…±äº«ã€‚
    - çŠ¶æ€å¯ä¸ºç»“æ„åŒ–ï¼ˆPydantic BaseModelï¼‰æˆ–éç»“æ„åŒ–ï¼ˆå­—å…¸ï¼‰ï¼Œæ¯å®ä¾‹æœ‰å”¯ä¸€ UUIDã€‚
    - é€šè¿‡ @persist è£…é¥°å™¨å®ç°çŠ¶æ€æŒä¹…åŒ–ï¼Œé»˜è®¤ä½¿ç”¨ SQLite åç«¯ã€‚

### ç»†ç²’åº¦æ§åˆ¶
+ **Crews**ï¼š
    - é«˜å±‚æ¬¡æ§åˆ¶ï¼Œé€šè¿‡è§’è‰²åˆ†é…ã€ç›®æ ‡è®¾å®šå’Œæµç¨‹ç±»å‹ï¼ˆé¡ºåºæˆ–å±‚æ¬¡ï¼‰ç®¡ç†ã€‚
    - å±‚æ¬¡æ¨¡å¼ä¸‹ï¼Œç®¡ç†ä»£ç†åŠ¨æ€åˆ†é…ä»»åŠ¡ï¼Œæ”¯æŒæ¡ä»¶é€»è¾‘ã€‚
    - æ”¯æŒä»»åŠ¡é‡è¯•ï¼ˆmax_retriesï¼‰å’Œå›è°ƒå‡½æ•°ï¼Œå¢å¼ºæ§åˆ¶èƒ½åŠ›ã€‚
+ **Flows**ï¼š
    - ç»†ç²’åº¦æ§åˆ¶ï¼Œæ”¯æŒï¼š
        * æ¡ä»¶é€»è¾‘ï¼ˆor_ã€and_ï¼‰ã€‚
        * å¾ªç¯å’Œåˆ†æ”¯ï¼ˆé€šè¿‡ @router è£…é¥°å™¨ï¼‰ã€‚
        * äº‹ä»¶é©±åŠ¨è§¦å‘ï¼ˆé€šè¿‡ @listen å“åº”äº‹ä»¶ï¼‰ã€‚
    - å…è®¸ç²¾ç¡®å®šä¹‰ä»»åŠ¡ä¾èµ–å’Œæ‰§è¡Œé¡ºåºã€‚

### å¼‚æ­¥ä¸å¹¶å‘
+ **Crews**ï¼š
    - ä»£ç†æ”¯æŒå¼‚æ­¥æ“ä½œï¼Œä»»åŠ¡å¯å¹¶å‘æ‰§è¡Œã€‚
    - æä¾›å¼‚æ­¥å¯åŠ¨æ–¹æ³•ï¼škickoff_async()ï¼ˆå•æ¬¡å¼‚æ­¥ï¼‰å’Œ kickoff_for_each_async()ï¼ˆå¹¶å‘å¤„ç†å¤šè¾“å…¥ï¼‰ã€‚
+ **Flows**ï¼š
    - æ”¯æŒå¼‚æ­¥ä»»åŠ¡æ‰§è¡Œï¼Œå…è®¸å¹¶è¡Œè¿è¡Œæ— å…³ä»»åŠ¡ã€‚
    - äº‹ä»¶é©±åŠ¨æ¶æ„æ”¯æŒåŠ¨æ€å“åº”å’Œå¹¶å‘ä¼˜åŒ–

### æµå¼è¾“å‡º
+ **æœ‰é™æ”¯æŒ**ï¼š
    - æ— åŸç”Ÿæµå¼è¾“å‡ºæ”¯æŒï¼Œä»»åŠ¡è¾“å‡ºä»¥å®Œæ•´å•å…ƒäº¤ä»˜ã€‚
    - å¯é€šè¿‡æ”¯æŒæµå¼çš„ LLM æä¾›å•†ï¼ˆå¦‚ OpenAIï¼‰å®ç°æœ‰é™æµå¼å“åº”ï¼Œä½†éœ€è‡ªå®šä¹‰ã€‚

### æŒä¹…åŒ–æœºåˆ¶
+ **Crews**ï¼š
    - é€šè¿‡è®°å¿†æœºåˆ¶ï¼ˆçŸ­æœŸã€é•¿æœŸã€å®ä½“ï¼‰ä¿ç•™ä¸Šä¸‹æ–‡ã€‚
    - ç¼“å­˜å­˜å‚¨å·¥å…·æ‰§è¡Œç»“æœï¼ŒåŠ é€Ÿé‡å¤è°ƒç”¨ã€‚
+ **Flows**ï¼š
    - æ”¯æŒçŠ¶æ€æŒä¹…åŒ–ï¼Œä½¿ç”¨ @persist è£…é¥°å™¨ã€‚
    - é»˜è®¤ SQLite åç«¯ï¼Œæ”¯æŒç»“æ„åŒ–å’Œéç»“æ„åŒ–çŠ¶æ€ã€‚
    - å¯è·¨ä»»åŠ¡å’Œè¿è¡Œä¿ç•™çŠ¶æ€ã€‚

### å¯è§‚æµ‹æ€§
+ **æ§åˆ¶å¹³é¢**ï¼šæä¾› Crew æ€§èƒ½ã€èµ„æºæ¶ˆè€—å’Œä»»åŠ¡è¿›åº¦çš„ç›‘æ§è§†å›¾ï¼ˆä¼ä¸šç‰ˆæ›´å®Œå–„ï¼‰ã€‚
+ **æ—¥å¿—**ï¼šæ”¯æŒå®æ—¶æ—¥å¿—ä¿å­˜ï¼ˆ.txt æˆ– .jsonï¼‰ï¼Œé€šè¿‡ output_log_file é…ç½®ã€‚
+ **é«˜çº§ç›‘æ§**ï¼šå¯é›†æˆ LangSmith è¿½è¸ª LLM è°ƒç”¨ï¼›æä¾›ä½¿ç”¨æŒ‡æ ‡ï¼ˆusage_metricsï¼‰åˆ†æ LLM æ¶ˆè€—ã€‚
+ **é‡æ”¾åŠŸèƒ½**ï¼šæ”¯æŒä»ç‰¹å®šä»»åŠ¡é‡æ”¾ï¼ˆcrewai replay -t <task_id>ï¼‰ï¼Œä¾¿äºè°ƒè¯•ã€‚



